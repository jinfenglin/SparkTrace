2018-12-31 07:34:29 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 16)
2018-12-31 07:34:29 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 16). 3196 bytes result sent to driver
2018-12-31 07:34:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 16) in 21 ms on localhost (executor driver) (1/1)
2018-12-31 07:34:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-12-31 07:34:29 INFO  DAGScheduler:54 - ResultStage 5 (show at CustomizedStagesTest.java:135) finished in 0.053 s
2018-12-31 07:34:29 INFO  DAGScheduler:54 - Job 5 finished: show at CustomizedStagesTest.java:135, took 0.056664 s
2018-12-31 07:34:29 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:135
2018-12-31 07:34:29 INFO  DAGScheduler:54 - Got job 6 (show at CustomizedStagesTest.java:135) with 3 output partitions
2018-12-31 07:34:29 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (show at CustomizedStagesTest.java:135)
2018-12-31 07:34:29 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:34:29 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:34:29 INFO  DAGScheduler:54 - Submitting ResultStage 6 (MapPartitionsRDD[75] at show at CustomizedStagesTest.java:135), which has no missing parents
2018-12-31 07:34:29 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 2.1 MB, free 1992.0 MB)
2018-12-31 07:34:29 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 34.2 KB, free 1992.0 MB)
2018-12-31 07:34:29 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:51811 (size: 34.2 KB, free: 1996.1 MB)
2018-12-31 07:34:29 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:34:29 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ResultStage 6 (MapPartitionsRDD[75] at show at CustomizedStagesTest.java:135) (first 15 tasks are for partitions Vector(1, 2, 3))
2018-12-31 07:34:29 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 3 tasks
2018-12-31 07:34:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 17, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:34:29 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 17)
2018-12-31 07:34:29 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 17). 2775 bytes result sent to driver
2018-12-31 07:34:29 INFO  TaskSetManager:54 - Starting task 1.0 in stage 6.0 (TID 18, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:34:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 17) in 12 ms on localhost (executor driver) (1/3)
2018-12-31 07:34:29 INFO  Executor:54 - Running task 1.0 in stage 6.0 (TID 18)
2018-12-31 07:34:29 INFO  Executor:54 - Finished task 1.0 in stage 6.0 (TID 18). 2732 bytes result sent to driver
2018-12-31 07:34:29 INFO  TaskSetManager:54 - Starting task 2.0 in stage 6.0 (TID 19, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:34:29 INFO  TaskSetManager:54 - Finished task 1.0 in stage 6.0 (TID 18) in 12 ms on localhost (executor driver) (2/3)
2018-12-31 07:34:29 INFO  Executor:54 - Running task 2.0 in stage 6.0 (TID 19)
2018-12-31 07:34:29 INFO  Executor:54 - Finished task 2.0 in stage 6.0 (TID 19). 2732 bytes result sent to driver
2018-12-31 07:34:29 INFO  TaskSetManager:54 - Finished task 2.0 in stage 6.0 (TID 19) in 12 ms on localhost (executor driver) (3/3)
2018-12-31 07:34:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-12-31 07:34:29 INFO  DAGScheduler:54 - ResultStage 6 (show at CustomizedStagesTest.java:135) finished in 0.048 s
2018-12-31 07:34:29 INFO  DAGScheduler:54 - Job 6 finished: show at CustomizedStagesTest.java:135, took 0.050424 s
2018-12-31 07:35:01 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-12-31 07:35:01 INFO  AbstractConnector:318 - Stopped Spark@3a175162{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:35:01 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2018-12-31 07:35:01 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-12-31 07:35:01 INFO  MemoryStore:54 - MemoryStore cleared
2018-12-31 07:35:01 INFO  BlockManager:54 - BlockManager stopped
2018-12-31 07:35:01 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-12-31 07:35:01 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-12-31 07:35:01 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-12-31 07:35:01 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-12-31 07:35:01 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-2def7913-89a5-4e80-b467-538245df1c16
2018-12-31 07:36:18 INFO  SparkContext:54 - Running Spark version 2.3.2
2018-12-31 07:36:18 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-31 07:36:18 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at CustomizedStagesTest.<init>(CustomizedStagesTest.java:27)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-31 07:36:18 INFO  SparkContext:54 - Submitted application: SparkTest
2018-12-31 07:36:18 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2018-12-31 07:36:18 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2018-12-31 07:36:18 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-12-31 07:36:18 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-12-31 07:36:18 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2018-12-31 07:36:19 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 52135.
2018-12-31 07:36:19 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-12-31 07:36:19 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-12-31 07:36:19 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-31 07:36:19 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-12-31 07:36:19 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-741f63d7-ff68-49e6-a291-424c35b474cb
2018-12-31 07:36:19 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2018-12-31 07:36:19 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-12-31 07:36:19 INFO  log:192 - Logging initialized @7861ms
2018-12-31 07:36:19 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2018-12-31 07:36:19 INFO  Server:419 - Started @7922ms
2018-12-31 07:36:19 INFO  AbstractConnector:278 - Started ServerConnector@3a175162{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:36:19 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c8d5312{/jobs,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/jobs/json,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@35eb4a3b{/jobs/job,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26b95b0b{/stages,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f7da3d3{/stages/json,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@103082dd{/stages/stage,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f172d4a{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/pool,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67efd2c2{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@71d9cb05{/storage,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17c2d509{/storage/json,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@36bf84e{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a0b5323{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@25b52284{/environment,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@245ec1a6{/environment/json,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@782be4eb{/executors,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38792286{/executors/json,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@34d4860f{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@665522c2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/static,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@19f7222e{/,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3f725306{/api,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29138d3a{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-31 07:36:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5cbe2654{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-31 07:36:20 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2018-12-31 07:36:20 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-12-31 07:36:20 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52149.
2018-12-31 07:36:20 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:52149
2018-12-31 07:36:20 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-31 07:36:20 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 52149, None)
2018-12-31 07:36:20 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:52149 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 52149, None)
2018-12-31 07:36:20 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 52149, None)
2018-12-31 07:36:20 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 52149, None)
2018-12-31 07:36:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4232b34a{/metrics/json,null,AVAILABLE,@Spark}
2018-12-31 07:36:20 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2018-12-31 07:36:20 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2018-12-31 07:36:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@47c7a9e5{/SQL,null,AVAILABLE,@Spark}
2018-12-31 07:36:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7951c3a2{/SQL/json,null,AVAILABLE,@Spark}
2018-12-31 07:36:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20580d4e{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-31 07:36:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21bd128b{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-31 07:36:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@580fd26b{/static/sql,null,AVAILABLE,@Spark}
2018-12-31 07:36:21 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2018-12-31 07:36:24 INFO  CodeGenerator:54 - Code generated in 319.3361 ms
2018-12-31 07:36:24 INFO  CodeGenerator:54 - Code generated in 11.2511 ms
2018-12-31 07:36:24 INFO  CodeGenerator:54 - Code generated in 25.5215 ms
2018-12-31 07:36:24 INFO  CodeGenerator:54 - Code generated in 21.1648 ms
2018-12-31 07:36:24 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2018-12-31 07:36:24 INFO  DAGScheduler:54 - Got job 0 (treeAggregate at IDF.scala:54) with 4 output partitions
2018-12-31 07:36:24 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (treeAggregate at IDF.scala:54)
2018-12-31 07:36:24 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:36:24 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:36:24 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54), which has no missing parents
2018-12-31 07:36:24 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 38.4 KB, free 1996.2 MB)
2018-12-31 07:36:24 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1996.2 MB)
2018-12-31 07:36:24 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:52149 (size: 10.2 KB, free: 1996.2 MB)
2018-12-31 07:36:24 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:36:24 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:36:24 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 4 tasks
2018-12-31 07:36:24 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:36:24 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2018-12-31 07:36:24 INFO  CodeGenerator:54 - Code generated in 7.9209 ms
2018-12-31 07:36:25 INFO  MemoryStore:54 - Block taskresult_0 stored as bytes in memory (estimated size 2.0 MB, free 1994.1 MB)
2018-12-31 07:36:25 INFO  BlockManagerInfo:54 - Added taskresult_0 in memory on AshCloud-D1:52149 (size: 2.0 MB, free: 1994.2 MB)
2018-12-31 07:36:25 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2109304 bytes result sent via BlockManager)
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:36:25 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2018-12-31 07:36:25 INFO  Executor:54 - Finished task 1.0 in stage 0.0 (TID 1). 1634 bytes result sent to driver
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:36:25 INFO  Executor:54 - Running task 2.0 in stage 0.0 (TID 2)
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 17 ms on localhost (executor driver) (1/4)
2018-12-31 07:36:25 INFO  Executor:54 - Finished task 2.0 in stage 0.0 (TID 2). 1677 bytes result sent to driver
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:36:25 INFO  Executor:54 - Running task 3.0 in stage 0.0 (TID 3)
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Finished task 2.0 in stage 0.0 (TID 2) in 17 ms on localhost (executor driver) (2/4)
2018-12-31 07:36:25 INFO  Executor:54 - Finished task 3.0 in stage 0.0 (TID 3). 1677 bytes result sent to driver
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Finished task 3.0 in stage 0.0 (TID 3) in 17 ms on localhost (executor driver) (3/4)
2018-12-31 07:36:25 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:52149 after 42 ms (0 ms spent in bootstraps)
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 727 ms on localhost (executor driver) (4/4)
2018-12-31 07:36:25 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-12-31 07:36:25 INFO  DAGScheduler:54 - ResultStage 0 (treeAggregate at IDF.scala:54) finished in 0.907 s
2018-12-31 07:36:25 INFO  BlockManagerInfo:54 - Removed taskresult_0 on AshCloud-D1:52149 in memory (size: 2.0 MB, free: 1996.2 MB)
2018-12-31 07:36:25 INFO  DAGScheduler:54 - Job 0 finished: treeAggregate at IDF.scala:54, took 0.954980 s
2018-12-31 07:36:25 INFO  CodeGenerator:54 - Code generated in 11.3875 ms
2018-12-31 07:36:25 INFO  CodeGenerator:54 - Code generated in 12.6067 ms
2018-12-31 07:36:25 INFO  CodeGenerator:54 - Code generated in 23.3172 ms
2018-12-31 07:36:25 INFO  CodeGenerator:54 - Code generated in 17.7707 ms
2018-12-31 07:36:25 INFO  CodeGenerator:54 - Code generated in 23.6525 ms
2018-12-31 07:36:25 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1142
2018-12-31 07:36:25 INFO  DAGScheduler:54 - Got job 1 (run at ThreadPoolExecutor.java:1142) with 4 output partitions
2018-12-31 07:36:25 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (run at ThreadPoolExecutor.java:1142)
2018-12-31 07:36:25 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:36:25 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:36:25 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-12-31 07:36:25 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 2.0 MB, free 1994.1 MB)
2018-12-31 07:36:25 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 22.7 KB, free 1994.1 MB)
2018-12-31 07:36:25 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:52149 (size: 22.7 KB, free: 1996.2 MB)
2018-12-31 07:36:25 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:36:25 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:36:25 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 4 tasks
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:36:25 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 4)
2018-12-31 07:36:25 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 4). 1859 bytes result sent to driver
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:36:25 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 5)
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 4) in 23 ms on localhost (executor driver) (1/4)
2018-12-31 07:36:25 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 5). 1741 bytes result sent to driver
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:36:25 INFO  Executor:54 - Running task 2.0 in stage 1.0 (TID 6)
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 5) in 7 ms on localhost (executor driver) (2/4)
2018-12-31 07:36:25 INFO  Executor:54 - Finished task 2.0 in stage 1.0 (TID 6). 1784 bytes result sent to driver
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:36:25 INFO  Executor:54 - Running task 3.0 in stage 1.0 (TID 7)
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Finished task 2.0 in stage 1.0 (TID 6) in 9 ms on localhost (executor driver) (3/4)
2018-12-31 07:36:25 INFO  Executor:54 - Finished task 3.0 in stage 1.0 (TID 7). 1741 bytes result sent to driver
2018-12-31 07:36:25 INFO  TaskSetManager:54 - Finished task 3.0 in stage 1.0 (TID 7) in 7 ms on localhost (executor driver) (4/4)
2018-12-31 07:36:25 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-12-31 07:36:25 INFO  DAGScheduler:54 - ResultStage 1 (run at ThreadPoolExecutor.java:1142) finished in 0.076 s
2018-12-31 07:36:25 INFO  DAGScheduler:54 - Job 1 finished: run at ThreadPoolExecutor.java:1142, took 0.080602 s
2018-12-31 07:36:25 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 216.0 B, free 1994.1 MB)
2018-12-31 07:36:25 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 252.0 B, free 1994.1 MB)
2018-12-31 07:36:25 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:52149 (size: 252.0 B, free: 1996.2 MB)
2018-12-31 07:36:25 INFO  SparkContext:54 - Created broadcast 2 from run at ThreadPoolExecutor.java:1142
2018-12-31 07:36:25 INFO  CodeGenerator:54 - Code generated in 20.1865 ms
2018-12-31 07:36:26 INFO  CodeGenerator:54 - Code generated in 17.4035 ms
2018-12-31 07:36:26 INFO  CodeGenerator:54 - Code generated in 14.6517 ms
2018-12-31 07:36:26 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:133
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Got job 2 (show at CustomizedStagesTest.java:133) with 1 output partitions
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (show at CustomizedStagesTest.java:133)
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:133), which has no missing parents
2018-12-31 07:36:26 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 2.0 MB, free 1992.0 MB)
2018-12-31 07:36:26 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 28.0 KB, free 1992.0 MB)
2018-12-31 07:36:26 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:52149 (size: 28.0 KB, free: 1996.1 MB)
2018-12-31 07:36:26 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:133) (first 15 tasks are for partitions Vector(0))
2018-12-31 07:36:26 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2018-12-31 07:36:26 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:36:26 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 8)
2018-12-31 07:36:26 INFO  CodeGenerator:54 - Code generated in 18.3475 ms
2018-12-31 07:36:26 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 8). 3018 bytes result sent to driver
2018-12-31 07:36:26 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 8) in 45 ms on localhost (executor driver) (1/1)
2018-12-31 07:36:26 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-12-31 07:36:26 INFO  DAGScheduler:54 - ResultStage 2 (show at CustomizedStagesTest.java:133) finished in 0.076 s
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Job 2 finished: show at CustomizedStagesTest.java:133, took 0.079424 s
2018-12-31 07:36:26 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:133
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Got job 3 (show at CustomizedStagesTest.java:133) with 3 output partitions
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (show at CustomizedStagesTest.java:133)
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:133), which has no missing parents
2018-12-31 07:36:26 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 2.0 MB, free 1990.0 MB)
2018-12-31 07:36:26 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 28.0 KB, free 1989.9 MB)
2018-12-31 07:36:26 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:52149 (size: 28.0 KB, free: 1996.1 MB)
2018-12-31 07:36:26 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:133) (first 15 tasks are for partitions Vector(1, 2, 3))
2018-12-31 07:36:26 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 3 tasks
2018-12-31 07:36:26 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:36:26 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 9)
2018-12-31 07:36:26 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 9). 2732 bytes result sent to driver
2018-12-31 07:36:26 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:36:26 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 10)
2018-12-31 07:36:26 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 9) in 11 ms on localhost (executor driver) (1/3)
2018-12-31 07:36:26 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 10). 2775 bytes result sent to driver
2018-12-31 07:36:26 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:36:26 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 10) in 11 ms on localhost (executor driver) (2/3)
2018-12-31 07:36:26 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 11)
2018-12-31 07:36:26 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 11). 2775 bytes result sent to driver
2018-12-31 07:36:26 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 11) in 13 ms on localhost (executor driver) (3/3)
2018-12-31 07:36:26 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-12-31 07:36:26 INFO  DAGScheduler:54 - ResultStage 3 (show at CustomizedStagesTest.java:133) finished in 0.051 s
2018-12-31 07:36:26 INFO  DAGScheduler:54 - Job 3 finished: show at CustomizedStagesTest.java:133, took 0.054118 s
2018-12-31 07:36:37 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-12-31 07:36:37 INFO  AbstractConnector:318 - Stopped Spark@3a175162{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:36:37 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2018-12-31 07:36:37 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-12-31 07:36:38 INFO  MemoryStore:54 - MemoryStore cleared
2018-12-31 07:36:38 INFO  BlockManager:54 - BlockManager stopped
2018-12-31 07:36:38 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-12-31 07:36:38 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-12-31 07:36:38 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-12-31 07:36:38 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-12-31 07:36:38 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-8475f872-6bd0-4c99-85b8-65549a82a3f9
2018-12-31 07:37:54 INFO  SparkContext:54 - Running Spark version 2.3.2
2018-12-31 07:37:54 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-31 07:37:54 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at CustomizedStagesTest.<init>(CustomizedStagesTest.java:27)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-31 07:37:54 INFO  SparkContext:54 - Submitted application: SparkTest
2018-12-31 07:37:54 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2018-12-31 07:37:54 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2018-12-31 07:37:54 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-12-31 07:37:54 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-12-31 07:37:54 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2018-12-31 07:37:55 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 52373.
2018-12-31 07:37:55 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-12-31 07:37:55 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-12-31 07:37:55 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-31 07:37:55 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-12-31 07:37:55 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-1752d304-41c3-4aa8-b4b8-cf1dde21eefd
2018-12-31 07:37:55 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2018-12-31 07:37:55 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-12-31 07:37:55 INFO  log:192 - Logging initialized @7297ms
2018-12-31 07:37:55 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2018-12-31 07:37:55 INFO  Server:419 - Started @7353ms
2018-12-31 07:37:55 INFO  AbstractConnector:278 - Started ServerConnector@3a175162{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:37:55 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c8d5312{/jobs,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/jobs/json,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@35eb4a3b{/jobs/job,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26b95b0b{/stages,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f7da3d3{/stages/json,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@103082dd{/stages/stage,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f172d4a{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/pool,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67efd2c2{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@71d9cb05{/storage,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17c2d509{/storage/json,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@36bf84e{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a0b5323{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@25b52284{/environment,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@245ec1a6{/environment/json,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@782be4eb{/executors,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38792286{/executors/json,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@34d4860f{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@665522c2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/static,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@19f7222e{/,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3f725306{/api,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29138d3a{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5cbe2654{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-31 07:37:55 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2018-12-31 07:37:56 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-12-31 07:37:56 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52386.
2018-12-31 07:37:56 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:52386
2018-12-31 07:37:56 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-31 07:37:56 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 52386, None)
2018-12-31 07:37:56 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:52386 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 52386, None)
2018-12-31 07:37:56 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 52386, None)
2018-12-31 07:37:56 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 52386, None)
2018-12-31 07:37:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4232b34a{/metrics/json,null,AVAILABLE,@Spark}
2018-12-31 07:37:56 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2018-12-31 07:37:56 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2018-12-31 07:37:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@47c7a9e5{/SQL,null,AVAILABLE,@Spark}
2018-12-31 07:37:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7951c3a2{/SQL/json,null,AVAILABLE,@Spark}
2018-12-31 07:37:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20580d4e{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-31 07:37:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21bd128b{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-31 07:37:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@580fd26b{/static/sql,null,AVAILABLE,@Spark}
2018-12-31 07:37:57 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2018-12-31 07:37:59 INFO  CodeGenerator:54 - Code generated in 283.3677 ms
2018-12-31 07:37:59 INFO  CodeGenerator:54 - Code generated in 9.3033 ms
2018-12-31 07:37:59 INFO  CodeGenerator:54 - Code generated in 24.1431 ms
2018-12-31 07:37:59 INFO  CodeGenerator:54 - Code generated in 15.8588 ms
2018-12-31 07:37:59 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2018-12-31 07:37:59 INFO  DAGScheduler:54 - Got job 0 (treeAggregate at IDF.scala:54) with 4 output partitions
2018-12-31 07:37:59 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (treeAggregate at IDF.scala:54)
2018-12-31 07:37:59 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:37:59 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:37:59 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54), which has no missing parents
2018-12-31 07:38:00 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 38.4 KB, free 1996.2 MB)
2018-12-31 07:38:00 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1996.2 MB)
2018-12-31 07:38:00 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:52386 (size: 10.2 KB, free: 1996.2 MB)
2018-12-31 07:38:00 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:38:00 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:38:00 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 4 tasks
2018-12-31 07:38:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:38:00 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2018-12-31 07:38:00 INFO  CodeGenerator:54 - Code generated in 7.3799 ms
2018-12-31 07:38:00 INFO  MemoryStore:54 - Block taskresult_0 stored as bytes in memory (estimated size 2.0 MB, free 1994.1 MB)
2018-12-31 07:38:00 INFO  BlockManagerInfo:54 - Added taskresult_0 in memory on AshCloud-D1:52386 (size: 2.0 MB, free: 1994.2 MB)
2018-12-31 07:38:00 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2109304 bytes result sent via BlockManager)
2018-12-31 07:38:00 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:38:00 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2018-12-31 07:38:00 INFO  Executor:54 - Finished task 1.0 in stage 0.0 (TID 1). 1677 bytes result sent to driver
2018-12-31 07:38:00 INFO  TaskSetManager:54 - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:38:00 INFO  Executor:54 - Running task 2.0 in stage 0.0 (TID 2)
2018-12-31 07:38:00 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 14 ms on localhost (executor driver) (1/4)
2018-12-31 07:38:00 INFO  Executor:54 - Finished task 2.0 in stage 0.0 (TID 2). 1677 bytes result sent to driver
2018-12-31 07:38:00 INFO  TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:38:00 INFO  Executor:54 - Running task 3.0 in stage 0.0 (TID 3)
2018-12-31 07:38:00 INFO  TaskSetManager:54 - Finished task 2.0 in stage 0.0 (TID 2) in 18 ms on localhost (executor driver) (2/4)
2018-12-31 07:38:00 INFO  Executor:54 - Finished task 3.0 in stage 0.0 (TID 3). 1634 bytes result sent to driver
2018-12-31 07:38:00 INFO  TaskSetManager:54 - Finished task 3.0 in stage 0.0 (TID 3) in 22 ms on localhost (executor driver) (3/4)
2018-12-31 07:38:00 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:52386 after 44 ms (0 ms spent in bootstraps)
2018-12-31 07:38:00 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 676 ms on localhost (executor driver) (4/4)
2018-12-31 07:38:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-12-31 07:38:00 INFO  DAGScheduler:54 - ResultStage 0 (treeAggregate at IDF.scala:54) finished in 0.844 s
2018-12-31 07:38:00 INFO  BlockManagerInfo:54 - Removed taskresult_0 on AshCloud-D1:52386 in memory (size: 2.0 MB, free: 1996.2 MB)
2018-12-31 07:38:00 INFO  DAGScheduler:54 - Job 0 finished: treeAggregate at IDF.scala:54, took 0.891446 s
2018-12-31 07:38:01 INFO  CodeGenerator:54 - Code generated in 8.6863 ms
2018-12-31 07:38:01 INFO  CodeGenerator:54 - Code generated in 13.8176 ms
2018-12-31 07:38:01 INFO  CodeGenerator:54 - Code generated in 23.4016 ms
2018-12-31 07:38:01 INFO  CodeGenerator:54 - Code generated in 17.6235 ms
2018-12-31 07:38:01 INFO  CodeGenerator:54 - Code generated in 26.191 ms
2018-12-31 07:38:01 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1142
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Got job 1 (run at ThreadPoolExecutor.java:1142) with 4 output partitions
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (run at ThreadPoolExecutor.java:1142)
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-12-31 07:38:01 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 2.0 MB, free 1994.1 MB)
2018-12-31 07:38:01 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 22.7 KB, free 1994.1 MB)
2018-12-31 07:38:01 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:52386 (size: 22.7 KB, free: 1996.2 MB)
2018-12-31 07:38:01 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:38:01 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 4 tasks
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:38:01 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 4)
2018-12-31 07:38:01 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 4). 1859 bytes result sent to driver
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:38:01 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 5)
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 4) in 19 ms on localhost (executor driver) (1/4)
2018-12-31 07:38:01 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 5). 1784 bytes result sent to driver
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 5) in 8 ms on localhost (executor driver) (2/4)
2018-12-31 07:38:01 INFO  Executor:54 - Running task 2.0 in stage 1.0 (TID 6)
2018-12-31 07:38:01 INFO  Executor:54 - Finished task 2.0 in stage 1.0 (TID 6). 1784 bytes result sent to driver
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Finished task 2.0 in stage 1.0 (TID 6) in 9 ms on localhost (executor driver) (3/4)
2018-12-31 07:38:01 INFO  Executor:54 - Running task 3.0 in stage 1.0 (TID 7)
2018-12-31 07:38:01 INFO  Executor:54 - Finished task 3.0 in stage 1.0 (TID 7). 1784 bytes result sent to driver
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Finished task 3.0 in stage 1.0 (TID 7) in 10 ms on localhost (executor driver) (4/4)
2018-12-31 07:38:01 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-12-31 07:38:01 INFO  DAGScheduler:54 - ResultStage 1 (run at ThreadPoolExecutor.java:1142) finished in 0.060 s
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Job 1 finished: run at ThreadPoolExecutor.java:1142, took 0.063813 s
2018-12-31 07:38:01 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 216.0 B, free 1994.1 MB)
2018-12-31 07:38:01 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 252.0 B, free 1994.1 MB)
2018-12-31 07:38:01 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:52386 (size: 252.0 B, free: 1996.2 MB)
2018-12-31 07:38:01 INFO  SparkContext:54 - Created broadcast 2 from run at ThreadPoolExecutor.java:1142
2018-12-31 07:38:01 INFO  CodeGenerator:54 - Code generated in 18.7747 ms
2018-12-31 07:38:01 INFO  CodeGenerator:54 - Code generated in 17.4817 ms
2018-12-31 07:38:01 INFO  CodeGenerator:54 - Code generated in 12.7989 ms
2018-12-31 07:38:01 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:133
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Got job 2 (show at CustomizedStagesTest.java:133) with 1 output partitions
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (show at CustomizedStagesTest.java:133)
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:133), which has no missing parents
2018-12-31 07:38:01 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 2.0 MB, free 1992.0 MB)
2018-12-31 07:38:01 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 28.0 KB, free 1992.0 MB)
2018-12-31 07:38:01 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:52386 (size: 28.0 KB, free: 1996.1 MB)
2018-12-31 07:38:01 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:133) (first 15 tasks are for partitions Vector(0))
2018-12-31 07:38:01 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:38:01 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 8)
2018-12-31 07:38:01 INFO  CodeGenerator:54 - Code generated in 11.6038 ms
2018-12-31 07:38:01 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 8). 2975 bytes result sent to driver
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 8) in 39 ms on localhost (executor driver) (1/1)
2018-12-31 07:38:01 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-12-31 07:38:01 INFO  DAGScheduler:54 - ResultStage 2 (show at CustomizedStagesTest.java:133) finished in 0.067 s
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Job 2 finished: show at CustomizedStagesTest.java:133, took 0.069955 s
2018-12-31 07:38:01 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:133
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Got job 3 (show at CustomizedStagesTest.java:133) with 3 output partitions
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (show at CustomizedStagesTest.java:133)
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:133), which has no missing parents
2018-12-31 07:38:01 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 2.0 MB, free 1990.0 MB)
2018-12-31 07:38:01 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 28.0 KB, free 1989.9 MB)
2018-12-31 07:38:01 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:52386 (size: 28.0 KB, free: 1996.1 MB)
2018-12-31 07:38:01 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:133) (first 15 tasks are for partitions Vector(1, 2, 3))
2018-12-31 07:38:01 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 3 tasks
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:38:01 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 9)
2018-12-31 07:38:01 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 9). 2732 bytes result sent to driver
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 9) in 11 ms on localhost (executor driver) (1/3)
2018-12-31 07:38:01 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 10)
2018-12-31 07:38:01 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 10). 2732 bytes result sent to driver
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:38:01 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 11)
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 10) in 12 ms on localhost (executor driver) (2/3)
2018-12-31 07:38:01 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 11). 2818 bytes result sent to driver
2018-12-31 07:38:01 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 11) in 15 ms on localhost (executor driver) (3/3)
2018-12-31 07:38:01 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-12-31 07:38:01 INFO  DAGScheduler:54 - ResultStage 3 (show at CustomizedStagesTest.java:133) finished in 0.052 s
2018-12-31 07:38:01 INFO  DAGScheduler:54 - Job 3 finished: show at CustomizedStagesTest.java:133, took 0.055951 s
2018-12-31 07:39:06 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-12-31 07:39:06 INFO  AbstractConnector:318 - Stopped Spark@3a175162{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:39:06 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2018-12-31 07:39:06 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-12-31 07:39:06 INFO  MemoryStore:54 - MemoryStore cleared
2018-12-31 07:39:06 INFO  BlockManager:54 - BlockManager stopped
2018-12-31 07:39:06 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-12-31 07:39:06 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-12-31 07:39:06 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-12-31 07:39:06 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-12-31 07:39:06 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-525d9171-240d-43d8-aa74-87aab44df878
2018-12-31 07:40:21 INFO  SparkContext:54 - Running Spark version 2.3.2
2018-12-31 07:40:21 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-31 07:40:22 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at CustomizedStagesTest.<init>(CustomizedStagesTest.java:29)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-31 07:40:22 INFO  SparkContext:54 - Submitted application: SparkTest
2018-12-31 07:40:22 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2018-12-31 07:40:22 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2018-12-31 07:40:22 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-12-31 07:40:22 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-12-31 07:40:22 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2018-12-31 07:40:23 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 52624.
2018-12-31 07:40:23 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-12-31 07:40:23 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-12-31 07:40:23 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-31 07:40:23 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-12-31 07:40:23 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-8941c011-7e38-4df1-8025-943b25a63e36
2018-12-31 07:40:23 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2018-12-31 07:40:23 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-12-31 07:40:23 INFO  log:192 - Logging initialized @7646ms
2018-12-31 07:40:23 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2018-12-31 07:40:23 INFO  Server:419 - Started @7709ms
2018-12-31 07:40:23 INFO  AbstractConnector:278 - Started ServerConnector@3a175162{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:40:23 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c8d5312{/jobs,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/jobs/json,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@35eb4a3b{/jobs/job,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26b95b0b{/stages,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f7da3d3{/stages/json,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@103082dd{/stages/stage,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f172d4a{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/pool,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67efd2c2{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@71d9cb05{/storage,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17c2d509{/storage/json,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@36bf84e{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a0b5323{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@25b52284{/environment,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@245ec1a6{/environment/json,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@782be4eb{/executors,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38792286{/executors/json,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@34d4860f{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@665522c2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/static,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@19f7222e{/,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3f725306{/api,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29138d3a{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5cbe2654{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-31 07:40:23 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2018-12-31 07:40:23 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-12-31 07:40:23 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52637.
2018-12-31 07:40:23 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:52637
2018-12-31 07:40:23 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-31 07:40:23 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 52637, None)
2018-12-31 07:40:23 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:52637 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 52637, None)
2018-12-31 07:40:23 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 52637, None)
2018-12-31 07:40:23 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 52637, None)
2018-12-31 07:40:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@751ae8a4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-31 07:40:24 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2018-12-31 07:40:24 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2018-12-31 07:40:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@64da6cbd{/SQL,null,AVAILABLE,@Spark}
2018-12-31 07:40:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72a2312e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-31 07:40:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2d119405{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-31 07:40:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57e388c3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-31 07:40:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62f11ebb{/static/sql,null,AVAILABLE,@Spark}
2018-12-31 07:40:24 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2018-12-31 07:40:27 INFO  CodeGenerator:54 - Code generated in 369.3101 ms
2018-12-31 07:40:27 INFO  CodeGenerator:54 - Code generated in 9.2617 ms
2018-12-31 07:40:27 INFO  CodeGenerator:54 - Code generated in 23.0758 ms
2018-12-31 07:40:27 INFO  CodeGenerator:54 - Code generated in 15.25 ms
2018-12-31 07:40:27 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2018-12-31 07:40:27 INFO  DAGScheduler:54 - Got job 0 (treeAggregate at IDF.scala:54) with 4 output partitions
2018-12-31 07:40:27 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (treeAggregate at IDF.scala:54)
2018-12-31 07:40:27 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:40:27 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:40:27 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54), which has no missing parents
2018-12-31 07:40:28 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 38.4 KB, free 1996.2 MB)
2018-12-31 07:40:28 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1996.2 MB)
2018-12-31 07:40:28 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:52637 (size: 10.2 KB, free: 1996.2 MB)
2018-12-31 07:40:28 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:40:28 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:40:28 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 4 tasks
2018-12-31 07:40:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:40:28 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2018-12-31 07:40:28 INFO  CodeGenerator:54 - Code generated in 7.8018 ms
2018-12-31 07:40:28 INFO  MemoryStore:54 - Block taskresult_0 stored as bytes in memory (estimated size 2.0 MB, free 1994.1 MB)
2018-12-31 07:40:28 INFO  BlockManagerInfo:54 - Added taskresult_0 in memory on AshCloud-D1:52637 (size: 2.0 MB, free: 1994.2 MB)
2018-12-31 07:40:28 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2109304 bytes result sent via BlockManager)
2018-12-31 07:40:28 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:40:28 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2018-12-31 07:40:28 INFO  Executor:54 - Finished task 1.0 in stage 0.0 (TID 1). 1677 bytes result sent to driver
2018-12-31 07:40:28 INFO  TaskSetManager:54 - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:40:28 INFO  Executor:54 - Running task 2.0 in stage 0.0 (TID 2)
2018-12-31 07:40:28 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 19 ms on localhost (executor driver) (1/4)
2018-12-31 07:40:28 INFO  Executor:54 - Finished task 2.0 in stage 0.0 (TID 2). 1677 bytes result sent to driver
2018-12-31 07:40:28 INFO  TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:40:28 INFO  Executor:54 - Running task 3.0 in stage 0.0 (TID 3)
2018-12-31 07:40:28 INFO  TaskSetManager:54 - Finished task 2.0 in stage 0.0 (TID 2) in 18 ms on localhost (executor driver) (2/4)
2018-12-31 07:40:28 INFO  Executor:54 - Finished task 3.0 in stage 0.0 (TID 3). 1677 bytes result sent to driver
2018-12-31 07:40:28 INFO  TaskSetManager:54 - Finished task 3.0 in stage 0.0 (TID 3) in 18 ms on localhost (executor driver) (3/4)
2018-12-31 07:40:28 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:52637 after 42 ms (0 ms spent in bootstraps)
2018-12-31 07:40:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 703 ms on localhost (executor driver) (4/4)
2018-12-31 07:40:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-12-31 07:40:28 INFO  DAGScheduler:54 - ResultStage 0 (treeAggregate at IDF.scala:54) finished in 0.871 s
2018-12-31 07:40:28 INFO  BlockManagerInfo:54 - Removed taskresult_0 on AshCloud-D1:52637 in memory (size: 2.0 MB, free: 1996.2 MB)
2018-12-31 07:40:28 INFO  DAGScheduler:54 - Job 0 finished: treeAggregate at IDF.scala:54, took 0.919430 s
2018-12-31 07:40:29 INFO  CodeGenerator:54 - Code generated in 9.196 ms
2018-12-31 07:40:29 INFO  CodeGenerator:54 - Code generated in 14.1417 ms
2018-12-31 07:40:29 INFO  CodeGenerator:54 - Code generated in 28.9611 ms
2018-12-31 07:40:29 INFO  CodeGenerator:54 - Code generated in 24.4275 ms
2018-12-31 07:40:29 INFO  CodeGenerator:54 - Code generated in 22.0632 ms
2018-12-31 07:40:29 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1142
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Got job 1 (run at ThreadPoolExecutor.java:1142) with 4 output partitions
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (run at ThreadPoolExecutor.java:1142)
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-12-31 07:40:29 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 2.0 MB, free 1994.1 MB)
2018-12-31 07:40:29 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 22.7 KB, free 1994.1 MB)
2018-12-31 07:40:29 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:52637 (size: 22.7 KB, free: 1996.2 MB)
2018-12-31 07:40:29 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:40:29 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 4 tasks
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:40:29 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 4)
2018-12-31 07:40:29 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 4). 1859 bytes result sent to driver
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:40:29 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 5)
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 4) in 19 ms on localhost (executor driver) (1/4)
2018-12-31 07:40:29 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 5). 1698 bytes result sent to driver
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:40:29 INFO  Executor:54 - Running task 2.0 in stage 1.0 (TID 6)
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 5) in 8 ms on localhost (executor driver) (2/4)
2018-12-31 07:40:29 INFO  Executor:54 - Finished task 2.0 in stage 1.0 (TID 6). 1784 bytes result sent to driver
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:40:29 INFO  Executor:54 - Running task 3.0 in stage 1.0 (TID 7)
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Finished task 2.0 in stage 1.0 (TID 6) in 10 ms on localhost (executor driver) (3/4)
2018-12-31 07:40:29 INFO  Executor:54 - Finished task 3.0 in stage 1.0 (TID 7). 1741 bytes result sent to driver
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Finished task 3.0 in stage 1.0 (TID 7) in 8 ms on localhost (executor driver) (4/4)
2018-12-31 07:40:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-12-31 07:40:29 INFO  DAGScheduler:54 - ResultStage 1 (run at ThreadPoolExecutor.java:1142) finished in 0.058 s
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Job 1 finished: run at ThreadPoolExecutor.java:1142, took 0.063475 s
2018-12-31 07:40:29 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 216.0 B, free 1994.1 MB)
2018-12-31 07:40:29 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 252.0 B, free 1994.1 MB)
2018-12-31 07:40:29 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:52637 (size: 252.0 B, free: 1996.2 MB)
2018-12-31 07:40:29 INFO  SparkContext:54 - Created broadcast 2 from run at ThreadPoolExecutor.java:1142
2018-12-31 07:40:29 INFO  CodeGenerator:54 - Code generated in 16.9246 ms
2018-12-31 07:40:29 INFO  CodeGenerator:54 - Code generated in 18.5478 ms
2018-12-31 07:40:29 INFO  CodeGenerator:54 - Code generated in 17.2632 ms
2018-12-31 07:40:29 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:135
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Got job 2 (show at CustomizedStagesTest.java:135) with 1 output partitions
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (show at CustomizedStagesTest.java:135)
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:135), which has no missing parents
2018-12-31 07:40:29 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 2.0 MB, free 1992.0 MB)
2018-12-31 07:40:29 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 28.0 KB, free 1992.0 MB)
2018-12-31 07:40:29 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:52637 (size: 28.0 KB, free: 1996.1 MB)
2018-12-31 07:40:29 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:135) (first 15 tasks are for partitions Vector(0))
2018-12-31 07:40:29 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:40:29 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 8)
2018-12-31 07:40:29 INFO  CodeGenerator:54 - Code generated in 18.8562 ms
2018-12-31 07:40:29 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 8). 3018 bytes result sent to driver
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 8) in 50 ms on localhost (executor driver) (1/1)
2018-12-31 07:40:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-12-31 07:40:29 INFO  DAGScheduler:54 - ResultStage 2 (show at CustomizedStagesTest.java:135) finished in 0.083 s
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Job 2 finished: show at CustomizedStagesTest.java:135, took 0.084867 s
2018-12-31 07:40:29 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:135
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Got job 3 (show at CustomizedStagesTest.java:135) with 3 output partitions
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (show at CustomizedStagesTest.java:135)
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:135), which has no missing parents
2018-12-31 07:40:29 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 2.0 MB, free 1990.0 MB)
2018-12-31 07:40:29 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 28.0 KB, free 1989.9 MB)
2018-12-31 07:40:29 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:52637 (size: 28.0 KB, free: 1996.1 MB)
2018-12-31 07:40:29 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:135) (first 15 tasks are for partitions Vector(1, 2, 3))
2018-12-31 07:40:29 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 3 tasks
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:40:29 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 9)
2018-12-31 07:40:29 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 9). 2775 bytes result sent to driver
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:40:29 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 10)
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 9) in 11 ms on localhost (executor driver) (1/3)
2018-12-31 07:40:29 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 10). 2775 bytes result sent to driver
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:40:29 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 11)
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 10) in 13 ms on localhost (executor driver) (2/3)
2018-12-31 07:40:29 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 11). 2775 bytes result sent to driver
2018-12-31 07:40:29 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 11) in 13 ms on localhost (executor driver) (3/3)
2018-12-31 07:40:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-12-31 07:40:29 INFO  DAGScheduler:54 - ResultStage 3 (show at CustomizedStagesTest.java:135) finished in 0.054 s
2018-12-31 07:40:29 INFO  DAGScheduler:54 - Job 3 finished: show at CustomizedStagesTest.java:135, took 0.058548 s
2018-12-31 07:40:41 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-12-31 07:40:41 INFO  AbstractConnector:318 - Stopped Spark@3a175162{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:40:41 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2018-12-31 07:40:41 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-12-31 07:40:41 INFO  MemoryStore:54 - MemoryStore cleared
2018-12-31 07:40:41 INFO  BlockManager:54 - BlockManager stopped
2018-12-31 07:40:41 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-12-31 07:40:41 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-12-31 07:40:41 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-12-31 07:40:41 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-12-31 07:40:41 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-c9d1c6a3-ff30-43e4-af9b-fdfb9d09433b
2018-12-31 07:41:23 INFO  SparkContext:54 - Running Spark version 2.3.2
2018-12-31 07:41:24 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-31 07:41:24 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at CustomizedStagesTest.<init>(CustomizedStagesTest.java:29)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-31 07:41:24 INFO  SparkContext:54 - Submitted application: SparkTest
2018-12-31 07:41:24 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2018-12-31 07:41:24 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2018-12-31 07:41:24 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-12-31 07:41:24 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-12-31 07:41:24 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2018-12-31 07:41:25 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 52762.
2018-12-31 07:41:25 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-12-31 07:41:25 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-12-31 07:41:25 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-31 07:41:25 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-12-31 07:41:25 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-3af57ce3-dbbc-41b2-8edc-f505342a72a6
2018-12-31 07:41:25 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2018-12-31 07:41:25 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-12-31 07:41:25 INFO  log:192 - Logging initialized @7218ms
2018-12-31 07:41:25 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2018-12-31 07:41:25 INFO  Server:419 - Started @7277ms
2018-12-31 07:41:25 INFO  AbstractConnector:278 - Started ServerConnector@2f08c4b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:41:25 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/jobs,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54107f42{/jobs/json,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs/job,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cea706c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/stages,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/stages/json,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1eba372c{/stages/stage,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@552518c3{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/pool,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59aa20b3{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@363f6148{/storage,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b21844c{/storage/json,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b28f282{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@138fe6ec{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e77f0f4{/environment,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@19b30c92{/environment/json,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@455351c4{/executors,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29876704{/executors/json,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4816c290{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4940809c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16423501{/static,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6de54b40{/,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43ed0ff3{/api,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6691490c{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2187fff7{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-31 07:41:25 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2018-12-31 07:41:25 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-12-31 07:41:25 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52775.
2018-12-31 07:41:25 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:52775
2018-12-31 07:41:25 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-31 07:41:25 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 52775, None)
2018-12-31 07:41:25 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:52775 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 52775, None)
2018-12-31 07:41:25 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 52775, None)
2018-12-31 07:41:25 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 52775, None)
2018-12-31 07:41:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/metrics/json,null,AVAILABLE,@Spark}
2018-12-31 07:41:26 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2018-12-31 07:41:26 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2018-12-31 07:41:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@460b6d54{/SQL,null,AVAILABLE,@Spark}
2018-12-31 07:41:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5cf87cfd{/SQL/json,null,AVAILABLE,@Spark}
2018-12-31 07:41:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383790cf{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-31 07:41:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74971ed9{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-31 07:41:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29fc1a2b{/static/sql,null,AVAILABLE,@Spark}
2018-12-31 07:41:26 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2018-12-31 07:41:28 INFO  CodeGenerator:54 - Code generated in 233.3347 ms
2018-12-31 07:41:28 INFO  CodeGenerator:54 - Code generated in 10.632 ms
2018-12-31 07:41:29 INFO  CodeGenerator:54 - Code generated in 22.9269 ms
2018-12-31 07:41:29 INFO  CodeGenerator:54 - Code generated in 19.0026 ms
2018-12-31 07:41:29 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2018-12-31 07:41:29 INFO  DAGScheduler:54 - Got job 0 (treeAggregate at IDF.scala:54) with 4 output partitions
2018-12-31 07:41:29 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (treeAggregate at IDF.scala:54)
2018-12-31 07:41:29 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:41:29 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:41:29 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54), which has no missing parents
2018-12-31 07:41:29 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 38.4 KB, free 1996.2 MB)
2018-12-31 07:41:29 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1996.2 MB)
2018-12-31 07:41:29 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:52775 (size: 10.2 KB, free: 1996.2 MB)
2018-12-31 07:41:29 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:41:29 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:41:29 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 4 tasks
2018-12-31 07:41:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:41:29 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2018-12-31 07:41:29 INFO  CodeGenerator:54 - Code generated in 7.405 ms
2018-12-31 07:41:30 INFO  MemoryStore:54 - Block taskresult_0 stored as bytes in memory (estimated size 2.0 MB, free 1994.1 MB)
2018-12-31 07:41:30 INFO  BlockManagerInfo:54 - Added taskresult_0 in memory on AshCloud-D1:52775 (size: 2.0 MB, free: 1994.2 MB)
2018-12-31 07:41:30 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2109347 bytes result sent via BlockManager)
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:41:30 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2018-12-31 07:41:30 INFO  Executor:54 - Finished task 1.0 in stage 0.0 (TID 1). 1634 bytes result sent to driver
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:41:30 INFO  Executor:54 - Running task 2.0 in stage 0.0 (TID 2)
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 14 ms on localhost (executor driver) (1/4)
2018-12-31 07:41:30 INFO  Executor:54 - Finished task 2.0 in stage 0.0 (TID 2). 1677 bytes result sent to driver
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:41:30 INFO  Executor:54 - Running task 3.0 in stage 0.0 (TID 3)
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Finished task 2.0 in stage 0.0 (TID 2) in 19 ms on localhost (executor driver) (2/4)
2018-12-31 07:41:30 INFO  Executor:54 - Finished task 3.0 in stage 0.0 (TID 3). 1677 bytes result sent to driver
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Finished task 3.0 in stage 0.0 (TID 3) in 17 ms on localhost (executor driver) (3/4)
2018-12-31 07:41:30 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:52775 after 40 ms (0 ms spent in bootstraps)
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 615 ms on localhost (executor driver) (4/4)
2018-12-31 07:41:30 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-12-31 07:41:30 INFO  DAGScheduler:54 - ResultStage 0 (treeAggregate at IDF.scala:54) finished in 0.779 s
2018-12-31 07:41:30 INFO  BlockManagerInfo:54 - Removed taskresult_0 on AshCloud-D1:52775 in memory (size: 2.0 MB, free: 1996.2 MB)
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Job 0 finished: treeAggregate at IDF.scala:54, took 0.825476 s
2018-12-31 07:41:30 INFO  CodeGenerator:54 - Code generated in 13.493 ms
2018-12-31 07:41:30 INFO  CodeGenerator:54 - Code generated in 20.7853 ms
2018-12-31 07:41:30 INFO  CodeGenerator:54 - Code generated in 22.7696 ms
2018-12-31 07:41:30 INFO  CodeGenerator:54 - Code generated in 18.6394 ms
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 17
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 16
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 13
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 14
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 31
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 25
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 32
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 10
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 21
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 34
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 24
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 28
2018-12-31 07:41:30 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on AshCloud-D1:52775 in memory (size: 10.2 KB, free: 1996.2 MB)
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 20
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 22
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 33
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 23
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 11
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 30
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 27
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 15
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 26
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 18
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 29
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 19
2018-12-31 07:41:30 INFO  ContextCleaner:54 - Cleaned accumulator 12
2018-12-31 07:41:30 INFO  CodeGenerator:54 - Code generated in 19.7255 ms
2018-12-31 07:41:30 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1142
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Got job 1 (run at ThreadPoolExecutor.java:1142) with 4 output partitions
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (run at ThreadPoolExecutor.java:1142)
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-12-31 07:41:30 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 2.0 MB, free 1994.2 MB)
2018-12-31 07:41:30 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 22.7 KB, free 1994.1 MB)
2018-12-31 07:41:30 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:52775 (size: 22.7 KB, free: 1996.2 MB)
2018-12-31 07:41:30 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:41:30 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 4 tasks
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:41:30 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 4)
2018-12-31 07:41:30 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 4). 1859 bytes result sent to driver
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:41:30 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 5)
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 4) in 14 ms on localhost (executor driver) (1/4)
2018-12-31 07:41:30 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 5). 1784 bytes result sent to driver
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:41:30 INFO  Executor:54 - Running task 2.0 in stage 1.0 (TID 6)
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 5) in 7 ms on localhost (executor driver) (2/4)
2018-12-31 07:41:30 INFO  Executor:54 - Finished task 2.0 in stage 1.0 (TID 6). 1741 bytes result sent to driver
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:41:30 INFO  Executor:54 - Running task 3.0 in stage 1.0 (TID 7)
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Finished task 2.0 in stage 1.0 (TID 6) in 11 ms on localhost (executor driver) (3/4)
2018-12-31 07:41:30 INFO  Executor:54 - Finished task 3.0 in stage 1.0 (TID 7). 1784 bytes result sent to driver
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Finished task 3.0 in stage 1.0 (TID 7) in 8 ms on localhost (executor driver) (4/4)
2018-12-31 07:41:30 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-12-31 07:41:30 INFO  DAGScheduler:54 - ResultStage 1 (run at ThreadPoolExecutor.java:1142) finished in 0.050 s
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Job 1 finished: run at ThreadPoolExecutor.java:1142, took 0.052937 s
2018-12-31 07:41:30 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 216.0 B, free 1994.1 MB)
2018-12-31 07:41:30 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 252.0 B, free 1994.1 MB)
2018-12-31 07:41:30 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:52775 (size: 252.0 B, free: 1996.2 MB)
2018-12-31 07:41:30 INFO  SparkContext:54 - Created broadcast 2 from run at ThreadPoolExecutor.java:1142
2018-12-31 07:41:30 INFO  CodeGenerator:54 - Code generated in 17.487 ms
2018-12-31 07:41:30 INFO  CodeGenerator:54 - Code generated in 21.1921 ms
2018-12-31 07:41:30 INFO  CodeGenerator:54 - Code generated in 14.7259 ms
2018-12-31 07:41:30 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:140
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Got job 2 (show at CustomizedStagesTest.java:140) with 1 output partitions
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (show at CustomizedStagesTest.java:140)
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:140), which has no missing parents
2018-12-31 07:41:30 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 2.1 MB, free 1992.1 MB)
2018-12-31 07:41:30 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 28.9 KB, free 1992.1 MB)
2018-12-31 07:41:30 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:52775 (size: 28.9 KB, free: 1996.1 MB)
2018-12-31 07:41:30 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:140) (first 15 tasks are for partitions Vector(0))
2018-12-31 07:41:30 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:41:30 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 8)
2018-12-31 07:41:30 INFO  CodeGenerator:54 - Code generated in 17.1196 ms
2018-12-31 07:41:30 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 8). 3061 bytes result sent to driver
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 8) in 46 ms on localhost (executor driver) (1/1)
2018-12-31 07:41:30 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-12-31 07:41:30 INFO  DAGScheduler:54 - ResultStage 2 (show at CustomizedStagesTest.java:140) finished in 0.070 s
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Job 2 finished: show at CustomizedStagesTest.java:140, took 0.073323 s
2018-12-31 07:41:30 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:140
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Got job 3 (show at CustomizedStagesTest.java:140) with 3 output partitions
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (show at CustomizedStagesTest.java:140)
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:140), which has no missing parents
2018-12-31 07:41:30 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 2.1 MB, free 1990.0 MB)
2018-12-31 07:41:30 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.0 KB, free 1990.0 MB)
2018-12-31 07:41:30 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:52775 (size: 29.0 KB, free: 1996.1 MB)
2018-12-31 07:41:30 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:140) (first 15 tasks are for partitions Vector(1, 2, 3))
2018-12-31 07:41:30 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 3 tasks
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:41:30 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 9)
2018-12-31 07:41:30 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 9). 2775 bytes result sent to driver
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:41:30 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 10)
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 9) in 12 ms on localhost (executor driver) (1/3)
2018-12-31 07:41:30 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 10). 2775 bytes result sent to driver
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:41:30 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 11)
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 10) in 14 ms on localhost (executor driver) (2/3)
2018-12-31 07:41:30 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 11). 2732 bytes result sent to driver
2018-12-31 07:41:30 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 11) in 14 ms on localhost (executor driver) (3/3)
2018-12-31 07:41:30 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-12-31 07:41:30 INFO  DAGScheduler:54 - ResultStage 3 (show at CustomizedStagesTest.java:140) finished in 0.055 s
2018-12-31 07:41:30 INFO  DAGScheduler:54 - Job 3 finished: show at CustomizedStagesTest.java:140, took 0.059115 s
2018-12-31 07:41:30 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-12-31 07:41:30 INFO  AbstractConnector:318 - Stopped Spark@2f08c4b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:41:30 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2018-12-31 07:41:30 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-12-31 07:41:31 INFO  MemoryStore:54 - MemoryStore cleared
2018-12-31 07:41:31 INFO  BlockManager:54 - BlockManager stopped
2018-12-31 07:41:31 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-12-31 07:41:31 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-12-31 07:41:31 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-12-31 07:41:31 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-12-31 07:41:31 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-f8e7ed15-5bc1-46c1-9321-1b20634c5da8
2018-12-31 07:46:29 INFO  SparkContext:54 - Running Spark version 2.3.2
2018-12-31 07:46:29 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-31 07:46:29 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at CustomizedStagesTest.<init>(CustomizedStagesTest.java:29)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-31 07:46:30 INFO  SparkContext:54 - Submitted application: SparkTest
2018-12-31 07:46:30 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2018-12-31 07:46:30 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2018-12-31 07:46:30 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-12-31 07:46:30 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-12-31 07:46:30 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2018-12-31 07:46:31 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 53283.
2018-12-31 07:46:31 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-12-31 07:46:31 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-12-31 07:46:31 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-31 07:46:31 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-12-31 07:46:31 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-c7b02614-9a8a-4d42-904e-731eaca351fd
2018-12-31 07:46:31 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2018-12-31 07:46:31 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-12-31 07:46:31 INFO  log:192 - Logging initialized @7326ms
2018-12-31 07:46:31 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2018-12-31 07:46:31 INFO  Server:419 - Started @7389ms
2018-12-31 07:46:31 INFO  AbstractConnector:278 - Started ServerConnector@2f08c4b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:46:31 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/jobs,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54107f42{/jobs/json,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs/job,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cea706c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/stages,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/stages/json,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1eba372c{/stages/stage,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@552518c3{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/pool,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59aa20b3{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@363f6148{/storage,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b21844c{/storage/json,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b28f282{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@138fe6ec{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e77f0f4{/environment,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@19b30c92{/environment/json,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@455351c4{/executors,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29876704{/executors/json,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4816c290{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4940809c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16423501{/static,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6de54b40{/,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43ed0ff3{/api,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6691490c{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2187fff7{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-31 07:46:31 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2018-12-31 07:46:31 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-12-31 07:46:31 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53296.
2018-12-31 07:46:31 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:53296
2018-12-31 07:46:31 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-31 07:46:31 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 53296, None)
2018-12-31 07:46:31 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:53296 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 53296, None)
2018-12-31 07:46:31 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 53296, None)
2018-12-31 07:46:31 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 53296, None)
2018-12-31 07:46:31 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/metrics/json,null,AVAILABLE,@Spark}
2018-12-31 07:46:32 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2018-12-31 07:46:32 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2018-12-31 07:46:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@460b6d54{/SQL,null,AVAILABLE,@Spark}
2018-12-31 07:46:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5cf87cfd{/SQL/json,null,AVAILABLE,@Spark}
2018-12-31 07:46:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383790cf{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-31 07:46:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74971ed9{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-31 07:46:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29fc1a2b{/static/sql,null,AVAILABLE,@Spark}
2018-12-31 07:46:32 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2018-12-31 07:46:34 INFO  CodeGenerator:54 - Code generated in 213.4236 ms
2018-12-31 07:46:34 INFO  CodeGenerator:54 - Code generated in 13.2064 ms
2018-12-31 07:46:34 INFO  ContextCleaner:54 - Cleaned accumulator 0
2018-12-31 07:46:35 INFO  ContextCleaner:54 - Cleaned accumulator 1
2018-12-31 07:46:35 INFO  CodeGenerator:54 - Code generated in 37.6552 ms
2018-12-31 07:46:35 INFO  CodeGenerator:54 - Code generated in 23.338 ms
2018-12-31 07:46:35 INFO  CodeGenerator:54 - Code generated in 18.7022 ms
2018-12-31 07:46:35 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2018-12-31 07:46:35 INFO  DAGScheduler:54 - Got job 0 (treeAggregate at IDF.scala:54) with 4 output partitions
2018-12-31 07:46:35 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (treeAggregate at IDF.scala:54)
2018-12-31 07:46:35 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:46:35 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:46:35 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54), which has no missing parents
2018-12-31 07:46:35 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 38.4 KB, free 1996.2 MB)
2018-12-31 07:46:35 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1996.2 MB)
2018-12-31 07:46:35 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:53296 (size: 10.2 KB, free: 1996.2 MB)
2018-12-31 07:46:35 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:46:35 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:46:35 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 4 tasks
2018-12-31 07:46:35 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:46:35 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2018-12-31 07:46:35 INFO  CodeGenerator:54 - Code generated in 6.8062 ms
2018-12-31 07:46:36 INFO  MemoryStore:54 - Block taskresult_0 stored as bytes in memory (estimated size 2.0 MB, free 1994.1 MB)
2018-12-31 07:46:36 INFO  BlockManagerInfo:54 - Added taskresult_0 in memory on AshCloud-D1:53296 (size: 2.0 MB, free: 1994.2 MB)
2018-12-31 07:46:36 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2109347 bytes result sent via BlockManager)
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:46:36 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2018-12-31 07:46:36 INFO  Executor:54 - Finished task 1.0 in stage 0.0 (TID 1). 1634 bytes result sent to driver
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:46:36 INFO  Executor:54 - Running task 2.0 in stage 0.0 (TID 2)
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 17 ms on localhost (executor driver) (1/4)
2018-12-31 07:46:36 INFO  Executor:54 - Finished task 2.0 in stage 0.0 (TID 2). 1634 bytes result sent to driver
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:46:36 INFO  Executor:54 - Running task 3.0 in stage 0.0 (TID 3)
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Finished task 2.0 in stage 0.0 (TID 2) in 18 ms on localhost (executor driver) (2/4)
2018-12-31 07:46:36 INFO  Executor:54 - Finished task 3.0 in stage 0.0 (TID 3). 1634 bytes result sent to driver
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Finished task 3.0 in stage 0.0 (TID 3) in 14 ms on localhost (executor driver) (3/4)
2018-12-31 07:46:36 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:53296 after 41 ms (0 ms spent in bootstraps)
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 627 ms on localhost (executor driver) (4/4)
2018-12-31 07:46:36 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-12-31 07:46:36 INFO  DAGScheduler:54 - ResultStage 0 (treeAggregate at IDF.scala:54) finished in 0.783 s
2018-12-31 07:46:36 INFO  BlockManagerInfo:54 - Removed taskresult_0 on AshCloud-D1:53296 in memory (size: 2.0 MB, free: 1996.2 MB)
2018-12-31 07:46:36 INFO  DAGScheduler:54 - Job 0 finished: treeAggregate at IDF.scala:54, took 0.822317 s
2018-12-31 07:46:36 INFO  CodeGenerator:54 - Code generated in 7.846 ms
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 33
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 28
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 13
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 29
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 31
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 12
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 34
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 25
2018-12-31 07:46:36 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on AshCloud-D1:53296 in memory (size: 10.2 KB, free: 1996.2 MB)
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 36
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 26
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 22
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 24
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 17
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 14
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 30
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 27
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 20
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 35
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 18
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 21
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 32
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 23
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 15
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 16
2018-12-31 07:46:36 INFO  ContextCleaner:54 - Cleaned accumulator 19
2018-12-31 07:46:36 INFO  CodeGenerator:54 - Code generated in 33.2611 ms
2018-12-31 07:46:36 INFO  CodeGenerator:54 - Code generated in 21.8383 ms
2018-12-31 07:46:36 INFO  CodeGenerator:54 - Code generated in 12.2734 ms
2018-12-31 07:46:36 INFO  CodeGenerator:54 - Code generated in 21.6842 ms
2018-12-31 07:46:36 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1142
2018-12-31 07:46:36 INFO  DAGScheduler:54 - Got job 1 (run at ThreadPoolExecutor.java:1142) with 4 output partitions
2018-12-31 07:46:36 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (run at ThreadPoolExecutor.java:1142)
2018-12-31 07:46:36 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:46:36 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:46:36 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-12-31 07:46:36 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 2.0 MB, free 1994.2 MB)
2018-12-31 07:46:36 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 22.7 KB, free 1994.1 MB)
2018-12-31 07:46:36 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:53296 (size: 22.7 KB, free: 1996.2 MB)
2018-12-31 07:46:36 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:46:36 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:46:36 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 4 tasks
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:46:36 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 4)
2018-12-31 07:46:36 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 4). 1859 bytes result sent to driver
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:46:36 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 5)
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 4) in 15 ms on localhost (executor driver) (1/4)
2018-12-31 07:46:36 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 5). 1784 bytes result sent to driver
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 5) in 6 ms on localhost (executor driver) (2/4)
2018-12-31 07:46:36 INFO  Executor:54 - Running task 2.0 in stage 1.0 (TID 6)
2018-12-31 07:46:36 INFO  Executor:54 - Finished task 2.0 in stage 1.0 (TID 6). 1741 bytes result sent to driver
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:46:36 INFO  Executor:54 - Running task 3.0 in stage 1.0 (TID 7)
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Finished task 2.0 in stage 1.0 (TID 6) in 9 ms on localhost (executor driver) (3/4)
2018-12-31 07:46:36 INFO  Executor:54 - Finished task 3.0 in stage 1.0 (TID 7). 1784 bytes result sent to driver
2018-12-31 07:46:36 INFO  TaskSetManager:54 - Finished task 3.0 in stage 1.0 (TID 7) in 9 ms on localhost (executor driver) (4/4)
2018-12-31 07:46:36 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-12-31 07:46:36 INFO  DAGScheduler:54 - ResultStage 1 (run at ThreadPoolExecutor.java:1142) finished in 0.050 s
2018-12-31 07:46:36 INFO  DAGScheduler:54 - Job 1 finished: run at ThreadPoolExecutor.java:1142, took 0.052350 s
2018-12-31 07:46:36 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 216.0 B, free 1994.1 MB)
2018-12-31 07:46:36 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 252.0 B, free 1994.1 MB)
2018-12-31 07:46:36 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:53296 (size: 252.0 B, free: 1996.2 MB)
2018-12-31 07:46:36 INFO  SparkContext:54 - Created broadcast 2 from run at ThreadPoolExecutor.java:1142
2018-12-31 07:46:36 INFO  CodeGenerator:54 - Code generated in 17.3717 ms
2018-12-31 07:46:37 INFO  CodeGenerator:54 - Code generated in 15.9428 ms
2018-12-31 07:46:37 INFO  CodeGenerator:54 - Code generated in 13.1944 ms
2018-12-31 07:46:37 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:142
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Got job 2 (show at CustomizedStagesTest.java:142) with 1 output partitions
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (show at CustomizedStagesTest.java:142)
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:142), which has no missing parents
2018-12-31 07:46:37 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 2.1 MB, free 1992.1 MB)
2018-12-31 07:46:37 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 28.9 KB, free 1992.1 MB)
2018-12-31 07:46:37 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:53296 (size: 28.9 KB, free: 1996.1 MB)
2018-12-31 07:46:37 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:142) (first 15 tasks are for partitions Vector(0))
2018-12-31 07:46:37 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2018-12-31 07:46:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:46:37 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 8)
2018-12-31 07:46:37 INFO  CodeGenerator:54 - Code generated in 17.7978 ms
2018-12-31 07:46:37 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 8). 3061 bytes result sent to driver
2018-12-31 07:46:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 8) in 46 ms on localhost (executor driver) (1/1)
2018-12-31 07:46:37 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-12-31 07:46:37 INFO  DAGScheduler:54 - ResultStage 2 (show at CustomizedStagesTest.java:142) finished in 0.072 s
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Job 2 finished: show at CustomizedStagesTest.java:142, took 0.075697 s
2018-12-31 07:46:37 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:142
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Got job 3 (show at CustomizedStagesTest.java:142) with 3 output partitions
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (show at CustomizedStagesTest.java:142)
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:142), which has no missing parents
2018-12-31 07:46:37 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 2.1 MB, free 1990.0 MB)
2018-12-31 07:46:37 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.0 KB, free 1990.0 MB)
2018-12-31 07:46:37 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:53296 (size: 29.0 KB, free: 1996.1 MB)
2018-12-31 07:46:37 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:142) (first 15 tasks are for partitions Vector(1, 2, 3))
2018-12-31 07:46:37 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 3 tasks
2018-12-31 07:46:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:46:37 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 9)
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 102
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 64
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 100
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 86
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 111
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 84
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 87
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 95
2018-12-31 07:46:37 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:53296 in memory (size: 22.7 KB, free: 1996.1 MB)
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 82
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 93
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 91
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 107
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 81
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 67
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 97
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 79
2018-12-31 07:46:37 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on AshCloud-D1:53296 in memory (size: 28.9 KB, free: 1996.2 MB)
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 80
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 109
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 89
2018-12-31 07:46:37 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 9). 2818 bytes result sent to driver
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 63
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 92
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 76
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 75
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 98
2018-12-31 07:46:37 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 69
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 94
2018-12-31 07:46:37 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 10)
2018-12-31 07:46:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 9) in 18 ms on localhost (executor driver) (1/3)
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 83
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 101
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 66
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 74
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 112
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 110
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 88
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 90
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 103
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 70
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 68
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 85
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 105
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 73
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 96
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 104
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 71
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 78
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 65
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 72
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 108
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 99
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 77
2018-12-31 07:46:37 INFO  ContextCleaner:54 - Cleaned accumulator 106
2018-12-31 07:46:37 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 10). 2775 bytes result sent to driver
2018-12-31 07:46:37 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:46:37 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 10) in 15 ms on localhost (executor driver) (2/3)
2018-12-31 07:46:37 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 11)
2018-12-31 07:46:37 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 11). 2732 bytes result sent to driver
2018-12-31 07:46:37 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 11) in 13 ms on localhost (executor driver) (3/3)
2018-12-31 07:46:37 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-12-31 07:46:37 INFO  DAGScheduler:54 - ResultStage 3 (show at CustomizedStagesTest.java:142) finished in 0.064 s
2018-12-31 07:46:37 INFO  DAGScheduler:54 - Job 3 finished: show at CustomizedStagesTest.java:142, took 0.066554 s
2018-12-31 07:46:37 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-12-31 07:46:37 INFO  AbstractConnector:318 - Stopped Spark@2f08c4b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:46:37 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2018-12-31 07:46:37 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-12-31 07:46:37 INFO  MemoryStore:54 - MemoryStore cleared
2018-12-31 07:46:37 INFO  BlockManager:54 - BlockManager stopped
2018-12-31 07:46:37 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-12-31 07:46:37 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-12-31 07:46:37 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-12-31 07:46:37 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-12-31 07:46:37 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-a6907d98-e9ad-4e31-a5ae-44341adb5742
2018-12-31 07:47:46 INFO  SparkContext:54 - Running Spark version 2.3.2
2018-12-31 07:47:46 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-31 07:47:46 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at CustomizedStagesTest.<init>(CustomizedStagesTest.java:29)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-31 07:47:46 INFO  SparkContext:54 - Submitted application: SparkTest
2018-12-31 07:47:46 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2018-12-31 07:47:46 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2018-12-31 07:47:46 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-12-31 07:47:46 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-12-31 07:47:46 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2018-12-31 07:47:47 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 53453.
2018-12-31 07:47:47 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-12-31 07:47:47 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-12-31 07:47:47 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-31 07:47:47 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-12-31 07:47:47 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-99ba69c8-50eb-413f-b067-490441cb2c8b
2018-12-31 07:47:47 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2018-12-31 07:47:47 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-12-31 07:47:48 INFO  log:192 - Logging initialized @7176ms
2018-12-31 07:47:48 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2018-12-31 07:47:48 INFO  Server:419 - Started @7233ms
2018-12-31 07:47:48 INFO  AbstractConnector:278 - Started ServerConnector@2f08c4b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:47:48 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/jobs,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54107f42{/jobs/json,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs/job,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cea706c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/stages,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/stages/json,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1eba372c{/stages/stage,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@552518c3{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/pool,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59aa20b3{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@363f6148{/storage,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b21844c{/storage/json,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b28f282{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@138fe6ec{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e77f0f4{/environment,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@19b30c92{/environment/json,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@455351c4{/executors,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29876704{/executors/json,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4816c290{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4940809c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16423501{/static,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6de54b40{/,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43ed0ff3{/api,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6691490c{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2187fff7{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2018-12-31 07:47:48 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-12-31 07:47:48 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53466.
2018-12-31 07:47:48 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:53466
2018-12-31 07:47:48 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-31 07:47:48 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 53466, None)
2018-12-31 07:47:48 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:53466 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 53466, None)
2018-12-31 07:47:48 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 53466, None)
2018-12-31 07:47:48 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 53466, None)
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/metrics/json,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2018-12-31 07:47:48 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@460b6d54{/SQL,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5cf87cfd{/SQL/json,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383790cf{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74971ed9{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-31 07:47:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29fc1a2b{/static/sql,null,AVAILABLE,@Spark}
2018-12-31 07:47:49 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2018-12-31 07:47:51 INFO  CodeGenerator:54 - Code generated in 240.2271 ms
2018-12-31 07:47:51 INFO  CodeGenerator:54 - Code generated in 8.4159 ms
2018-12-31 07:47:51 INFO  CodeGenerator:54 - Code generated in 22.7338 ms
2018-12-31 07:47:51 INFO  CodeGenerator:54 - Code generated in 21.2357 ms
2018-12-31 07:47:51 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2018-12-31 07:47:51 INFO  DAGScheduler:54 - Got job 0 (treeAggregate at IDF.scala:54) with 4 output partitions
2018-12-31 07:47:51 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (treeAggregate at IDF.scala:54)
2018-12-31 07:47:51 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:47:51 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:47:51 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54), which has no missing parents
2018-12-31 07:47:52 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 38.4 KB, free 1996.2 MB)
2018-12-31 07:47:52 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1996.2 MB)
2018-12-31 07:47:52 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:53466 (size: 10.2 KB, free: 1996.2 MB)
2018-12-31 07:47:52 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:47:52 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:47:52 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 4 tasks
2018-12-31 07:47:52 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:47:52 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2018-12-31 07:47:52 INFO  CodeGenerator:54 - Code generated in 7.3671 ms
2018-12-31 07:47:52 INFO  MemoryStore:54 - Block taskresult_0 stored as bytes in memory (estimated size 2.0 MB, free 1994.1 MB)
2018-12-31 07:47:52 INFO  BlockManagerInfo:54 - Added taskresult_0 in memory on AshCloud-D1:53466 (size: 2.0 MB, free: 1994.2 MB)
2018-12-31 07:47:52 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2109347 bytes result sent via BlockManager)
2018-12-31 07:47:52 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:47:52 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2018-12-31 07:47:52 INFO  Executor:54 - Finished task 1.0 in stage 0.0 (TID 1). 1677 bytes result sent to driver
2018-12-31 07:47:52 INFO  TaskSetManager:54 - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:47:52 INFO  Executor:54 - Running task 2.0 in stage 0.0 (TID 2)
2018-12-31 07:47:52 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 18 ms on localhost (executor driver) (1/4)
2018-12-31 07:47:52 INFO  Executor:54 - Finished task 2.0 in stage 0.0 (TID 2). 1677 bytes result sent to driver
2018-12-31 07:47:52 INFO  TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:47:52 INFO  Executor:54 - Running task 3.0 in stage 0.0 (TID 3)
2018-12-31 07:47:52 INFO  TaskSetManager:54 - Finished task 2.0 in stage 0.0 (TID 2) in 16 ms on localhost (executor driver) (2/4)
2018-12-31 07:47:52 INFO  Executor:54 - Finished task 3.0 in stage 0.0 (TID 3). 1677 bytes result sent to driver
2018-12-31 07:47:52 INFO  TaskSetManager:54 - Finished task 3.0 in stage 0.0 (TID 3) in 16 ms on localhost (executor driver) (3/4)
2018-12-31 07:47:52 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:53466 after 40 ms (0 ms spent in bootstraps)
2018-12-31 07:47:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 705 ms on localhost (executor driver) (4/4)
2018-12-31 07:47:52 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-12-31 07:47:52 INFO  DAGScheduler:54 - ResultStage 0 (treeAggregate at IDF.scala:54) finished in 0.858 s
2018-12-31 07:47:52 INFO  BlockManagerInfo:54 - Removed taskresult_0 on AshCloud-D1:53466 in memory (size: 2.0 MB, free: 1996.2 MB)
2018-12-31 07:47:52 INFO  DAGScheduler:54 - Job 0 finished: treeAggregate at IDF.scala:54, took 0.900281 s
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 17
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 11
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 26
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 20
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 29
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 14
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 28
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 25
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 16
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 24
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 10
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 32
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 34
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 15
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 30
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 33
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 31
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 18
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 12
2018-12-31 07:47:53 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on AshCloud-D1:53466 in memory (size: 10.2 KB, free: 1996.2 MB)
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 23
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 19
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 21
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 27
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 13
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 22
2018-12-31 07:47:53 INFO  CodeGenerator:54 - Code generated in 14.0914 ms
2018-12-31 07:47:53 INFO  CodeGenerator:54 - Code generated in 30.8068 ms
2018-12-31 07:47:53 INFO  CodeGenerator:54 - Code generated in 39.367 ms
2018-12-31 07:47:53 INFO  CodeGenerator:54 - Code generated in 25.4294 ms
2018-12-31 07:47:53 INFO  CodeGenerator:54 - Code generated in 24.9768 ms
2018-12-31 07:47:53 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1142
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Got job 1 (run at ThreadPoolExecutor.java:1142) with 4 output partitions
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (run at ThreadPoolExecutor.java:1142)
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-12-31 07:47:53 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 2.1 MB, free 1994.1 MB)
2018-12-31 07:47:53 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 26.6 KB, free 1994.1 MB)
2018-12-31 07:47:53 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:53466 (size: 26.6 KB, free: 1996.2 MB)
2018-12-31 07:47:53 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:47:53 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 4 tasks
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:47:53 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 4)
2018-12-31 07:47:53 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 4). 1941 bytes result sent to driver
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:47:53 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 5)
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 4) in 16 ms on localhost (executor driver) (1/4)
2018-12-31 07:47:53 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 5). 1741 bytes result sent to driver
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:47:53 INFO  Executor:54 - Running task 2.0 in stage 1.0 (TID 6)
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 5) in 7 ms on localhost (executor driver) (2/4)
2018-12-31 07:47:53 INFO  Executor:54 - Finished task 2.0 in stage 1.0 (TID 6). 1784 bytes result sent to driver
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:47:53 INFO  Executor:54 - Running task 3.0 in stage 1.0 (TID 7)
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Finished task 2.0 in stage 1.0 (TID 6) in 7 ms on localhost (executor driver) (3/4)
2018-12-31 07:47:53 INFO  Executor:54 - Finished task 3.0 in stage 1.0 (TID 7). 1741 bytes result sent to driver
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Finished task 3.0 in stage 1.0 (TID 7) in 7 ms on localhost (executor driver) (4/4)
2018-12-31 07:47:53 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-12-31 07:47:53 INFO  DAGScheduler:54 - ResultStage 1 (run at ThreadPoolExecutor.java:1142) finished in 0.048 s
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Job 1 finished: run at ThreadPoolExecutor.java:1142, took 0.051835 s
2018-12-31 07:47:53 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 416.0 B, free 1994.1 MB)
2018-12-31 07:47:53 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 335.0 B, free 1994.1 MB)
2018-12-31 07:47:53 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:53466 (size: 335.0 B, free: 1996.2 MB)
2018-12-31 07:47:53 INFO  SparkContext:54 - Created broadcast 2 from run at ThreadPoolExecutor.java:1142
2018-12-31 07:47:53 INFO  CodeGenerator:54 - Code generated in 29.8429 ms
2018-12-31 07:47:53 INFO  CodeGenerator:54 - Code generated in 18.9865 ms
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 64
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 69
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 79
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 67
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 76
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 63
2018-12-31 07:47:53 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:53466 in memory (size: 26.6 KB, free: 1996.2 MB)
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 81
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 66
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 74
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 73
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 75
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 61
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 83
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 70
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 84
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 65
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 68
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 71
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 80
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 82
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 85
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 78
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 62
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 77
2018-12-31 07:47:53 INFO  ContextCleaner:54 - Cleaned accumulator 72
2018-12-31 07:47:53 INFO  CodeGenerator:54 - Code generated in 24.7628 ms
2018-12-31 07:47:53 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:141
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Got job 2 (show at CustomizedStagesTest.java:141) with 1 output partitions
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (show at CustomizedStagesTest.java:141)
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:141), which has no missing parents
2018-12-31 07:47:53 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 2.1 MB, free 1994.1 MB)
2018-12-31 07:47:53 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.1 KB, free 1994.1 MB)
2018-12-31 07:47:53 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:53466 (size: 35.1 KB, free: 1996.2 MB)
2018-12-31 07:47:53 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:141) (first 15 tasks are for partitions Vector(0))
2018-12-31 07:47:53 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:47:53 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 8)
2018-12-31 07:47:53 INFO  CodeGenerator:54 - Code generated in 39.424 ms
2018-12-31 07:47:53 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 8). 3363 bytes result sent to driver
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 8) in 73 ms on localhost (executor driver) (1/1)
2018-12-31 07:47:53 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-12-31 07:47:53 INFO  DAGScheduler:54 - ResultStage 2 (show at CustomizedStagesTest.java:141) finished in 0.106 s
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Job 2 finished: show at CustomizedStagesTest.java:141, took 0.109614 s
2018-12-31 07:47:53 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:141
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Got job 3 (show at CustomizedStagesTest.java:141) with 3 output partitions
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (show at CustomizedStagesTest.java:141)
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:141), which has no missing parents
2018-12-31 07:47:53 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 2.1 MB, free 1992.0 MB)
2018-12-31 07:47:53 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.1 KB, free 1992.0 MB)
2018-12-31 07:47:53 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:53466 (size: 35.1 KB, free: 1996.1 MB)
2018-12-31 07:47:53 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:141) (first 15 tasks are for partitions Vector(1, 2, 3))
2018-12-31 07:47:53 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 3 tasks
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:47:53 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 9)
2018-12-31 07:47:53 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 9). 2775 bytes result sent to driver
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:47:53 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 10)
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 9) in 12 ms on localhost (executor driver) (1/3)
2018-12-31 07:47:53 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 10). 2775 bytes result sent to driver
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 10) in 14 ms on localhost (executor driver) (2/3)
2018-12-31 07:47:53 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 11)
2018-12-31 07:47:53 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 11). 2775 bytes result sent to driver
2018-12-31 07:47:53 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 11) in 16 ms on localhost (executor driver) (3/3)
2018-12-31 07:47:53 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-12-31 07:47:53 INFO  DAGScheduler:54 - ResultStage 3 (show at CustomizedStagesTest.java:141) finished in 0.056 s
2018-12-31 07:47:53 INFO  DAGScheduler:54 - Job 3 finished: show at CustomizedStagesTest.java:141, took 0.058982 s
2018-12-31 07:47:53 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-12-31 07:47:53 INFO  AbstractConnector:318 - Stopped Spark@2f08c4b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:47:53 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2018-12-31 07:47:53 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-12-31 07:47:53 INFO  MemoryStore:54 - MemoryStore cleared
2018-12-31 07:47:53 INFO  BlockManager:54 - BlockManager stopped
2018-12-31 07:47:53 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-12-31 07:47:53 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-12-31 07:47:53 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-12-31 07:47:53 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-12-31 07:47:53 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-99364875-fcfb-418c-b269-31833e8f8fd8
2018-12-31 07:48:21 INFO  SparkContext:54 - Running Spark version 2.3.2
2018-12-31 07:48:21 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-31 07:48:21 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at CustomizedStagesTest.<init>(CustomizedStagesTest.java:29)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-31 07:48:22 INFO  SparkContext:54 - Submitted application: SparkTest
2018-12-31 07:48:22 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2018-12-31 07:48:22 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2018-12-31 07:48:22 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-12-31 07:48:22 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-12-31 07:48:22 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2018-12-31 07:48:23 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 53554.
2018-12-31 07:48:23 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-12-31 07:48:23 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-12-31 07:48:23 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-31 07:48:23 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-12-31 07:48:23 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-452cd4ff-86e6-4aa1-b7c8-fbb754db51a5
2018-12-31 07:48:23 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2018-12-31 07:48:23 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-12-31 07:48:23 INFO  log:192 - Logging initialized @7469ms
2018-12-31 07:48:23 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2018-12-31 07:48:23 INFO  Server:419 - Started @7539ms
2018-12-31 07:48:23 INFO  AbstractConnector:278 - Started ServerConnector@2f08c4b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:48:23 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/jobs,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54107f42{/jobs/json,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs/job,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cea706c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/stages,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/stages/json,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1eba372c{/stages/stage,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@552518c3{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/pool,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59aa20b3{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@363f6148{/storage,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b21844c{/storage/json,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b28f282{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@138fe6ec{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e77f0f4{/environment,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@19b30c92{/environment/json,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@455351c4{/executors,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29876704{/executors/json,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4816c290{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4940809c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16423501{/static,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6de54b40{/,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43ed0ff3{/api,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6691490c{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2187fff7{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-31 07:48:23 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2018-12-31 07:48:23 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-12-31 07:48:23 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53568.
2018-12-31 07:48:23 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:53568
2018-12-31 07:48:23 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-31 07:48:23 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 53568, None)
2018-12-31 07:48:23 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:53568 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 53568, None)
2018-12-31 07:48:23 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 53568, None)
2018-12-31 07:48:23 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 53568, None)
2018-12-31 07:48:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/metrics/json,null,AVAILABLE,@Spark}
2018-12-31 07:48:24 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2018-12-31 07:48:24 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2018-12-31 07:48:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@460b6d54{/SQL,null,AVAILABLE,@Spark}
2018-12-31 07:48:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5cf87cfd{/SQL/json,null,AVAILABLE,@Spark}
2018-12-31 07:48:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383790cf{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-31 07:48:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74971ed9{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-31 07:48:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29fc1a2b{/static/sql,null,AVAILABLE,@Spark}
2018-12-31 07:48:24 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2018-12-31 07:48:27 INFO  CodeGenerator:54 - Code generated in 223.2957 ms
2018-12-31 07:48:27 INFO  CodeGenerator:54 - Code generated in 10.4759 ms
2018-12-31 07:48:27 INFO  CodeGenerator:54 - Code generated in 26.9294 ms
2018-12-31 07:48:27 INFO  CodeGenerator:54 - Code generated in 20.8376 ms
2018-12-31 07:48:27 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2018-12-31 07:48:27 INFO  DAGScheduler:54 - Got job 0 (treeAggregate at IDF.scala:54) with 4 output partitions
2018-12-31 07:48:27 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (treeAggregate at IDF.scala:54)
2018-12-31 07:48:27 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:48:27 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:48:27 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54), which has no missing parents
2018-12-31 07:48:27 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 38.4 KB, free 1996.2 MB)
2018-12-31 07:48:27 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1996.2 MB)
2018-12-31 07:48:27 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:53568 (size: 10.2 KB, free: 1996.2 MB)
2018-12-31 07:48:27 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:48:27 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:48:27 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 4 tasks
2018-12-31 07:48:27 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:48:27 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2018-12-31 07:48:27 INFO  CodeGenerator:54 - Code generated in 6.8021 ms
2018-12-31 07:48:28 INFO  MemoryStore:54 - Block taskresult_0 stored as bytes in memory (estimated size 2.0 MB, free 1994.1 MB)
2018-12-31 07:48:28 INFO  BlockManagerInfo:54 - Added taskresult_0 in memory on AshCloud-D1:53568 (size: 2.0 MB, free: 1994.2 MB)
2018-12-31 07:48:28 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2109347 bytes result sent via BlockManager)
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:48:28 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2018-12-31 07:48:28 INFO  Executor:54 - Finished task 1.0 in stage 0.0 (TID 1). 1634 bytes result sent to driver
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:48:28 INFO  Executor:54 - Running task 2.0 in stage 0.0 (TID 2)
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 15 ms on localhost (executor driver) (1/4)
2018-12-31 07:48:28 INFO  Executor:54 - Finished task 2.0 in stage 0.0 (TID 2). 1634 bytes result sent to driver
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:48:28 INFO  Executor:54 - Running task 3.0 in stage 0.0 (TID 3)
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Finished task 2.0 in stage 0.0 (TID 2) in 19 ms on localhost (executor driver) (2/4)
2018-12-31 07:48:28 INFO  Executor:54 - Finished task 3.0 in stage 0.0 (TID 3). 1634 bytes result sent to driver
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Finished task 3.0 in stage 0.0 (TID 3) in 15 ms on localhost (executor driver) (3/4)
2018-12-31 07:48:28 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:53568 after 39 ms (0 ms spent in bootstraps)
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 598 ms on localhost (executor driver) (4/4)
2018-12-31 07:48:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-12-31 07:48:28 INFO  DAGScheduler:54 - ResultStage 0 (treeAggregate at IDF.scala:54) finished in 0.752 s
2018-12-31 07:48:28 INFO  BlockManagerInfo:54 - Removed taskresult_0 on AshCloud-D1:53568 in memory (size: 2.0 MB, free: 1996.2 MB)
2018-12-31 07:48:28 INFO  DAGScheduler:54 - Job 0 finished: treeAggregate at IDF.scala:54, took 0.791956 s
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 11
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 14
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 20
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 29
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 12
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 32
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 21
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 22
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 28
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 18
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 27
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 24
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 34
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 16
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 33
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 23
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 26
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 10
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 31
2018-12-31 07:48:28 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on AshCloud-D1:53568 in memory (size: 10.2 KB, free: 1996.2 MB)
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 15
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 13
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 25
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 19
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 30
2018-12-31 07:48:28 INFO  ContextCleaner:54 - Cleaned accumulator 17
2018-12-31 07:48:28 INFO  CodeGenerator:54 - Code generated in 14.1686 ms
2018-12-31 07:48:28 INFO  CodeGenerator:54 - Code generated in 24.4135 ms
2018-12-31 07:48:28 INFO  CodeGenerator:54 - Code generated in 34.0426 ms
2018-12-31 07:48:28 INFO  CodeGenerator:54 - Code generated in 27.4538 ms
2018-12-31 07:48:28 INFO  CodeGenerator:54 - Code generated in 21.3011 ms
2018-12-31 07:48:28 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1142
2018-12-31 07:48:28 INFO  DAGScheduler:54 - Got job 1 (run at ThreadPoolExecutor.java:1142) with 4 output partitions
2018-12-31 07:48:28 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (run at ThreadPoolExecutor.java:1142)
2018-12-31 07:48:28 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:48:28 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:48:28 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-12-31 07:48:28 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 2.1 MB, free 1994.1 MB)
2018-12-31 07:48:28 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 26.6 KB, free 1994.1 MB)
2018-12-31 07:48:28 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:53568 (size: 26.6 KB, free: 1996.2 MB)
2018-12-31 07:48:28 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:48:28 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:48:28 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 4 tasks
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:48:28 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 4)
2018-12-31 07:48:28 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 4). 1941 bytes result sent to driver
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:48:28 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 5)
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 4) in 15 ms on localhost (executor driver) (1/4)
2018-12-31 07:48:28 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 5). 1741 bytes result sent to driver
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:48:28 INFO  Executor:54 - Running task 2.0 in stage 1.0 (TID 6)
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 5) in 6 ms on localhost (executor driver) (2/4)
2018-12-31 07:48:28 INFO  Executor:54 - Finished task 2.0 in stage 1.0 (TID 6). 1741 bytes result sent to driver
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 8156 bytes)
2018-12-31 07:48:28 INFO  Executor:54 - Running task 3.0 in stage 1.0 (TID 7)
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Finished task 2.0 in stage 1.0 (TID 6) in 9 ms on localhost (executor driver) (3/4)
2018-12-31 07:48:28 INFO  Executor:54 - Finished task 3.0 in stage 1.0 (TID 7). 1784 bytes result sent to driver
2018-12-31 07:48:28 INFO  TaskSetManager:54 - Finished task 3.0 in stage 1.0 (TID 7) in 7 ms on localhost (executor driver) (4/4)
2018-12-31 07:48:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-12-31 07:48:28 INFO  DAGScheduler:54 - ResultStage 1 (run at ThreadPoolExecutor.java:1142) finished in 0.047 s
2018-12-31 07:48:28 INFO  DAGScheduler:54 - Job 1 finished: run at ThreadPoolExecutor.java:1142, took 0.050733 s
2018-12-31 07:48:28 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 416.0 B, free 1994.1 MB)
2018-12-31 07:48:28 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 335.0 B, free 1994.1 MB)
2018-12-31 07:48:28 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:53568 (size: 335.0 B, free: 1996.2 MB)
2018-12-31 07:48:28 INFO  SparkContext:54 - Created broadcast 2 from run at ThreadPoolExecutor.java:1142
2018-12-31 07:48:29 INFO  CodeGenerator:54 - Code generated in 26.4917 ms
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 64
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 72
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 67
2018-12-31 07:48:29 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:53568 in memory (size: 26.6 KB, free: 1996.2 MB)
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 85
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 66
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 73
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 68
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 81
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 75
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 71
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 83
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 63
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 62
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 84
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 61
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 77
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 80
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 79
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 78
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 82
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 70
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 76
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 74
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 69
2018-12-31 07:48:29 INFO  ContextCleaner:54 - Cleaned accumulator 65
2018-12-31 07:48:29 INFO  CodeGenerator:54 - Code generated in 25.3019 ms
2018-12-31 07:48:29 INFO  CodeGenerator:54 - Code generated in 17.5105 ms
2018-12-31 07:48:29 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:141
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Got job 2 (show at CustomizedStagesTest.java:141) with 1 output partitions
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (show at CustomizedStagesTest.java:141)
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:141), which has no missing parents
2018-12-31 07:48:29 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 2.1 MB, free 1994.1 MB)
2018-12-31 07:48:29 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.1 KB, free 1994.1 MB)
2018-12-31 07:48:29 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:53568 (size: 35.1 KB, free: 1996.2 MB)
2018-12-31 07:48:29 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:141) (first 15 tasks are for partitions Vector(0))
2018-12-31 07:48:29 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2018-12-31 07:48:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:48:29 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 8)
2018-12-31 07:48:29 INFO  CodeGenerator:54 - Code generated in 23.4694 ms
2018-12-31 07:48:29 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 8). 3363 bytes result sent to driver
2018-12-31 07:48:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 8) in 52 ms on localhost (executor driver) (1/1)
2018-12-31 07:48:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-12-31 07:48:29 INFO  DAGScheduler:54 - ResultStage 2 (show at CustomizedStagesTest.java:141) finished in 0.084 s
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Job 2 finished: show at CustomizedStagesTest.java:141, took 0.086128 s
2018-12-31 07:48:29 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:141
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Got job 3 (show at CustomizedStagesTest.java:141) with 3 output partitions
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (show at CustomizedStagesTest.java:141)
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:141), which has no missing parents
2018-12-31 07:48:29 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 2.1 MB, free 1992.0 MB)
2018-12-31 07:48:29 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.1 KB, free 1992.0 MB)
2018-12-31 07:48:29 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:53568 (size: 35.1 KB, free: 1996.1 MB)
2018-12-31 07:48:29 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:141) (first 15 tasks are for partitions Vector(1, 2, 3))
2018-12-31 07:48:29 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 3 tasks
2018-12-31 07:48:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:48:29 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 9)
2018-12-31 07:48:29 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 9). 2775 bytes result sent to driver
2018-12-31 07:48:29 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:48:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 9) in 13 ms on localhost (executor driver) (1/3)
2018-12-31 07:48:29 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 10)
2018-12-31 07:48:29 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 10). 2775 bytes result sent to driver
2018-12-31 07:48:29 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 3, PROCESS_LOCAL, 8262 bytes)
2018-12-31 07:48:29 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 10) in 14 ms on localhost (executor driver) (2/3)
2018-12-31 07:48:29 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 11)
2018-12-31 07:48:29 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 11). 2775 bytes result sent to driver
2018-12-31 07:48:29 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 11) in 17 ms on localhost (executor driver) (3/3)
2018-12-31 07:48:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-12-31 07:48:29 INFO  DAGScheduler:54 - ResultStage 3 (show at CustomizedStagesTest.java:141) finished in 0.056 s
2018-12-31 07:48:29 INFO  DAGScheduler:54 - Job 3 finished: show at CustomizedStagesTest.java:141, took 0.059350 s
2018-12-31 07:48:29 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-12-31 07:48:29 INFO  AbstractConnector:318 - Stopped Spark@2f08c4b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:48:29 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2018-12-31 07:48:29 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-12-31 07:48:29 INFO  MemoryStore:54 - MemoryStore cleared
2018-12-31 07:48:29 INFO  BlockManager:54 - BlockManager stopped
2018-12-31 07:48:29 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-12-31 07:48:29 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-12-31 07:48:29 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-12-31 07:48:29 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-12-31 07:48:29 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-afd737e9-9dec-48fa-a501-e03adbf628f7
2018-12-31 07:59:53 INFO  SparkContext:54 - Running Spark version 2.3.2
2018-12-31 07:59:54 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-31 07:59:54 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at CustomizedStagesTest.<init>(CustomizedStagesTest.java:29)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-31 07:59:54 INFO  SparkContext:54 - Submitted application: SparkTest
2018-12-31 07:59:54 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2018-12-31 07:59:54 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2018-12-31 07:59:54 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-12-31 07:59:54 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-12-31 07:59:54 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2018-12-31 07:59:55 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 54612.
2018-12-31 07:59:55 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-12-31 07:59:55 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-12-31 07:59:55 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-31 07:59:55 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-12-31 07:59:55 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-f909525f-2afc-45b9-85e6-6b99dc06f9ca
2018-12-31 07:59:55 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2018-12-31 07:59:55 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-12-31 07:59:55 INFO  log:192 - Logging initialized @7401ms
2018-12-31 07:59:55 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2018-12-31 07:59:55 INFO  Server:419 - Started @7460ms
2018-12-31 07:59:55 INFO  AbstractConnector:278 - Started ServerConnector@2f08c4b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 07:59:55 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/jobs,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54107f42{/jobs/json,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs/job,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cea706c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/stages,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/stages/json,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1eba372c{/stages/stage,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@552518c3{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/pool,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59aa20b3{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@363f6148{/storage,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b21844c{/storage/json,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b28f282{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@138fe6ec{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e77f0f4{/environment,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@19b30c92{/environment/json,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@455351c4{/executors,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29876704{/executors/json,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4816c290{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4940809c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16423501{/static,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6de54b40{/,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43ed0ff3{/api,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6691490c{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2187fff7{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-31 07:59:55 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2018-12-31 07:59:55 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-12-31 07:59:55 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54625.
2018-12-31 07:59:55 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:54625
2018-12-31 07:59:55 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-31 07:59:55 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 54625, None)
2018-12-31 07:59:55 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:54625 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 54625, None)
2018-12-31 07:59:55 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 54625, None)
2018-12-31 07:59:55 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 54625, None)
2018-12-31 07:59:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c5a54b7{/metrics/json,null,AVAILABLE,@Spark}
2018-12-31 07:59:56 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2018-12-31 07:59:56 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2018-12-31 07:59:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@460b6d54{/SQL,null,AVAILABLE,@Spark}
2018-12-31 07:59:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5cf87cfd{/SQL/json,null,AVAILABLE,@Spark}
2018-12-31 07:59:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383790cf{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-31 07:59:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74971ed9{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-31 07:59:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29fc1a2b{/static/sql,null,AVAILABLE,@Spark}
2018-12-31 07:59:56 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2018-12-31 07:59:58 INFO  CodeGenerator:54 - Code generated in 226.919 ms
2018-12-31 07:59:58 INFO  CodeGenerator:54 - Code generated in 9.9986 ms
2018-12-31 07:59:58 INFO  CodeGenerator:54 - Code generated in 19.681 ms
2018-12-31 07:59:58 INFO  CodeGenerator:54 - Code generated in 19.9586 ms
2018-12-31 07:59:59 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2018-12-31 07:59:59 INFO  DAGScheduler:54 - Got job 0 (treeAggregate at IDF.scala:54) with 4 output partitions
2018-12-31 07:59:59 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (treeAggregate at IDF.scala:54)
2018-12-31 07:59:59 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 07:59:59 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 07:59:59 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54), which has no missing parents
2018-12-31 07:59:59 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 38.4 KB, free 1996.2 MB)
2018-12-31 07:59:59 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1996.2 MB)
2018-12-31 07:59:59 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:54625 (size: 10.2 KB, free: 1996.2 MB)
2018-12-31 07:59:59 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-12-31 07:59:59 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[15] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 07:59:59 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 4 tasks
2018-12-31 07:59:59 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8270 bytes)
2018-12-31 07:59:59 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2018-12-31 07:59:59 INFO  CodeGenerator:54 - Code generated in 8.2511 ms
2018-12-31 07:59:59 INFO  MemoryStore:54 - Block taskresult_0 stored as bytes in memory (estimated size 2.0 MB, free 1994.1 MB)
2018-12-31 07:59:59 INFO  BlockManagerInfo:54 - Added taskresult_0 in memory on AshCloud-D1:54625 (size: 2.0 MB, free: 1994.2 MB)
2018-12-31 07:59:59 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2109347 bytes result sent via BlockManager)
2018-12-31 07:59:59 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 07:59:59 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2018-12-31 07:59:59 INFO  Executor:54 - Finished task 1.0 in stage 0.0 (TID 1). 1677 bytes result sent to driver
2018-12-31 07:59:59 INFO  TaskSetManager:54 - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8270 bytes)
2018-12-31 07:59:59 INFO  Executor:54 - Running task 2.0 in stage 0.0 (TID 2)
2018-12-31 07:59:59 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 15 ms on localhost (executor driver) (1/4)
2018-12-31 07:59:59 INFO  Executor:54 - Finished task 2.0 in stage 0.0 (TID 2). 1634 bytes result sent to driver
2018-12-31 07:59:59 INFO  TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8270 bytes)
2018-12-31 07:59:59 INFO  Executor:54 - Running task 3.0 in stage 0.0 (TID 3)
2018-12-31 07:59:59 INFO  TaskSetManager:54 - Finished task 2.0 in stage 0.0 (TID 2) in 17 ms on localhost (executor driver) (2/4)
2018-12-31 07:59:59 INFO  Executor:54 - Finished task 3.0 in stage 0.0 (TID 3). 1677 bytes result sent to driver
2018-12-31 07:59:59 INFO  TaskSetManager:54 - Finished task 3.0 in stage 0.0 (TID 3) in 15 ms on localhost (executor driver) (3/4)
2018-12-31 07:59:59 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:54625 after 37 ms (0 ms spent in bootstraps)
2018-12-31 07:59:59 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 614 ms on localhost (executor driver) (4/4)
2018-12-31 07:59:59 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-12-31 07:59:59 INFO  DAGScheduler:54 - ResultStage 0 (treeAggregate at IDF.scala:54) finished in 0.753 s
2018-12-31 07:59:59 INFO  BlockManagerInfo:54 - Removed taskresult_0 on AshCloud-D1:54625 in memory (size: 2.0 MB, free: 1996.2 MB)
2018-12-31 07:59:59 INFO  DAGScheduler:54 - Job 0 finished: treeAggregate at IDF.scala:54, took 0.792960 s
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 26
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 28
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 30
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 14
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 10
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 21
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 32
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 18
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 25
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 31
2018-12-31 08:00:00 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on AshCloud-D1:54625 in memory (size: 10.2 KB, free: 1996.2 MB)
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 34
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 17
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 29
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 12
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 22
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 23
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 11
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 15
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 20
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 19
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 33
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 16
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 24
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 27
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 13
2018-12-31 08:00:00 INFO  CodeGenerator:54 - Code generated in 13.9494 ms
2018-12-31 08:00:00 INFO  CodeGenerator:54 - Code generated in 27.5426 ms
2018-12-31 08:00:00 INFO  CodeGenerator:54 - Code generated in 39.828 ms
2018-12-31 08:00:00 INFO  CodeGenerator:54 - Code generated in 36.8396 ms
2018-12-31 08:00:00 INFO  CodeGenerator:54 - Code generated in 24.4866 ms
2018-12-31 08:00:00 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1142
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Got job 1 (run at ThreadPoolExecutor.java:1142) with 4 output partitions
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (run at ThreadPoolExecutor.java:1142)
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-12-31 08:00:00 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 2.1 MB, free 1994.1 MB)
2018-12-31 08:00:00 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 26.6 KB, free 1994.1 MB)
2018-12-31 08:00:00 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:54625 (size: 26.6 KB, free: 1996.2 MB)
2018-12-31 08:00:00 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-12-31 08:00:00 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 4 tasks
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8156 bytes)
2018-12-31 08:00:00 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 4)
2018-12-31 08:00:00 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 4). 1941 bytes result sent to driver
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 08:00:00 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 5)
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 4) in 18 ms on localhost (executor driver) (1/4)
2018-12-31 08:00:00 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 5). 1741 bytes result sent to driver
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 8156 bytes)
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 5) in 6 ms on localhost (executor driver) (2/4)
2018-12-31 08:00:00 INFO  Executor:54 - Running task 2.0 in stage 1.0 (TID 6)
2018-12-31 08:00:00 INFO  Executor:54 - Finished task 2.0 in stage 1.0 (TID 6). 1784 bytes result sent to driver
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 8156 bytes)
2018-12-31 08:00:00 INFO  Executor:54 - Running task 3.0 in stage 1.0 (TID 7)
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Finished task 2.0 in stage 1.0 (TID 6) in 10 ms on localhost (executor driver) (3/4)
2018-12-31 08:00:00 INFO  Executor:54 - Finished task 3.0 in stage 1.0 (TID 7). 1741 bytes result sent to driver
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Finished task 3.0 in stage 1.0 (TID 7) in 7 ms on localhost (executor driver) (4/4)
2018-12-31 08:00:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-12-31 08:00:00 INFO  DAGScheduler:54 - ResultStage 1 (run at ThreadPoolExecutor.java:1142) finished in 0.055 s
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Job 1 finished: run at ThreadPoolExecutor.java:1142, took 0.058440 s
2018-12-31 08:00:00 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 416.0 B, free 1994.1 MB)
2018-12-31 08:00:00 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 335.0 B, free 1994.1 MB)
2018-12-31 08:00:00 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:54625 (size: 335.0 B, free: 1996.2 MB)
2018-12-31 08:00:00 INFO  SparkContext:54 - Created broadcast 2 from run at ThreadPoolExecutor.java:1142
2018-12-31 08:00:00 INFO  CodeGenerator:54 - Code generated in 29.9044 ms
2018-12-31 08:00:00 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:54625 in memory (size: 26.6 KB, free: 1996.2 MB)
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 63
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 81
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 70
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 72
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 64
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 77
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 65
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 66
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 85
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 78
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 84
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 75
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 61
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 79
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 74
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 82
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 76
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 62
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 68
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 83
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 67
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 71
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 69
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 80
2018-12-31 08:00:00 INFO  ContextCleaner:54 - Cleaned accumulator 73
2018-12-31 08:00:00 INFO  CodeGenerator:54 - Code generated in 32.9648 ms
2018-12-31 08:00:00 INFO  CodeGenerator:54 - Code generated in 19.5009 ms
2018-12-31 08:00:00 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:141
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Got job 2 (show at CustomizedStagesTest.java:141) with 1 output partitions
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (show at CustomizedStagesTest.java:141)
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:141), which has no missing parents
2018-12-31 08:00:00 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 2.1 MB, free 1994.1 MB)
2018-12-31 08:00:00 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.1 KB, free 1994.1 MB)
2018-12-31 08:00:00 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:54625 (size: 35.1 KB, free: 1996.2 MB)
2018-12-31 08:00:00 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:141) (first 15 tasks are for partitions Vector(0))
2018-12-31 08:00:00 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8270 bytes)
2018-12-31 08:00:00 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 8)
2018-12-31 08:00:00 INFO  CodeGenerator:54 - Code generated in 25.3892 ms
2018-12-31 08:00:00 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 8). 3384 bytes result sent to driver
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 8) in 55 ms on localhost (executor driver) (1/1)
2018-12-31 08:00:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-12-31 08:00:00 INFO  DAGScheduler:54 - ResultStage 2 (show at CustomizedStagesTest.java:141) finished in 0.084 s
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Job 2 finished: show at CustomizedStagesTest.java:141, took 0.087486 s
2018-12-31 08:00:00 INFO  SparkContext:54 - Starting job: show at CustomizedStagesTest.java:141
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Got job 3 (show at CustomizedStagesTest.java:141) with 3 output partitions
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (show at CustomizedStagesTest.java:141)
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:141), which has no missing parents
2018-12-31 08:00:00 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 2.1 MB, free 1992.0 MB)
2018-12-31 08:00:00 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.1 KB, free 1992.0 MB)
2018-12-31 08:00:00 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:54625 (size: 35.1 KB, free: 1996.1 MB)
2018-12-31 08:00:00 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ResultStage 3 (MapPartitionsRDD[45] at show at CustomizedStagesTest.java:141) (first 15 tasks are for partitions Vector(1, 2, 3))
2018-12-31 08:00:00 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 3 tasks
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 7989 bytes)
2018-12-31 08:00:00 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 9)
2018-12-31 08:00:00 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 9). 2775 bytes result sent to driver
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 8270 bytes)
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 9) in 11 ms on localhost (executor driver) (1/3)
2018-12-31 08:00:00 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 10)
2018-12-31 08:00:00 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 10). 2775 bytes result sent to driver
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 3, PROCESS_LOCAL, 8270 bytes)
2018-12-31 08:00:00 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 11)
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 10) in 15 ms on localhost (executor driver) (2/3)
2018-12-31 08:00:00 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 11). 2732 bytes result sent to driver
2018-12-31 08:00:00 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 11) in 14 ms on localhost (executor driver) (3/3)
2018-12-31 08:00:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-12-31 08:00:00 INFO  DAGScheduler:54 - ResultStage 3 (show at CustomizedStagesTest.java:141) finished in 0.053 s
2018-12-31 08:00:00 INFO  DAGScheduler:54 - Job 3 finished: show at CustomizedStagesTest.java:141, took 0.055693 s
2018-12-31 08:00:00 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-12-31 08:00:00 INFO  AbstractConnector:318 - Stopped Spark@2f08c4b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-31 08:00:00 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2018-12-31 08:00:00 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-12-31 08:00:00 INFO  MemoryStore:54 - MemoryStore cleared
2018-12-31 08:00:00 INFO  BlockManager:54 - BlockManager stopped
2018-12-31 08:00:00 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-12-31 08:00:00 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-12-31 08:00:00 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-12-31 08:00:00 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-12-31 08:00:00 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-d09c6601-fcc1-49dc-96ff-63f65975cf33
2019-01-22 14:47:57 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 14:47:57 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 14:47:57 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 14:47:57 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 14:47:57 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 14:47:57 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 14:47:57 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 14:47:57 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 14:47:57 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 14:47:58 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 49226.
2019-01-22 14:47:58 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 14:47:58 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 14:47:58 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 14:47:58 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 14:47:58 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-5301d231-0a15-47e8-abb3-90e5326791a5
2019-01-22 14:47:59 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 14:47:59 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 14:47:59 INFO  log:192 - Logging initialized @7888ms
2019-01-22 14:47:59 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 14:47:59 INFO  Server:419 - Started @7961ms
2019-01-22 14:47:59 INFO  AbstractConnector:278 - Started ServerConnector@7807ac2c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 14:47:59 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32fe9d0a{/jobs,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30ed9c6c{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@782a4fff{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae81e1{/stages,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2fd1731c{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae76500{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54709809{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a2da905{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@24f360b2{/storage,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60cf80e7{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@302fec27{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@770d0ea6{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@48c40605{/environment,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54107f42{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b11ef33{/executors,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@476aac9{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cea706c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a138fc5{/,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@379ab47b{/api,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4e4efc1b{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459f7aa3{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 14:47:59 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 14:47:59 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49239.
2019-01-22 14:47:59 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:49239
2019-01-22 14:47:59 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 14:47:59 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 49239, None)
2019-01-22 14:47:59 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:49239 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 49239, None)
2019-01-22 14:47:59 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 49239, None)
2019-01-22 14:47:59 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 49239, None)
2019-01-22 14:47:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69e308c6{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 14:47:59 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 14:47:59 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 14:48:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7551da2a{/SQL,null,AVAILABLE,@Spark}
2019-01-22 14:48:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@432034a{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 14:48:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69c93ca4{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 14:48:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63da207f{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 14:48:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e9456ae{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 14:48:00 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-22 14:48:02 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:48:02 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-22 14:48:02 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 14:48:02 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:48:02 INFO  CodeGenerator:54 - Code generated in 288.2393 ms
2019-01-22 14:48:03 INFO  CodeGenerator:54 - Code generated in 14.056799 ms
2019-01-22 14:48:03 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-22 14:48:03 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-22 14:48:03 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:49239 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 14:48:03 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-22 14:48:03 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:48:03 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 14:48:03 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 14:48:03 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-22 14:48:03 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 14:48:03 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 14:48:03 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 14:48:03 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-22 14:48:03 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-22 14:48:03 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:49239 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 14:48:03 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-22 14:48:03 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 14:48:03 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-22 14:48:03 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-22 14:48:03 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-22 14:48:03 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 14:48:03 INFO  CodeGenerator:54 - Code generated in 8.8702 ms
2019-01-22 14:48:03 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2019-01-22 14:48:03 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 162 ms on localhost (executor driver) (1/1)
2019-01-22 14:48:03 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-22 14:48:03 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.246 s
2019-01-22 14:48:03 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.302512 s
2019-01-22 14:48:03 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:48:03 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 14:48:03 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 14:48:03 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:48:03 INFO  CodeGenerator:54 - Code generated in 4.424601 ms
2019-01-22 14:48:03 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-22 14:48:03 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-22 14:48:03 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:49239 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 14:48:03 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-22 14:48:03 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:48:04 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:48:04 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-22 14:48:04 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 14:48:04 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:48:04 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 14:48:04 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 14:48:04 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:49239 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:48:04 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-22 14:48:04 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:48:04 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 14:48:04 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-22 14:48:04 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-22 14:48:04 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:49239 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 14:48:04 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 14:48:04 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-22 14:48:04 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-22 14:48:04 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-22 14:48:04 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 14:48:04 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1290 bytes result sent to driver
2019-01-22 14:48:04 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 18 ms on localhost (executor driver) (1/1)
2019-01-22 14:48:04 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-22 14:48:04 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.025 s
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.027842 s
2019-01-22 14:48:04 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:48:04 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 14:48:04 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 14:48:04 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:48:04 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 14:48:04 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 14:48:04 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:49239 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:48:04 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-22 14:48:04 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:48:04 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:48:04 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-22 14:48:04 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 14:48:04 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:48:04 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 14:48:04 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 14:48:04 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:49239 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:48:04 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-22 14:48:04 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:48:04 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 46
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 59
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 26
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 28
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 15
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 66
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 52
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 48
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 41
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 17
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 43
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 60
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 61
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 39
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 71
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 58
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 30
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 65
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 45
2019-01-22 14:48:04 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-22 14:48:04 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-22 14:48:04 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:49239 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 14:48:04 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 14:48:04 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-22 14:48:04 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-22 14:48:04 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-22 14:48:04 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-22 14:48:04 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on AshCloud-D1:49239 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 9
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 12
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 40
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 27
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 10
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 51
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 36
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 44
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 14
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 24
2019-01-22 14:48:04 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on AshCloud-D1:49239 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 6
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 22
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 55
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 19
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 57
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 13
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 38
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 20
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 18
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 23
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 49
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 8
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 37
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 69
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 70
2019-01-22 14:48:04 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on AshCloud-D1:49239 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 14:48:04 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1205 bytes result sent to driver
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 53
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 16
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 29
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 56
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 50
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 25
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 64
2019-01-22 14:48:04 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 24 ms on localhost (executor driver) (1/1)
2019-01-22 14:48:04 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-22 14:48:04 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.051 s
2019-01-22 14:48:04 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.054647 s
2019-01-22 14:48:04 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:49239 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 54
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 42
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 67
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 11
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 62
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 7
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 47
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 63
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 68
2019-01-22 14:48:04 INFO  ContextCleaner:54 - Cleaned accumulator 21
2019-01-22 14:48:04 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:48:04 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 14:48:04 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 14:48:04 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:48:04 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 14:48:04 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 14:48:04 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:49239 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:48:04 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-22 14:48:04 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:48:04 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 14:48:04 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 14:48:04 INFO  column remover:43 - removing column commit_content
2019-01-22 14:48:04 INFO  column remover:43 - removing column issue_content
2019-01-22 14:48:04 INFO  column remover:43 - removing column s_tokens
2019-01-22 14:48:04 INFO  column remover:43 - removing column t_tokens
2019-01-22 14:48:04 INFO  column remover:43 - removing column t_htf
2019-01-22 14:48:04 INFO  column remover:43 - removing column s_htf
2019-01-22 14:48:05 INFO  FileSourceStrategy:54 - Pruning directories with: isnotnull(UDF(UDF(null)))
2019-01-22 14:48:05 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(UDF(UDF(null)))
2019-01-22 14:48:05 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-01-22 14:48:05 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:48:05 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:48:05 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 14:48:05 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_summary: string>
2019-01-22 14:48:05 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:48:05 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:48:05 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(UDF(UDF(commit_content#17)))
2019-01-22 14:48:05 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-22 14:48:05 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:48:05 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:48:05 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 14:48:05 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string>
2019-01-22 14:48:05 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:48:05 INFO  CodeGenerator:54 - Code generated in 31.151701 ms
2019-01-22 14:48:05 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 14:48:05 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 14:48:05 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on AshCloud-D1:49239 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:48:05 INFO  SparkContext:54 - Created broadcast 9 from rdd at IDF.scala:89
2019-01-22 14:48:05 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:48:05 INFO  CodeGenerator:54 - Code generated in 27.3266 ms
2019-01-22 14:48:05 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 14:48:05 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-22 14:48:05 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on AshCloud-D1:49239 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:48:05 INFO  SparkContext:54 - Created broadcast 10 from rdd at IDF.scala:89
2019-01-22 14:48:05 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:48:05 INFO  CodeGenerator:54 - Code generated in 16.095101 ms
2019-01-22 14:48:05 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 220.9 KB, free 1994.6 MB)
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 100
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 105
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 77
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 106
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 93
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 97
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 76
2019-01-22 14:48:05 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on AshCloud-D1:49239 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 103
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 79
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 94
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 87
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 72
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 83
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 96
2019-01-22 14:48:05 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on AshCloud-D1:49239 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:48:05 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 107
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 73
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 104
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 89
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 84
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 91
2019-01-22 14:48:05 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on AshCloud-D1:49239 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:48:05 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on AshCloud-D1:49239 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 14:48:05 INFO  SparkContext:54 - Created broadcast 11 from rdd at IDF.scala:89
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 78
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 92
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 90
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 88
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 75
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 74
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 99
2019-01-22 14:48:05 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 85
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 80
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 101
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 95
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 86
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 98
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 102
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 81
2019-01-22 14:48:05 INFO  ContextCleaner:54 - Cleaned accumulator 82
2019-01-22 14:48:05 INFO  CodeGenerator:54 - Code generated in 22.172799 ms
2019-01-22 14:48:05 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 14:48:05 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-22 14:48:05 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on AshCloud-D1:49239 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:48:05 INFO  SparkContext:54 - Created broadcast 12 from rdd at IDF.scala:89
2019-01-22 14:48:05 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:48:05 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2019-01-22 14:48:05 INFO  DAGScheduler:54 - Got job 3 (treeAggregate at IDF.scala:54) with 5 output partitions
2019-01-22 14:48:05 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (treeAggregate at IDF.scala:54)
2019-01-22 14:48:05 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 14:48:05 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 14:48:05 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[41] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-22 14:48:05 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 65.5 KB, free 1994.7 MB)
2019-01-22 14:48:05 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.4 KB, free 1994.7 MB)
2019-01-22 14:48:05 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on AshCloud-D1:49239 (size: 20.4 KB, free: 1996.1 MB)
2019-01-22 14:48:05 INFO  SparkContext:54 - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2019-01-22 14:48:05 INFO  DAGScheduler:54 - Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[41] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2019-01-22 14:48:05 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 5 tasks
2019-01-22 14:48:05 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7989 bytes)
2019-01-22 14:48:05 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2019-01-22 14:48:05 INFO  CodeGenerator:54 - Code generated in 5.813599 ms
2019-01-22 14:48:05 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 2823 bytes result sent to driver
2019-01-22 14:48:05 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 8448 bytes)
2019-01-22 14:48:05 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 4)
2019-01-22 14:48:05 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 30 ms on localhost (executor driver) (1/5)
2019-01-22 14:48:05 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 14:48:05 INFO  CodeGenerator:54 - Code generated in 5.905999 ms
2019-01-22 14:48:05 ERROR Executor:91 - Exception in task 1.0 in stage 3.0 (TID 4)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (string) => array<string>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.filter_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23.apply(RDD.scala:1145)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23.apply(RDD.scala:1145)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1146)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1146)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.spark.ml.feature.Tokenizer$$anonfun$createTransformFunc$1.apply(Tokenizer.scala:39)
	at org.apache.spark.ml.feature.Tokenizer$$anonfun$createTransformFunc$1.apply(Tokenizer.scala:39)
	... 28 more
2019-01-22 14:48:05 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 5, localhost, executor driver, partition 2, PROCESS_LOCAL, 8452 bytes)
2019-01-22 14:48:05 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 5)
2019-01-22 14:48:05 WARN  TaskSetManager:66 - Lost task 1.0 in stage 3.0 (TID 4, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (string) => array<string>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.filter_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23.apply(RDD.scala:1145)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23.apply(RDD.scala:1145)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1146)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1146)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.spark.ml.feature.Tokenizer$$anonfun$createTransformFunc$1.apply(Tokenizer.scala:39)
	at org.apache.spark.ml.feature.Tokenizer$$anonfun$createTransformFunc$1.apply(Tokenizer.scala:39)
	... 28 more

2019-01-22 14:48:05 ERROR TaskSetManager:70 - Task 1 in stage 3.0 failed 1 times; aborting job
2019-01-22 14:48:05 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 14:48:05 INFO  TaskSchedulerImpl:54 - Cancelling stage 3
2019-01-22 14:48:05 INFO  TaskSchedulerImpl:54 - Stage 3 was cancelled
2019-01-22 14:48:05 INFO  Executor:54 - Executor is trying to kill task 2.0 in stage 3.0 (TID 5), reason: Stage cancelled
2019-01-22 14:48:05 INFO  DAGScheduler:54 - ResultStage 3 (treeAggregate at IDF.scala:54) failed in 0.120 s due to Job aborted due to stage failure: Task 1 in stage 3.0 failed 1 times, most recent failure: Lost task 1.0 in stage 3.0 (TID 4, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (string) => array<string>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.filter_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23.apply(RDD.scala:1145)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23.apply(RDD.scala:1145)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1146)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1146)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.spark.ml.feature.Tokenizer$$anonfun$createTransformFunc$1.apply(Tokenizer.scala:39)
	at org.apache.spark.ml.feature.Tokenizer$$anonfun$createTransformFunc$1.apply(Tokenizer.scala:39)
	... 28 more

Driver stacktrace:
2019-01-22 14:48:05 INFO  DAGScheduler:54 - Job 3 failed: treeAggregate at IDF.scala:54, took 0.127658 s
2019-01-22 14:48:05 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-22 14:48:05 INFO  AbstractConnector:318 - Stopped Spark@7807ac2c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 14:48:05 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-22 14:48:05 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-22 14:48:05 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-22 14:48:05 INFO  BlockManager:54 - BlockManager stopped
2019-01-22 14:48:05 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-22 14:48:05 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-22 14:48:05 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-22 14:48:05 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-22 14:48:05 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-84304f8c-a7dd-4170-ac9b-24a54398d248
2019-01-22 14:57:08 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 14:57:09 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 14:57:09 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 14:57:09 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 14:57:09 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 14:57:09 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 14:57:09 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 14:57:09 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 14:57:09 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 14:57:10 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 49394.
2019-01-22 14:57:10 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 14:57:10 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 14:57:10 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 14:57:10 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 14:57:10 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-139b7797-4896-48d4-bec4-e9700706c3d1
2019-01-22 14:57:10 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 14:57:10 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 14:57:10 INFO  log:192 - Logging initialized @7787ms
2019-01-22 14:57:10 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 14:57:10 INFO  Server:419 - Started @7843ms
2019-01-22 14:57:10 INFO  AbstractConnector:278 - Started ServerConnector@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 14:57:10 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26221bad{/jobs,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@468dda3e{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1729ec00{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/static,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3062f9f4{/api,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 14:57:10 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 14:57:10 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 14:57:10 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49407.
2019-01-22 14:57:10 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:49407
2019-01-22 14:57:10 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 14:57:10 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 49407, None)
2019-01-22 14:57:10 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:49407 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 49407, None)
2019-01-22 14:57:10 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 49407, None)
2019-01-22 14:57:10 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 49407, None)
2019-01-22 14:57:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12ad1b2a{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 14:57:11 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 14:57:11 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 14:57:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL,null,AVAILABLE,@Spark}
2019-01-22 14:57:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1624775{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 14:57:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 14:57:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@712ac7e6{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 14:57:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e43bfe{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 14:57:11 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-22 14:57:13 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:57:13 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-22 14:57:13 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 14:57:13 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:57:14 INFO  CodeGenerator:54 - Code generated in 172.737701 ms
2019-01-22 14:57:14 INFO  CodeGenerator:54 - Code generated in 19.1998 ms
2019-01-22 14:57:14 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-22 14:57:14 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-22 14:57:14 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:49407 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 14:57:14 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-22 14:57:14 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:57:14 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 14:57:14 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 14:57:14 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-22 14:57:14 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 14:57:14 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 14:57:14 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 14:57:14 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-22 14:57:14 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-22 14:57:14 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:49407 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 14:57:14 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-22 14:57:14 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 14:57:14 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-22 14:57:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-22 14:57:14 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-22 14:57:14 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 14:57:14 INFO  CodeGenerator:54 - Code generated in 9.2322 ms
2019-01-22 14:57:14 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1261 bytes result sent to driver
2019-01-22 14:57:14 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 132 ms on localhost (executor driver) (1/1)
2019-01-22 14:57:14 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-22 14:57:14 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.233 s
2019-01-22 14:57:14 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.282893 s
2019-01-22 14:57:14 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:57:14 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 14:57:14 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 14:57:14 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:57:14 INFO  CodeGenerator:54 - Code generated in 5.511599 ms
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-22 14:57:15 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:49407 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 14:57:15 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-22 14:57:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:57:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:57:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-22 14:57:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 14:57:15 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 14:57:15 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:49407 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:57:15 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-22 14:57:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:57:15 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-22 14:57:15 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:49407 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 14:57:15 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 14:57:15 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-22 14:57:15 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-22 14:57:15 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-22 14:57:15 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 14:57:15 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1290 bytes result sent to driver
2019-01-22 14:57:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 10 ms on localhost (executor driver) (1/1)
2019-01-22 14:57:15 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-22 14:57:15 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.021 s
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.023816 s
2019-01-22 14:57:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:57:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 14:57:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 14:57:15 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 14:57:15 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:49407 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:57:15 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-22 14:57:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:57:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:57:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-22 14:57:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 14:57:15 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 14:57:15 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:49407 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:57:15 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-22 14:57:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:57:15 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-22 14:57:15 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:49407 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 14:57:15 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 14:57:15 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-22 14:57:15 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-22 14:57:15 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-22 14:57:15 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-22 14:57:15 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1248 bytes result sent to driver
2019-01-22 14:57:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 11 ms on localhost (executor driver) (1/1)
2019-01-22 14:57:15 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-22 14:57:15 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.019 s
2019-01-22 14:57:15 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.022308 s
2019-01-22 14:57:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:57:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 14:57:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 14:57:15 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 14:57:15 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-22 14:57:15 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:49407 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:57:15 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-22 14:57:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:57:15 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 14:57:15 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 14:57:24 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:57:24 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 14:57:24 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_id: string, commit_date: string, commit_content: string, commit_author: string, commit_type: string ... 3 more fields>
2019-01-22 14:57:24 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:57:24 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:57:24 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 14:57:24 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 14:57:24 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:57:24 INFO  CodeGenerator:54 - Code generated in 21.1384 ms
2019-01-22 14:57:24 INFO  CodeGenerator:54 - Code generated in 27.8741 ms
2019-01-22 14:57:24 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 220.9 KB, free 1994.5 MB)
2019-01-22 14:57:24 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.5 MB)
2019-01-22 14:57:24 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on AshCloud-D1:49407 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 14:57:24 INFO  SparkContext:54 - Created broadcast 9 from show at SparkTraceTask.java:217
2019-01-22 14:57:24 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:57:24 INFO  CodeGenerator:54 - Code generated in 23.3036 ms
2019-01-22 14:57:24 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 220.9 KB, free 1994.3 MB)
2019-01-22 14:57:24 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.3 MB)
2019-01-22 14:57:24 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on AshCloud-D1:49407 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 14:57:24 INFO  SparkContext:54 - Created broadcast 10 from show at SparkTraceTask.java:217
2019-01-22 14:57:24 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:57:24 INFO  SparkContext:54 - Starting job: show at SparkTraceTask.java:217
2019-01-22 14:57:24 INFO  DAGScheduler:54 - Got job 3 (show at SparkTraceTask.java:217) with 1 output partitions
2019-01-22 14:57:24 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (show at SparkTraceTask.java:217)
2019-01-22 14:57:24 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 14:57:24 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 14:57:24 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[33] at show at SparkTraceTask.java:217), which has no missing parents
2019-01-22 14:57:24 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 24.7 KB, free 1994.2 MB)
2019-01-22 14:57:24 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 9.4 KB, free 1994.2 MB)
2019-01-22 14:57:24 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on AshCloud-D1:49407 (size: 9.4 KB, free: 1996.0 MB)
2019-01-22 14:57:24 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2019-01-22 14:57:24 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[33] at show at SparkTraceTask.java:217) (first 15 tasks are for partitions Vector(0))
2019-01-22 14:57:24 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2019-01-22 14:57:24 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8448 bytes)
2019-01-22 14:57:24 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2019-01-22 14:57:24 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 14:57:24 INFO  CodeGenerator:54 - Code generated in 15.112701 ms
2019-01-22 14:57:25 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 4529 bytes result sent to driver
2019-01-22 14:57:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 268 ms on localhost (executor driver) (1/1)
2019-01-22 14:57:25 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2019-01-22 14:57:25 INFO  DAGScheduler:54 - ResultStage 3 (show at SparkTraceTask.java:217) finished in 0.290 s
2019-01-22 14:57:25 INFO  DAGScheduler:54 - Job 3 finished: show at SparkTraceTask.java:217, took 0.294208 s
2019-01-22 14:59:03 WARN  Executor:87 - Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:785)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:814)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
2019-01-22 14:59:03 WARN  NettyRpcEnv:66 - Ignored message: HeartbeatResponse(false)
2019-01-22 14:59:03 INFO  column remover:43 - removing column issue_content
2019-01-22 14:59:03 INFO  column remover:43 - removing column commit_content
2019-01-22 14:59:03 INFO  column remover:43 - removing column t_tokens
2019-01-22 14:59:03 INFO  column remover:43 - removing column s_tokens
2019-01-22 14:59:03 INFO  column remover:43 - removing column s_htf
2019-01-22 14:59:03 INFO  column remover:43 - removing column t_htf
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 82
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 55
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 12
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 28
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 87
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 41
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 61
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 8
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 15
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 24
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 57
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 62
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 103
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 20
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 69
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 74
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 98
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 51
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 67
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 133
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 101
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 113
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 105
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 81
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 9
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 89
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on AshCloud-D1:49407 in memory (size: 4.4 KB, free: 1996.0 MB)
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 73
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 93
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 40
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 139
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 122
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 64
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on AshCloud-D1:49407 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 45
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 94
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 72
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 70
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 142
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 52
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 79
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 108
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 53
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 124
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 54
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 39
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 66
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 111
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 78
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on AshCloud-D1:49407 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 47
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 116
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 110
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 125
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 131
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 134
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 107
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 126
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 77
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 26
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 90
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 60
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 44
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 6
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 68
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 65
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 37
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 92
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 130
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 13
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on AshCloud-D1:49407 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 137
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 83
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 59
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 42
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 56
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 58
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 30
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 48
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 14
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 36
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 88
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on AshCloud-D1:49407 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 96
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 141
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 106
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 120
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 114
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 23
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 11
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 19
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 80
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 46
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 91
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 76
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 132
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 7
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 49
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 140
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 10
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 104
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 136
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 95
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 121
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on AshCloud-D1:49407 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 85
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 27
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 102
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 38
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on AshCloud-D1:49407 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 118
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 135
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 128
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 29
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 100
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 71
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 129
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 109
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 50
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 86
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 84
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 16
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 75
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 21
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 117
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:49407 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on AshCloud-D1:49407 in memory (size: 9.4 KB, free: 1996.1 MB)
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 18
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 25
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 119
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 99
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 115
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 22
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 17
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 127
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 63
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 97
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on AshCloud-D1:49407 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 138
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 43
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 112
2019-01-22 14:59:03 INFO  ContextCleaner:54 - Cleaned accumulator 123
2019-01-22 14:59:03 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:59:03 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(UDF(UDF(commit_content#17)))
2019-01-22 14:59:03 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-22 14:59:03 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:59:03 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:59:03 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 14:59:03 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string>
2019-01-22 14:59:03 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:59:03 INFO  FileSourceStrategy:54 - Pruning directories with: isnotnull(UDF(UDF(null)))
2019-01-22 14:59:03 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(UDF(UDF(null)))
2019-01-22 14:59:03 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-01-22 14:59:03 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:59:03 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 14:59:03 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 14:59:03 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_summary: string>
2019-01-22 14:59:03 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 14:59:03 INFO  CodeGenerator:54 - Code generated in 26.151601 ms
2019-01-22 14:59:03 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 14:59:03 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on AshCloud-D1:49407 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:59:03 INFO  SparkContext:54 - Created broadcast 12 from rdd at IDF.scala:89
2019-01-22 14:59:03 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:59:03 INFO  CodeGenerator:54 - Code generated in 16.384699 ms
2019-01-22 14:59:03 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 14:59:03 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.3 MB)
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on AshCloud-D1:49407 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:59:03 INFO  SparkContext:54 - Created broadcast 13 from rdd at IDF.scala:89
2019-01-22 14:59:03 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:59:03 INFO  CodeGenerator:54 - Code generated in 14.1564 ms
2019-01-22 14:59:03 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 14:59:03 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on AshCloud-D1:49407 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:59:03 INFO  SparkContext:54 - Created broadcast 14 from rdd at IDF.scala:89
2019-01-22 14:59:03 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:59:03 INFO  CodeGenerator:54 - Code generated in 14.6324 ms
2019-01-22 14:59:03 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 14:59:03 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on AshCloud-D1:49407 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:59:03 INFO  SparkContext:54 - Created broadcast 15 from rdd at IDF.scala:89
2019-01-22 14:59:03 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 14:59:03 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2019-01-22 14:59:03 INFO  DAGScheduler:54 - Got job 4 (treeAggregate at IDF.scala:54) with 5 output partitions
2019-01-22 14:59:03 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (treeAggregate at IDF.scala:54)
2019-01-22 14:59:03 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 14:59:03 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 14:59:03 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[48] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-22 14:59:03 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 65.5 KB, free 1994.7 MB)
2019-01-22 14:59:03 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-22 14:59:03 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on AshCloud-D1:49407 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 14:59:03 INFO  SparkContext:54 - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2019-01-22 14:59:03 INFO  DAGScheduler:54 - Submitting 5 missing tasks from ResultStage 4 (MapPartitionsRDD[48] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2019-01-22 14:59:03 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 5 tasks
2019-01-22 14:59:03 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7989 bytes)
2019-01-22 14:59:03 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2019-01-22 14:59:03 INFO  CodeGenerator:54 - Code generated in 7.679001 ms
2019-01-22 14:59:03 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 2823 bytes result sent to driver
2019-01-22 14:59:03 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 8448 bytes)
2019-01-22 14:59:03 INFO  Executor:54 - Running task 1.0 in stage 4.0 (TID 5)
2019-01-22 14:59:03 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 33 ms on localhost (executor driver) (1/5)
2019-01-22 14:59:03 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 14:59:04 INFO  MemoryStore:54 - Block taskresult_5 stored as bytes in memory (estimated size 2.0 MB, free 1992.7 MB)
2019-01-22 14:59:04 INFO  BlockManagerInfo:54 - Added taskresult_5 in memory on AshCloud-D1:49407 (size: 2.0 MB, free: 1994.0 MB)
2019-01-22 14:59:04 INFO  Executor:54 - Finished task 1.0 in stage 4.0 (TID 5). 2110493 bytes result sent via BlockManager)
2019-01-22 14:59:04 INFO  TaskSetManager:54 - Starting task 2.0 in stage 4.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 8452 bytes)
2019-01-22 14:59:04 INFO  Executor:54 - Running task 2.0 in stage 4.0 (TID 6)
2019-01-22 14:59:04 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 14:59:05 INFO  MemoryStore:54 - Block taskresult_6 stored as bytes in memory (estimated size 2.0 MB, free 1990.7 MB)
2019-01-22 14:59:05 INFO  BlockManagerInfo:54 - Added taskresult_6 in memory on AshCloud-D1:49407 (size: 2.0 MB, free: 1992.0 MB)
2019-01-22 14:59:05 INFO  Executor:54 - Finished task 2.0 in stage 4.0 (TID 6). 2110450 bytes result sent via BlockManager)
2019-01-22 14:59:05 INFO  TaskSetManager:54 - Starting task 3.0 in stage 4.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 8448 bytes)
2019-01-22 14:59:05 INFO  Executor:54 - Running task 3.0 in stage 4.0 (TID 7)
2019-01-22 14:59:05 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 14:59:05 INFO  CodeGenerator:54 - Code generated in 5.712901 ms
2019-01-22 14:59:05 ERROR Executor:91 - Exception in task 3.0 in stage 4.0 (TID 7)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (string) => array<string>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.filter_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23.apply(RDD.scala:1145)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23.apply(RDD.scala:1145)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1146)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1146)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.spark.ml.feature.Tokenizer$$anonfun$createTransformFunc$1.apply(Tokenizer.scala:39)
	at org.apache.spark.ml.feature.Tokenizer$$anonfun$createTransformFunc$1.apply(Tokenizer.scala:39)
	... 28 more
2019-01-22 14:59:05 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:49407 after 47 ms (0 ms spent in bootstraps)
2019-01-22 14:59:05 INFO  TaskSetManager:54 - Starting task 4.0 in stage 4.0 (TID 8, localhost, executor driver, partition 4, PROCESS_LOCAL, 8452 bytes)
2019-01-22 14:59:05 INFO  Executor:54 - Running task 4.0 in stage 4.0 (TID 8)
2019-01-22 14:59:05 WARN  TaskSetManager:66 - Lost task 3.0 in stage 4.0 (TID 7, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (string) => array<string>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.filter_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23.apply(RDD.scala:1145)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23.apply(RDD.scala:1145)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1146)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1146)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.spark.ml.feature.Tokenizer$$anonfun$createTransformFunc$1.apply(Tokenizer.scala:39)
	at org.apache.spark.ml.feature.Tokenizer$$anonfun$createTransformFunc$1.apply(Tokenizer.scala:39)
	... 28 more

2019-01-22 14:59:05 ERROR TaskSetManager:70 - Task 3 in stage 4.0 failed 1 times; aborting job
2019-01-22 14:59:05 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 14:59:05 INFO  TaskSchedulerImpl:54 - Cancelling stage 4
2019-01-22 14:59:05 INFO  TaskSchedulerImpl:54 - Stage 4 was cancelled
2019-01-22 14:59:05 INFO  Executor:54 - Executor is trying to kill task 4.0 in stage 4.0 (TID 8), reason: Stage cancelled
2019-01-22 14:59:05 INFO  DAGScheduler:54 - ResultStage 4 (treeAggregate at IDF.scala:54) failed in 1.122 s due to Job aborted due to stage failure: Task 3 in stage 4.0 failed 1 times, most recent failure: Lost task 3.0 in stage 4.0 (TID 7, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (string) => array<string>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.filter_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23.apply(RDD.scala:1145)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23.apply(RDD.scala:1145)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1146)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1146)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.spark.ml.feature.Tokenizer$$anonfun$createTransformFunc$1.apply(Tokenizer.scala:39)
	at org.apache.spark.ml.feature.Tokenizer$$anonfun$createTransformFunc$1.apply(Tokenizer.scala:39)
	... 28 more

Driver stacktrace:
2019-01-22 14:59:05 INFO  DAGScheduler:54 - Job 4 failed: treeAggregate at IDF.scala:54, took 1.126848 s
2019-01-22 14:59:05 INFO  Executor:54 - Executor killed task 4.0 in stage 4.0 (TID 8), reason: Stage cancelled
2019-01-22 14:59:05 WARN  TaskSetManager:66 - Lost task 4.0 in stage 4.0 (TID 8, localhost, executor driver): TaskKilled (Stage cancelled)
2019-01-22 14:59:05 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2019-01-22 14:59:05 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-22 14:59:05 INFO  AbstractConnector:318 - Stopped Spark@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 14:59:05 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-22 14:59:05 ERROR Utils:91 - Uncaught exception in thread task-result-getter-1
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
	at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:202)
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:218)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:115)
	at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:693)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:82)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2019-01-22 14:59:05 ERROR Utils:91 - Uncaught exception in thread task-result-getter-2
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
	at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:202)
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:218)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:115)
	at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:693)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:82)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2019-01-22 14:59:05 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-22 14:59:05 ERROR TransportRequestHandler:226 - Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1686155016001, chunkIndex=0}, buffer=org.apache.spark.storage.BlockManagerManagedBuffer@86cfaf6} to /192.168.56.1:49447; closing connection
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(...)(Unknown Source)
2019-01-22 14:59:05 ERROR TransportResponseHandler:144 - Still have 1 requests outstanding when connection from AshCloud-D1/192.168.56.1:49407 is closed
2019-01-22 14:59:05 INFO  RetryingBlockFetcher:164 - Retrying fetch (1/3) for 1 outstanding blocks after 5000 ms
2019-01-22 14:59:05 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-22 14:59:05 INFO  BlockManager:54 - BlockManager stopped
2019-01-22 14:59:05 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-22 14:59:05 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-22 14:59:05 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-22 14:59:05 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-22 14:59:05 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-4c525150-ae99-4111-b278-6d52a9fc32e7
2019-01-22 17:51:20 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 17:51:20 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 17:51:20 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 17:51:20 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 17:51:20 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 17:51:20 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 17:51:20 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 17:51:20 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 17:51:20 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 17:51:21 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 51876.
2019-01-22 17:51:21 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 17:51:21 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 17:51:21 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 17:51:21 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 17:51:21 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-e8488f16-68ff-4b53-9632-0da16d0a540a
2019-01-22 17:51:21 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 17:51:21 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 17:51:21 INFO  log:192 - Logging initialized @6867ms
2019-01-22 17:51:21 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 17:51:21 INFO  Server:419 - Started @6919ms
2019-01-22 17:51:21 INFO  AbstractConnector:278 - Started ServerConnector@7807ac2c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 17:51:21 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32fe9d0a{/jobs,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30ed9c6c{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@782a4fff{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae81e1{/stages,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2fd1731c{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae76500{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54709809{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a2da905{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@24f360b2{/storage,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60cf80e7{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@302fec27{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@770d0ea6{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@48c40605{/environment,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54107f42{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b11ef33{/executors,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@476aac9{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cea706c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 17:51:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 17:51:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static,null,AVAILABLE,@Spark}
2019-01-22 17:51:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a138fc5{/,null,AVAILABLE,@Spark}
2019-01-22 17:51:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@379ab47b{/api,null,AVAILABLE,@Spark}
2019-01-22 17:51:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4e4efc1b{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 17:51:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459f7aa3{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 17:51:22 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 17:51:22 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 17:51:22 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51889.
2019-01-22 17:51:22 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:51889
2019-01-22 17:51:22 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 17:51:22 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 51889, None)
2019-01-22 17:51:22 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:51889 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 51889, None)
2019-01-22 17:51:22 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 51889, None)
2019-01-22 17:51:22 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 51889, None)
2019-01-22 17:51:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69e308c6{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 17:51:22 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 17:51:22 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 17:51:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@250b236d{/SQL,null,AVAILABLE,@Spark}
2019-01-22 17:51:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f3fbb8{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 17:51:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60e5272{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 17:51:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d755813{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 17:51:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60dd3c23{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 17:51:22 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-22 17:51:24 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:51:24 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-22 17:51:24 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:51:24 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:51:24 INFO  CodeGenerator:54 - Code generated in 156.914501 ms
2019-01-22 17:51:25 INFO  CodeGenerator:54 - Code generated in 13.768599 ms
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-22 17:51:25 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:51889 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 17:51:25 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-22 17:51:25 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:51:25 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-22 17:51:25 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:51889 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 17:51:25 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 17:51:25 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-22 17:51:25 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-22 17:51:25 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-22 17:51:25 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 17:51:25 INFO  CodeGenerator:54 - Code generated in 7.9079 ms
2019-01-22 17:51:25 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2019-01-22 17:51:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 129 ms on localhost (executor driver) (1/1)
2019-01-22 17:51:25 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-22 17:51:25 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.202 s
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.236562 s
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:51:25 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:51:25 INFO  CodeGenerator:54 - Code generated in 7.3965 ms
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-22 17:51:25 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:51889 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 17:51:25 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-22 17:51:25 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:51:25 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 17:51:25 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:51889 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:51:25 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-22 17:51:25 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:51:25 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-22 17:51:25 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:51889 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 17:51:25 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 17:51:25 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-22 17:51:25 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-22 17:51:25 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-22 17:51:25 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 17:51:25 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1290 bytes result sent to driver
2019-01-22 17:51:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 11 ms on localhost (executor driver) (1/1)
2019-01-22 17:51:25 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-22 17:51:25 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.020 s
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.022973 s
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:51:25 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 17:51:25 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:51889 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:51:25 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-22 17:51:25 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:51:25 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 17:51:25 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:51889 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:51:25 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-22 17:51:25 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 12
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 25
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 8
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 49
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 10
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 61
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 44
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 55
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 43
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 62
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 41
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 42
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 6
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 22
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 26
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 56
2019-01-22 17:51:25 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-22 17:51:25 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:51889 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 17:51:25 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 17:51:25 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-22 17:51:25 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-22 17:51:25 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on AshCloud-D1:51889 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:51:25 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 14
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 47
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 70
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 38
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 45
2019-01-22 17:51:25 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on AshCloud-D1:51889 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 23
2019-01-22 17:51:25 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 50
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 58
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 64
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 7
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 54
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 17
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 37
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 46
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 51
2019-01-22 17:51:25 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on AshCloud-D1:51889 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 27
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 57
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 59
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 28
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 20
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 53
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 40
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 29
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 60
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 67
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 39
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 71
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 18
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 36
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 9
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 24
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 13
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 15
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 19
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 16
2019-01-22 17:51:25 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1248 bytes result sent to driver
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 11
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 21
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 30
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 63
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 48
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 52
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 66
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 68
2019-01-22 17:51:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 9 ms on localhost (executor driver) (1/1)
2019-01-22 17:51:25 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-22 17:51:25 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.019 s
2019-01-22 17:51:25 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:51889 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 17:51:25 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.021349 s
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 65
2019-01-22 17:51:25 INFO  ContextCleaner:54 - Cleaned accumulator 69
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 17:51:25 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:51:25 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 17:51:25 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 17:51:25 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:51889 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:51:25 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-22 17:51:25 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:51:25 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_f801081e4535 inputCol, its NullRemover's IO params are set to null
2019-01-22 17:51:25 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_828c6ba6b4c0 inputCol, its NullRemover's IO params are set to null
2019-01-22 17:51:25 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 17:51:25 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_7860647a34aa inputCol, its NullRemover's IO params are set to null
2019-01-22 17:51:25 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_24e32c023aa6 inputCol, its NullRemover's IO params are set to null
2019-01-22 17:51:25 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 17:51:25 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-22 17:51:26 INFO  AbstractConnector:318 - Stopped Spark@7807ac2c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 17:51:26 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-22 17:51:26 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-22 17:51:26 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-22 17:51:26 INFO  BlockManager:54 - BlockManager stopped
2019-01-22 17:51:26 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-22 17:51:26 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-22 17:51:26 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-22 17:51:26 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-22 17:51:26 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-a69ff9c4-0ee2-423e-ae15-b66fced622b6
2019-01-22 17:57:02 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 17:57:02 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 17:57:02 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 17:57:02 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 17:57:02 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 17:57:02 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 17:57:02 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 17:57:02 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 17:57:02 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 17:57:03 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 51978.
2019-01-22 17:57:03 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 17:57:03 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 17:57:03 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 17:57:03 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 17:57:03 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-c5faf5ce-43d8-4a16-a27e-838bbc0ebdd4
2019-01-22 17:57:03 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 17:57:03 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 17:57:04 INFO  log:192 - Logging initialized @7143ms
2019-01-22 17:57:04 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 17:57:04 INFO  Server:419 - Started @7200ms
2019-01-22 17:57:04 INFO  AbstractConnector:278 - Started ServerConnector@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 17:57:04 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26221bad{/jobs,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@468dda3e{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1729ec00{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/static,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3062f9f4{/api,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 17:57:04 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 17:57:04 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51991.
2019-01-22 17:57:04 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:51991
2019-01-22 17:57:04 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 17:57:04 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 51991, None)
2019-01-22 17:57:04 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:51991 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 51991, None)
2019-01-22 17:57:04 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 51991, None)
2019-01-22 17:57:04 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 51991, None)
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12ad1b2a{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 17:57:04 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1624775{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@712ac7e6{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 17:57:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e43bfe{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 17:57:05 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-22 17:57:06 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:57:06 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-22 17:57:06 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:57:06 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:57:07 INFO  CodeGenerator:54 - Code generated in 162.3488 ms
2019-01-22 17:57:07 INFO  CodeGenerator:54 - Code generated in 18.053301 ms
2019-01-22 17:57:07 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-22 17:57:07 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-22 17:57:07 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:51991 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 17:57:07 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-22 17:57:07 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:57:07 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 17:57:07 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 17:57:07 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-22 17:57:07 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 17:57:07 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 17:57:07 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 17:57:07 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-22 17:57:07 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-22 17:57:07 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:51991 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 17:57:07 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-22 17:57:07 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 17:57:07 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-22 17:57:07 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-22 17:57:07 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-22 17:57:07 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 17:57:07 INFO  CodeGenerator:54 - Code generated in 9.7518 ms
2019-01-22 17:57:07 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1261 bytes result sent to driver
2019-01-22 17:57:07 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 122 ms on localhost (executor driver) (1/1)
2019-01-22 17:57:07 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-22 17:57:07 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.202 s
2019-01-22 17:57:07 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.241656 s
2019-01-22 17:57:07 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:57:07 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 17:57:07 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:57:07 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:57:08 INFO  CodeGenerator:54 - Code generated in 5.711399 ms
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-22 17:57:08 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:51991 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 17:57:08 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-22 17:57:08 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:57:08 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:57:08 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-22 17:57:08 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:57:08 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 17:57:08 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:51991 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:57:08 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-22 17:57:08 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:57:08 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-22 17:57:08 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:51991 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 17:57:08 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 17:57:08 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-22 17:57:08 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-22 17:57:08 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-22 17:57:08 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 17:57:08 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1333 bytes result sent to driver
2019-01-22 17:57:08 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 13 ms on localhost (executor driver) (1/1)
2019-01-22 17:57:08 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-22 17:57:08 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.022 s
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.025446 s
2019-01-22 17:57:08 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:57:08 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 17:57:08 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:57:08 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 17:57:08 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:51991 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:57:08 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-22 17:57:08 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:57:08 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:57:08 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-22 17:57:08 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:57:08 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 17:57:08 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:51991 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:57:08 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-22 17:57:08 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:57:08 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-22 17:57:08 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:51991 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 17:57:08 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 17:57:08 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-22 17:57:08 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-22 17:57:08 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-22 17:57:08 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-22 17:57:08 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1248 bytes result sent to driver
2019-01-22 17:57:08 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 10 ms on localhost (executor driver) (1/1)
2019-01-22 17:57:08 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-22 17:57:08 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.019 s
2019-01-22 17:57:08 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.021078 s
2019-01-22 17:57:08 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:57:08 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 17:57:08 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:57:08 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 17:57:08 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-22 17:57:08 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:51991 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:57:08 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-22 17:57:08 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:57:08 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_0666bf64f068 inputCol, its NullRemover's IO params are set to null
2019-01-22 17:57:08 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_618faddc4952 inputCol, its NullRemover's IO params are set to null
2019-01-22 17:57:08 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 17:57:08 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_5d4bc5927a9f inputCol, its NullRemover's IO params are set to null
2019-01-22 17:57:08 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_939294fe1f87 inputCol, its NullRemover's IO params are set to null
2019-01-22 17:57:08 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 17:57:53 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-22 17:57:53 INFO  AbstractConnector:318 - Stopped Spark@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 17:57:53 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-22 17:57:53 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-22 17:57:53 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-22 17:57:53 INFO  BlockManager:54 - BlockManager stopped
2019-01-22 17:57:53 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-22 17:57:53 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-22 17:57:53 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-22 17:57:53 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-22 17:57:53 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-ddfe325b-5c53-4a2e-9cf1-5e99ac46782a
2019-01-22 17:58:51 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 17:58:52 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 17:58:52 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 17:58:52 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 17:58:52 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 17:58:52 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 17:58:52 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 17:58:52 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 17:58:52 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 17:58:53 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 52044.
2019-01-22 17:58:53 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 17:58:53 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 17:58:53 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 17:58:53 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 17:58:53 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-30d7b787-d4a1-4871-bc1a-127cca0472b1
2019-01-22 17:58:53 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 17:58:53 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 17:58:53 INFO  log:192 - Logging initialized @7105ms
2019-01-22 17:58:53 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 17:58:53 INFO  Server:419 - Started @7161ms
2019-01-22 17:58:53 INFO  AbstractConnector:278 - Started ServerConnector@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 17:58:53 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26221bad{/jobs,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@468dda3e{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1729ec00{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/static,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3062f9f4{/api,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 17:58:53 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 17:58:53 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 17:58:53 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52057.
2019-01-22 17:58:53 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:52057
2019-01-22 17:58:53 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 17:58:53 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 52057, None)
2019-01-22 17:58:53 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:52057 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 52057, None)
2019-01-22 17:58:53 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 52057, None)
2019-01-22 17:58:53 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 52057, None)
2019-01-22 17:58:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12ad1b2a{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 17:58:54 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 17:58:54 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 17:58:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL,null,AVAILABLE,@Spark}
2019-01-22 17:58:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1624775{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 17:58:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 17:58:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@712ac7e6{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 17:58:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e43bfe{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 17:58:54 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-22 17:58:56 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:58:56 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-22 17:58:56 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:58:56 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:58:56 INFO  CodeGenerator:54 - Code generated in 161.4681 ms
2019-01-22 17:58:56 INFO  CodeGenerator:54 - Code generated in 16.793299 ms
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-22 17:58:57 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:52057 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 17:58:57 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-22 17:58:57 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:58:57 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-22 17:58:57 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:52057 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 17:58:57 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 17:58:57 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-22 17:58:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-22 17:58:57 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-22 17:58:57 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 17:58:57 INFO  CodeGenerator:54 - Code generated in 9.4573 ms
2019-01-22 17:58:57 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2019-01-22 17:58:57 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 124 ms on localhost (executor driver) (1/1)
2019-01-22 17:58:57 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-22 17:58:57 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.204 s
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.244516 s
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:58:57 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:58:57 INFO  CodeGenerator:54 - Code generated in 4.9262 ms
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-22 17:58:57 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:52057 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 17:58:57 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-22 17:58:57 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:58:57 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 17:58:57 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:52057 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:58:57 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-22 17:58:57 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:58:57 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-22 17:58:57 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:52057 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 17:58:57 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 17:58:57 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-22 17:58:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-22 17:58:57 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-22 17:58:57 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 17:58:57 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1290 bytes result sent to driver
2019-01-22 17:58:57 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 10 ms on localhost (executor driver) (1/1)
2019-01-22 17:58:57 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-22 17:58:57 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.019 s
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.021797 s
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:58:57 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 17:58:57 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:52057 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:58:57 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-22 17:58:57 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:58:57 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 17:58:57 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:52057 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:58:57 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-22 17:58:57 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:58:57 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-22 17:58:57 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:52057 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 17:58:57 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 17:58:57 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-22 17:58:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-22 17:58:57 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-22 17:58:57 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-22 17:58:57 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1205 bytes result sent to driver
2019-01-22 17:58:57 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 8 ms on localhost (executor driver) (1/1)
2019-01-22 17:58:57 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-22 17:58:57 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.018 s
2019-01-22 17:58:57 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.019248 s
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 17:58:57 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 17:58:57 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 17:58:57 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-22 17:58:57 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:52057 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 17:58:57 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-22 17:58:57 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 17:58:57 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_9c973ad0a48a inputCol, its NullRemover's IO params are set to null
2019-01-22 17:58:57 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_e126ca3b909e inputCol, its NullRemover's IO params are set to null
2019-01-22 17:58:57 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 17:58:57 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_183890ec077f inputCol, its NullRemover's IO params are set to null
2019-01-22 17:58:57 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_6ad5930773cc inputCol, its NullRemover's IO params are set to null
2019-01-22 17:58:57 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 18:01:19 WARN  HeartbeatReceiver:66 - Removing executor driver with no recent heartbeats: 137947 ms exceeds timeout 120000 ms
2019-01-22 18:01:19 ERROR TaskSchedulerImpl:70 - Lost executor driver on localhost: Executor heartbeat timed out after 137947 ms
2019-01-22 18:01:19 INFO  DAGScheduler:54 - Executor lost: driver (epoch 0)
2019-01-22 18:01:19 WARN  SparkContext:66 - Killing executors is not supported by current scheduler.
2019-01-22 18:01:19 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-22 18:01:19 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 52057, None) re-registering with master
2019-01-22 18:01:19 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 52057, None)
2019-01-22 18:01:19 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-22 18:01:19 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor driver from BlockManagerMaster.
2019-01-22 18:01:19 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for broadcast_0_piece0 !
2019-01-22 18:01:19 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for broadcast_6_piece0 !
2019-01-22 18:01:19 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for broadcast_4_piece0 !
2019-01-22 18:01:19 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for broadcast_7_piece0 !
2019-01-22 18:01:19 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for broadcast_2_piece0 !
2019-01-22 18:01:19 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for broadcast_5_piece0 !
2019-01-22 18:01:19 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for broadcast_8_piece0 !
2019-01-22 18:01:19 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for broadcast_1_piece0 !
2019-01-22 18:01:19 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for broadcast_3_piece0 !
2019-01-22 18:01:19 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(driver, AshCloud-D1, 52057, None)
2019-01-22 18:01:19 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:52057 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 52057, None)
2019-01-22 18:01:19 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 52057, None)
2019-01-22 18:01:19 INFO  BlockManagerMaster:54 - Removed driver successfully in removeExecutor
2019-01-22 18:01:19 INFO  BlockManager:54 - Reporting 18 blocks to the master.
2019-01-22 18:01:19 INFO  DAGScheduler:54 - Shuffle files lost for executor: driver (epoch 0)
2019-01-22 18:01:19 INFO  AbstractConnector:318 - Stopped Spark@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 18:01:19 INFO  DAGScheduler:54 - Host added was in lost list earlier: localhost
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:52057 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:52057 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 18:01:19 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:52057 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:52057 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:52057 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:52057 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:52057 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:52057 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:52057 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-22 18:01:19 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 52057, None) re-registering with master
2019-01-22 18:01:19 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 52057, None)
2019-01-22 18:01:19 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 52057, None)
2019-01-22 18:01:19 INFO  BlockManager:54 - Reporting 18 blocks to the master.
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Updated broadcast_1_piece0 in memory on AshCloud-D1:52057 (current size: 4.4 KB, original size: 4.4 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Updated broadcast_3_piece0 in memory on AshCloud-D1:52057 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:52057 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Updated broadcast_4_piece0 in memory on AshCloud-D1:52057 (current size: 4.4 KB, original size: 4.4 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Updated broadcast_5_piece0 in memory on AshCloud-D1:52057 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:52057 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Updated broadcast_7_piece0 in memory on AshCloud-D1:52057 (current size: 4.4 KB, original size: 4.4 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Updated broadcast_6_piece0 in memory on AshCloud-D1:52057 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  BlockManagerInfo:54 - Updated broadcast_8_piece0 in memory on AshCloud-D1:52057 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:01:19 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-22 18:01:19 INFO  BlockManager:54 - BlockManager stopped
2019-01-22 18:01:19 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-22 18:01:19 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-22 18:01:19 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-22 18:01:19 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-22 18:01:19 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-08283a27-2d0c-4cf1-ad6b-6cbe41ddf69f
2019-01-22 18:02:52 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 18:02:52 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 18:02:52 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 18:02:52 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 18:02:52 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 18:02:52 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 18:02:52 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 18:02:52 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 18:02:52 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 18:02:53 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 52140.
2019-01-22 18:02:53 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 18:02:53 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 18:02:53 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 18:02:53 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 18:02:53 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-8bb58895-ccfe-4294-8536-1cb97ae9ba68
2019-01-22 18:02:53 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 18:02:53 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 18:02:53 INFO  log:192 - Logging initialized @7194ms
2019-01-22 18:02:53 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 18:02:53 INFO  Server:419 - Started @7248ms
2019-01-22 18:02:53 INFO  AbstractConnector:278 - Started ServerConnector@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 18:02:53 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26221bad{/jobs,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@468dda3e{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1729ec00{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/static,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3062f9f4{/api,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 18:02:53 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 18:02:54 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 18:02:54 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52153.
2019-01-22 18:02:54 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:52153
2019-01-22 18:02:54 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 18:02:54 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 52153, None)
2019-01-22 18:02:54 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:52153 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 52153, None)
2019-01-22 18:02:54 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 52153, None)
2019-01-22 18:02:54 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 52153, None)
2019-01-22 18:02:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12ad1b2a{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 18:02:54 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 18:02:54 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 18:02:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL,null,AVAILABLE,@Spark}
2019-01-22 18:02:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1624775{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 18:02:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 18:02:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@712ac7e6{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 18:02:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e43bfe{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 18:02:54 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-22 18:02:56 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:02:56 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-22 18:02:56 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:02:56 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:02:57 INFO  CodeGenerator:54 - Code generated in 169.3169 ms
2019-01-22 18:02:57 INFO  CodeGenerator:54 - Code generated in 16.8147 ms
2019-01-22 18:02:57 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-22 18:02:57 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-22 18:02:57 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:52153 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 18:02:57 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-22 18:02:57 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:02:57 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 18:02:57 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 18:02:57 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-22 18:02:57 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 18:02:57 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 18:02:57 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 18:02:57 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-22 18:02:57 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-22 18:02:57 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:52153 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 18:02:57 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-22 18:02:57 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 18:02:57 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-22 18:02:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-22 18:02:57 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-22 18:02:57 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 18:02:57 INFO  CodeGenerator:54 - Code generated in 8.456 ms
2019-01-22 18:02:57 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2019-01-22 18:02:57 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 121 ms on localhost (executor driver) (1/1)
2019-01-22 18:02:57 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-22 18:02:57 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.199 s
2019-01-22 18:02:57 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.237204 s
2019-01-22 18:02:57 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:02:57 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 18:02:57 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:02:57 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:02:57 INFO  CodeGenerator:54 - Code generated in 7.7288 ms
2019-01-22 18:02:57 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-22 18:02:57 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-22 18:02:57 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:52153 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 18:02:57 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-22 18:02:57 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:02:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:02:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-22 18:02:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:02:58 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:02:58 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 18:02:58 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 18:02:58 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:52153 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:02:58 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-22 18:02:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:02:58 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 18:02:58 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-22 18:02:58 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-22 18:02:58 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:52153 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 18:02:58 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 18:02:58 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-22 18:02:58 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-22 18:02:58 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-22 18:02:58 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 18:02:58 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1290 bytes result sent to driver
2019-01-22 18:02:58 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 11 ms on localhost (executor driver) (1/1)
2019-01-22 18:02:58 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-22 18:02:58 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.021 s
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.023461 s
2019-01-22 18:02:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:02:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 18:02:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:02:58 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:02:58 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 18:02:58 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 18:02:58 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:52153 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:02:58 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-22 18:02:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:02:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:02:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-22 18:02:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:02:58 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:02:58 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 18:02:58 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 18:02:58 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:52153 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:02:58 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-22 18:02:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:02:58 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 18:02:58 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-22 18:02:58 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-22 18:02:58 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:52153 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 18:02:58 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 18:02:58 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-22 18:02:58 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-22 18:02:58 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-22 18:02:58 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-22 18:02:58 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1248 bytes result sent to driver
2019-01-22 18:02:58 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 8 ms on localhost (executor driver) (1/1)
2019-01-22 18:02:58 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-22 18:02:58 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.016 s
2019-01-22 18:02:58 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.018703 s
2019-01-22 18:02:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:02:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 18:02:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:02:58 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:02:58 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 18:02:58 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-22 18:02:58 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:52153 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:02:58 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-22 18:02:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:02:58 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_e547ec99b5a1 inputCol, its NullRemover's IO params are set to null
2019-01-22 18:04:21 WARN  Executor:87 - Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:785)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:814)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
2019-01-22 18:04:54 WARN  Executor:87 - Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:785)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:814)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
2019-01-22 18:05:31 WARN  NettyRpcEnv:66 - Ignored message: HeartbeatResponse(false)
2019-01-22 18:05:31 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_e884d42abd56 inputCol, its NullRemover's IO params are set to null
2019-01-22 18:05:31 WARN  NettyRpcEnv:66 - Ignored message: HeartbeatResponse(false)
2019-01-22 18:05:31 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 18:05:31 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_6c98bdbcad1d inputCol, its NullRemover's IO params are set to null
2019-01-22 18:05:31 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_60777c516364 inputCol, its NullRemover's IO params are set to null
2019-01-22 18:05:31 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 18:05:31 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-22 18:05:31 INFO  AbstractConnector:318 - Stopped Spark@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 18:05:31 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-22 18:05:31 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-22 18:05:31 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-22 18:05:32 INFO  BlockManager:54 - BlockManager stopped
2019-01-22 18:05:32 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-22 18:05:32 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-22 18:05:32 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-22 18:05:32 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-22 18:05:32 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-9a621fb3-c2bb-48da-8124-45a0fba30867
2019-01-22 18:05:46 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 18:05:46 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 18:05:46 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 18:05:46 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 18:05:46 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 18:05:46 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 18:05:46 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 18:05:46 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 18:05:46 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 18:05:47 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 52213.
2019-01-22 18:05:47 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 18:05:47 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 18:05:47 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 18:05:48 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 18:05:48 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-7942a5c8-9ede-4b87-86c7-6605b03556b6
2019-01-22 18:05:48 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 18:05:48 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 18:05:48 INFO  log:192 - Logging initialized @7136ms
2019-01-22 18:05:48 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 18:05:48 INFO  Server:419 - Started @7195ms
2019-01-22 18:05:48 INFO  AbstractConnector:278 - Started ServerConnector@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 18:05:48 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26221bad{/jobs,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@468dda3e{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1729ec00{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/static,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3062f9f4{/api,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 18:05:48 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 18:05:48 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52226.
2019-01-22 18:05:48 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:52226
2019-01-22 18:05:48 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 18:05:48 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 52226, None)
2019-01-22 18:05:48 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:52226 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 52226, None)
2019-01-22 18:05:48 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 52226, None)
2019-01-22 18:05:48 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 52226, None)
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12ad1b2a{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 18:05:48 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1624775{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@712ac7e6{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 18:05:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e43bfe{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 18:05:49 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-22 18:05:50 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:05:51 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-22 18:05:51 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:05:51 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:05:51 INFO  CodeGenerator:54 - Code generated in 163.882501 ms
2019-01-22 18:05:51 INFO  CodeGenerator:54 - Code generated in 16.5703 ms
2019-01-22 18:05:51 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-22 18:05:51 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-22 18:05:51 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:52226 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 18:05:51 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-22 18:05:51 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:05:51 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 18:05:51 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 18:05:51 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-22 18:05:51 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 18:05:51 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 18:05:51 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 18:05:51 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-22 18:05:51 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-22 18:05:51 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:52226 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 18:05:51 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-22 18:05:51 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 18:05:51 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-22 18:05:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-22 18:05:51 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-22 18:05:52 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 18:05:52 INFO  CodeGenerator:54 - Code generated in 8.101701 ms
2019-01-22 18:05:52 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2019-01-22 18:05:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 127 ms on localhost (executor driver) (1/1)
2019-01-22 18:05:52 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-22 18:05:52 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.212 s
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.257671 s
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:05:52 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:05:52 INFO  CodeGenerator:54 - Code generated in 7.101101 ms
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-22 18:05:52 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:52226 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 18:05:52 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-22 18:05:52 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:05:52 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 18:05:52 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:52226 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:05:52 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-22 18:05:52 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:05:52 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-22 18:05:52 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:52226 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 18:05:52 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 18:05:52 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-22 18:05:52 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-22 18:05:52 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-22 18:05:52 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 18:05:52 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1290 bytes result sent to driver
2019-01-22 18:05:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 11 ms on localhost (executor driver) (1/1)
2019-01-22 18:05:52 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-22 18:05:52 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.020 s
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.022784 s
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:05:52 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 18:05:52 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:52226 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:05:52 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-22 18:05:52 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:05:52 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 18:05:52 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:52226 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:05:52 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-22 18:05:52 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:05:52 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-22 18:05:52 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:52226 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 18:05:52 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 18:05:52 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-22 18:05:52 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-22 18:05:52 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-22 18:05:52 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-22 18:05:52 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1248 bytes result sent to driver
2019-01-22 18:05:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 8 ms on localhost (executor driver) (1/1)
2019-01-22 18:05:52 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-22 18:05:52 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.015 s
2019-01-22 18:05:52 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.017901 s
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 18:05:52 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:05:52 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 18:05:52 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-22 18:05:52 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:52226 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:05:52 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-22 18:05:52 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:05:52 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_321d95b544d2 inputCol, its NullRemover's IO params are set to null
2019-01-22 18:05:52 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_a2e6a058cffb inputCol, its NullRemover's IO params are set to null
2019-01-22 18:05:52 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 18:05:52 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_2b9c769032d8 inputCol, its NullRemover's IO params are set to null
2019-01-22 18:05:52 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_a5bbd8165e5b inputCol, its NullRemover's IO params are set to null
2019-01-22 18:05:52 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 18:07:33 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-22 18:07:33 INFO  AbstractConnector:318 - Stopped Spark@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 18:07:33 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-22 18:07:33 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-22 18:07:33 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-22 18:07:33 INFO  BlockManager:54 - BlockManager stopped
2019-01-22 18:07:33 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-22 18:07:33 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-22 18:07:33 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-22 18:07:33 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-22 18:07:33 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-57b4f9d5-f872-4d59-877a-4c7dad8f63c5
2019-01-22 18:17:37 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 18:17:37 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 18:17:37 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 18:17:37 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 18:17:37 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 18:17:37 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 18:17:37 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 18:17:37 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 18:17:37 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 18:17:38 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 52334.
2019-01-22 18:17:38 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 18:17:38 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 18:17:38 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 18:17:38 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 18:17:38 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-ce820042-076b-4250-a15f-ae42257948ec
2019-01-22 18:17:38 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 18:17:38 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 18:17:38 INFO  log:192 - Logging initialized @7125ms
2019-01-22 18:17:38 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 18:17:38 INFO  Server:419 - Started @7181ms
2019-01-22 18:17:38 INFO  AbstractConnector:278 - Started ServerConnector@568906d0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 18:17:38 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5c7668ba{/jobs,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10823d72{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54cf7c6a{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/stages,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b10ace9{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/storage,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/environment,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/executors,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/static,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@665522c2{/,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/api,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a237731{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 18:17:38 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 18:17:39 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 18:17:39 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52347.
2019-01-22 18:17:39 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:52347
2019-01-22 18:17:39 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 18:17:39 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 52347, None)
2019-01-22 18:17:39 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:52347 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 52347, None)
2019-01-22 18:17:39 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 52347, None)
2019-01-22 18:17:39 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 52347, None)
2019-01-22 18:17:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1697f2b3{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 18:17:39 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 18:17:39 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 18:17:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10e5bf9c{/SQL,null,AVAILABLE,@Spark}
2019-01-22 18:17:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 18:17:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4346808{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 18:17:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 18:17:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@ab24484{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 18:17:39 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-22 18:17:41 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:17:41 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-22 18:17:41 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:17:41 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:17:41 INFO  CodeGenerator:54 - Code generated in 166.0559 ms
2019-01-22 18:17:42 INFO  CodeGenerator:54 - Code generated in 16.9632 ms
2019-01-22 18:17:42 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-22 18:17:42 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-22 18:17:42 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:52347 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 18:17:42 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-22 18:17:42 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:17:42 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 18:17:42 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-22 18:17:42 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-22 18:17:42 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:52347 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 18:17:42 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 18:17:42 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-22 18:17:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-22 18:17:42 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-22 18:17:42 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 18:17:42 INFO  CodeGenerator:54 - Code generated in 11.7284 ms
2019-01-22 18:17:42 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2019-01-22 18:17:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 127 ms on localhost (executor driver) (1/1)
2019-01-22 18:17:42 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-22 18:17:42 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.219 s
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.271058 s
2019-01-22 18:17:42 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:17:42 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 18:17:42 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:17:42 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:17:42 INFO  CodeGenerator:54 - Code generated in 5.131299 ms
2019-01-22 18:17:42 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-22 18:17:42 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-22 18:17:42 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:52347 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 18:17:42 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-22 18:17:42 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:17:42 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:17:42 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-22 18:17:42 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:17:42 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:17:42 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 18:17:42 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 18:17:42 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:52347 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:17:42 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-22 18:17:42 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:17:42 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 18:17:42 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-22 18:17:42 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-22 18:17:42 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:52347 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 18:17:42 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 18:17:42 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-22 18:17:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-22 18:17:42 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-22 18:17:42 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 18:17:42 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1333 bytes result sent to driver
2019-01-22 18:17:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 11 ms on localhost (executor driver) (1/1)
2019-01-22 18:17:42 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-22 18:17:42 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.019 s
2019-01-22 18:17:42 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.021138 s
2019-01-22 18:17:42 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:17:42 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 18:17:42 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:17:42 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:17:42 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 18:17:43 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 18:17:43 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:52347 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:17:43 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-22 18:17:43 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:17:43 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:17:43 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-22 18:17:43 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:17:43 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:17:43 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 18:17:43 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 18:17:43 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:52347 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:17:43 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-22 18:17:43 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:17:43 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 18:17:43 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 18:17:43 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-22 18:17:43 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 18:17:43 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 18:17:43 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 18:17:43 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-22 18:17:43 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-22 18:17:43 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:52347 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 18:17:43 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-22 18:17:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 18:17:43 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-22 18:17:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-22 18:17:43 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-22 18:17:43 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-22 18:17:43 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1248 bytes result sent to driver
2019-01-22 18:17:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 8 ms on localhost (executor driver) (1/1)
2019-01-22 18:17:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-22 18:17:43 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.016 s
2019-01-22 18:17:43 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.017796 s
2019-01-22 18:17:43 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 18:17:43 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 18:17:43 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 18:17:43 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 18:17:43 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 18:17:43 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-22 18:17:43 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:52347 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 18:17:43 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-22 18:17:43 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 18:17:43 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_d768511a2b17 inputCol, its NullRemover's IO params are set to null
2019-01-22 18:17:43 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_8acaf1a0865a inputCol, its NullRemover's IO params are set to null
2019-01-22 18:17:43 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 18:17:43 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_ed4e4bf2c0a3 inputCol, its NullRemover's IO params are set to null
2019-01-22 18:17:43 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_29876cb849c9 inputCol, its NullRemover's IO params are set to null
2019-01-22 18:17:43 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 18:18:15 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-22 18:18:15 INFO  AbstractConnector:318 - Stopped Spark@568906d0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 18:18:15 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-22 18:18:15 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-22 18:18:15 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-22 18:18:15 INFO  BlockManager:54 - BlockManager stopped
2019-01-22 18:18:15 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-22 18:18:15 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-22 18:18:15 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-22 18:18:15 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-22 18:18:15 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-9a13d229-cca7-49a1-85d8-e8d6ff2d1bcb
2019-01-22 19:22:44 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 19:22:44 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 19:22:44 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 19:22:44 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 19:22:44 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 19:22:44 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 19:22:44 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 19:22:44 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 19:22:44 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 19:22:45 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 53153.
2019-01-22 19:22:45 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 19:22:45 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 19:22:45 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 19:22:45 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 19:22:45 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-a287d0a2-546c-438a-b1a5-dd6333364354
2019-01-22 19:22:45 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 19:22:45 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 19:22:45 INFO  log:192 - Logging initialized @7271ms
2019-01-22 19:22:45 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 19:22:45 INFO  Server:419 - Started @7336ms
2019-01-22 19:22:45 INFO  AbstractConnector:278 - Started ServerConnector@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 19:22:45 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26221bad{/jobs,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@468dda3e{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1729ec00{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/static,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3062f9f4{/api,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 19:22:45 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 19:22:45 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 19:22:45 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53166.
2019-01-22 19:22:45 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:53166
2019-01-22 19:22:45 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 19:22:45 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 53166, None)
2019-01-22 19:22:45 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:53166 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 53166, None)
2019-01-22 19:22:45 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 53166, None)
2019-01-22 19:22:45 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 53166, None)
2019-01-22 19:22:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12ad1b2a{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 19:22:46 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 19:22:46 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 19:22:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL,null,AVAILABLE,@Spark}
2019-01-22 19:22:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1624775{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 19:22:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 19:22:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@712ac7e6{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 19:22:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e43bfe{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 19:22:46 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-22 19:22:48 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:22:48 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-22 19:22:48 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:22:48 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:22:48 INFO  CodeGenerator:54 - Code generated in 168.854501 ms
2019-01-22 19:22:49 INFO  CodeGenerator:54 - Code generated in 16.1588 ms
2019-01-22 19:22:49 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-22 19:22:49 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-22 19:22:49 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:53166 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:22:49 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-22 19:22:49 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:22:49 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 19:22:49 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 19:22:49 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-22 19:22:49 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:22:49 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:22:49 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 19:22:49 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-22 19:22:49 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-22 19:22:49 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:53166 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 19:22:49 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:22:49 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:22:49 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-22 19:22:49 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-22 19:22:49 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-22 19:22:49 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 19:22:49 INFO  CodeGenerator:54 - Code generated in 8.7905 ms
2019-01-22 19:22:49 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1261 bytes result sent to driver
2019-01-22 19:22:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 124 ms on localhost (executor driver) (1/1)
2019-01-22 19:22:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-22 19:22:49 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.207 s
2019-01-22 19:22:49 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.250270 s
2019-01-22 19:22:49 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:22:49 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 19:22:49 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:22:49 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:22:49 INFO  CodeGenerator:54 - Code generated in 7.1218 ms
2019-01-22 19:22:49 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-22 19:22:49 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-22 19:22:49 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:53166 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:22:49 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-22 19:22:49 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:22:49 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:22:49 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-22 19:22:49 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:22:49 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:22:49 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 19:22:50 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 19:22:50 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:53166 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:22:50 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-22 19:22:50 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:22:50 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 19:22:50 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-22 19:22:50 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-22 19:22:50 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:53166 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:22:50 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:22:50 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-22 19:22:50 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-22 19:22:50 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-22 19:22:50 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:22:50 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1290 bytes result sent to driver
2019-01-22 19:22:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 12 ms on localhost (executor driver) (1/1)
2019-01-22 19:22:50 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-22 19:22:50 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.022 s
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.025017 s
2019-01-22 19:22:50 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:22:50 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 19:22:50 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:22:50 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:22:50 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 19:22:50 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 19:22:50 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:53166 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:22:50 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-22 19:22:50 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:22:50 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:22:50 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-22 19:22:50 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:22:50 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:22:50 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 19:22:50 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 19:22:50 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:53166 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:22:50 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-22 19:22:50 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:22:50 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 19:22:50 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-22 19:22:50 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-22 19:22:50 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:53166 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:22:50 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:22:50 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-22 19:22:50 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-22 19:22:50 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-22 19:22:50 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-22 19:22:50 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1205 bytes result sent to driver
2019-01-22 19:22:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 9 ms on localhost (executor driver) (1/1)
2019-01-22 19:22:50 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-22 19:22:50 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.017 s
2019-01-22 19:22:50 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.019424 s
2019-01-22 19:22:50 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:22:50 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 19:22:50 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:22:50 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:22:50 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 19:22:50 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-22 19:22:50 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:53166 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:22:50 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-22 19:22:50 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:22:50 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_0472da9de51f inputCol, its NullRemover's IO params are set to null
2019-01-22 19:22:50 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_45f954481959 inputCol, its NullRemover's IO params are set to null
2019-01-22 19:22:50 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 19:22:50 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_c208f6c9331e inputCol, its NullRemover's IO params are set to null
2019-01-22 19:22:50 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_655920f39cc9 inputCol, its NullRemover's IO params are set to null
2019-01-22 19:22:50 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 19:22:50 INFO  column remover:43 - removing column commit_content
2019-01-22 19:22:50 INFO  column remover:43 - removing column issue_content
2019-01-22 19:22:50 INFO  column remover:43 - removing column s_tokens
2019-01-22 19:22:50 INFO  column remover:43 - removing column t_tokens
2019-01-22 19:22:50 INFO  column remover:43 - removing column s_htf
2019-01-22 19:22:50 INFO  column remover:43 - removing column t_htf
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 66
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 20
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 70
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 75
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 98
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 51
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 68
2019-01-22 19:22:50 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on AshCloud-D1:53166 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 101
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 24
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 15
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 62
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 104
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 61
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 106
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 81
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 9
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 89
2019-01-22 19:22:50 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on AshCloud-D1:53166 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 74
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 93
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 41
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 64
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 45
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 94
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 73
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 71
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 52
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 79
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 53
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 54
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 40
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 72
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 78
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 47
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 82
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 28
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 12
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 26
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 90
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 60
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 44
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 6
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 69
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 65
2019-01-22 19:22:50 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on AshCloud-D1:53166 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 103
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 38
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 92
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 13
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 83
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 59
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 42
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 56
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 58
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 30
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 48
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 14
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 55
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 37
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 88
2019-01-22 19:22:50 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on AshCloud-D1:53166 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 96
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 107
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 23
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 11
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 19
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 80
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 46
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 91
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 77
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 57
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 7
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 49
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 10
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 105
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 36
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 95
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 85
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 27
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 102
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 39
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 29
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 100
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 50
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 86
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 84
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 16
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 76
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 21
2019-01-22 19:22:50 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:53166 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 8
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 67
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 87
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 18
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 25
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 99
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 22
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 17
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 63
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 97
2019-01-22 19:22:50 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on AshCloud-D1:53166 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:22:50 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on AshCloud-D1:53166 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:22:50 INFO  ContextCleaner:54 - Cleaned accumulator 43
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:22:51 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:22:51 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnotnull(UDF(UDF(commit_content#17)))
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-22 19:22:51 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:22:51 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:22:51 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:22:51 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:22:51 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:22:51 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:22:51 INFO  CodeGenerator:54 - Code generated in 37.0928 ms
2019-01-22 19:22:51 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 19:22:51 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 19:22:51 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on AshCloud-D1:53166 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:22:51 INFO  SparkContext:54 - Created broadcast 9 from rdd at IDF.scala:89
2019-01-22 19:22:51 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:22:51 INFO  CodeGenerator:54 - Code generated in 24.822 ms
2019-01-22 19:22:51 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 19:22:51 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.3 MB)
2019-01-22 19:22:51 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on AshCloud-D1:53166 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:22:51 INFO  SparkContext:54 - Created broadcast 10 from rdd at IDF.scala:89
2019-01-22 19:22:51 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:22:52 INFO  CodeGenerator:54 - Code generated in 24.167101 ms
2019-01-22 19:22:52 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 19:22:52 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 19:22:52 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on AshCloud-D1:53166 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:22:52 INFO  SparkContext:54 - Created broadcast 11 from rdd at IDF.scala:89
2019-01-22 19:22:52 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:22:52 INFO  CodeGenerator:54 - Code generated in 24.166301 ms
2019-01-22 19:22:52 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 19:22:52 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-22 19:22:52 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on AshCloud-D1:53166 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:22:52 INFO  SparkContext:54 - Created broadcast 12 from rdd at IDF.scala:89
2019-01-22 19:22:52 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:22:52 INFO  CodeGenerator:54 - Code generated in 24.3039 ms
2019-01-22 19:22:52 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 220.9 KB, free 1994.6 MB)
2019-01-22 19:22:52 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.5 MB)
2019-01-22 19:22:52 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on AshCloud-D1:53166 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:22:52 INFO  SparkContext:54 - Created broadcast 13 from rdd at IDF.scala:89
2019-01-22 19:22:52 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:22:52 INFO  CodeGenerator:54 - Code generated in 24.2691 ms
2019-01-22 19:22:52 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 220.9 KB, free 1994.3 MB)
2019-01-22 19:22:52 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.3 MB)
2019-01-22 19:22:52 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on AshCloud-D1:53166 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:22:52 INFO  SparkContext:54 - Created broadcast 14 from rdd at IDF.scala:89
2019-01-22 19:22:52 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:22:52 INFO  CodeGenerator:54 - Code generated in 20.145099 ms
2019-01-22 19:22:52 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 220.9 KB, free 1994.1 MB)
2019-01-22 19:22:52 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.1 MB)
2019-01-22 19:22:52 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on AshCloud-D1:53166 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:22:52 INFO  SparkContext:54 - Created broadcast 15 from rdd at IDF.scala:89
2019-01-22 19:22:52 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:22:52 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2019-01-22 19:22:52 INFO  DAGScheduler:54 - Registering RDD 67 (treeAggregate at IDF.scala:54)
2019-01-22 19:22:52 INFO  DAGScheduler:54 - Got job 3 (treeAggregate at IDF.scala:54) with 4 output partitions
2019-01-22 19:22:52 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (treeAggregate at IDF.scala:54)
2019-01-22 19:22:52 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 3)
2019-01-22 19:22:52 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 3)
2019-01-22 19:22:52 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-22 19:22:52 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 117.2 KB, free 1994.0 MB)
2019-01-22 19:22:52 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.9 KB, free 1993.9 MB)
2019-01-22 19:22:52 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on AshCloud-D1:53166 (size: 29.9 KB, free: 1996.0 MB)
2019-01-22 19:22:52 INFO  SparkContext:54 - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:22:52 INFO  DAGScheduler:54 - Submitting 23 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2019-01-22 19:22:52 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 23 tasks
2019-01-22 19:22:52 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:52 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2019-01-22 19:22:52 INFO  CodeGenerator:54 - Code generated in 10.4076 ms
2019-01-22 19:22:52 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 4615 bytes result sent to driver
2019-01-22 19:22:52 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:52 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 4)
2019-01-22 19:22:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 108 ms on localhost (executor driver) (1/23)
2019-01-22 19:22:52 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 4). 4529 bytes result sent to driver
2019-01-22 19:22:52 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 5, localhost, executor driver, partition 2, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:22:52 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 5)
2019-01-22 19:22:52 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 4) in 25 ms on localhost (executor driver) (2/23)
2019-01-22 19:22:52 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:22:52 INFO  CodeGenerator:54 - Code generated in 6.918399 ms
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 5). 4658 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 3.0 in stage 3.0 (TID 6, localhost, executor driver, partition 3, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 3.0 in stage 3.0 (TID 6)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 5) in 583 ms on localhost (executor driver) (3/23)
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 3.0 in stage 3.0 (TID 6). 4529 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 4.0 in stage 3.0 (TID 7, localhost, executor driver, partition 4, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 4.0 in stage 3.0 (TID 7)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 3.0 in stage 3.0 (TID 6) in 16 ms on localhost (executor driver) (4/23)
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 4.0 in stage 3.0 (TID 7). 4529 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 5.0 in stage 3.0 (TID 8, localhost, executor driver, partition 5, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 5.0 in stage 3.0 (TID 8)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 4.0 in stage 3.0 (TID 7) in 15 ms on localhost (executor driver) (5/23)
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 5.0 in stage 3.0 (TID 8). 4529 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 6.0 in stage 3.0 (TID 9, localhost, executor driver, partition 6, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 6.0 in stage 3.0 (TID 9)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 5.0 in stage 3.0 (TID 8) in 17 ms on localhost (executor driver) (6/23)
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 6.0 in stage 3.0 (TID 9). 4486 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 7.0 in stage 3.0 (TID 10, localhost, executor driver, partition 7, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 7.0 in stage 3.0 (TID 10)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 6.0 in stage 3.0 (TID 9) in 16 ms on localhost (executor driver) (7/23)
2019-01-22 19:22:53 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 7.0 in stage 3.0 (TID 10). 4615 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 8.0 in stage 3.0 (TID 11, localhost, executor driver, partition 8, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 8.0 in stage 3.0 (TID 11)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 7.0 in stage 3.0 (TID 10) in 41 ms on localhost (executor driver) (8/23)
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 8.0 in stage 3.0 (TID 11). 4529 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 9.0 in stage 3.0 (TID 12, localhost, executor driver, partition 9, PROCESS_LOCAL, 8437 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 9.0 in stage 3.0 (TID 12)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 8.0 in stage 3.0 (TID 11) in 22 ms on localhost (executor driver) (9/23)
2019-01-22 19:22:53 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 9.0 in stage 3.0 (TID 12). 4658 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 10.0 in stage 3.0 (TID 13, localhost, executor driver, partition 10, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 10.0 in stage 3.0 (TID 13)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 9.0 in stage 3.0 (TID 12) in 424 ms on localhost (executor driver) (10/23)
2019-01-22 19:22:53 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 10.0 in stage 3.0 (TID 13). 4615 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 11.0 in stage 3.0 (TID 14, localhost, executor driver, partition 11, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 11.0 in stage 3.0 (TID 14)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 10.0 in stage 3.0 (TID 13) in 33 ms on localhost (executor driver) (11/23)
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 11.0 in stage 3.0 (TID 14). 4529 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 12.0 in stage 3.0 (TID 15, localhost, executor driver, partition 12, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 12.0 in stage 3.0 (TID 15)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 11.0 in stage 3.0 (TID 14) in 17 ms on localhost (executor driver) (12/23)
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 12.0 in stage 3.0 (TID 15). 4486 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 13.0 in stage 3.0 (TID 16, localhost, executor driver, partition 13, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 13.0 in stage 3.0 (TID 16)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 12.0 in stage 3.0 (TID 15) in 16 ms on localhost (executor driver) (13/23)
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 13.0 in stage 3.0 (TID 16). 4529 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 14.0 in stage 3.0 (TID 17, localhost, executor driver, partition 14, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 14.0 in stage 3.0 (TID 17)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 13.0 in stage 3.0 (TID 16) in 14 ms on localhost (executor driver) (14/23)
2019-01-22 19:22:53 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 14.0 in stage 3.0 (TID 17). 4615 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 15.0 in stage 3.0 (TID 18, localhost, executor driver, partition 15, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 15.0 in stage 3.0 (TID 18)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 14.0 in stage 3.0 (TID 17) in 75 ms on localhost (executor driver) (15/23)
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 15.0 in stage 3.0 (TID 18). 4529 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 16.0 in stage 3.0 (TID 19, localhost, executor driver, partition 16, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 16.0 in stage 3.0 (TID 19)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 15.0 in stage 3.0 (TID 18) in 17 ms on localhost (executor driver) (16/23)
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 16.0 in stage 3.0 (TID 19). 4529 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 17.0 in stage 3.0 (TID 20, localhost, executor driver, partition 17, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 17.0 in stage 3.0 (TID 20)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 16.0 in stage 3.0 (TID 19) in 13 ms on localhost (executor driver) (17/23)
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 17.0 in stage 3.0 (TID 20). 4529 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 18.0 in stage 3.0 (TID 21, localhost, executor driver, partition 18, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 18.0 in stage 3.0 (TID 21)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 17.0 in stage 3.0 (TID 20) in 16 ms on localhost (executor driver) (18/23)
2019-01-22 19:22:53 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 18.0 in stage 3.0 (TID 21). 4615 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 19.0 in stage 3.0 (TID 22, localhost, executor driver, partition 19, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 19.0 in stage 3.0 (TID 22)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 18.0 in stage 3.0 (TID 21) in 25 ms on localhost (executor driver) (19/23)
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 19.0 in stage 3.0 (TID 22). 4529 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 20.0 in stage 3.0 (TID 23, localhost, executor driver, partition 20, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 20.0 in stage 3.0 (TID 23)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 19.0 in stage 3.0 (TID 22) in 14 ms on localhost (executor driver) (20/23)
2019-01-22 19:22:53 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 20.0 in stage 3.0 (TID 23). 4615 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 21.0 in stage 3.0 (TID 24, localhost, executor driver, partition 21, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 21.0 in stage 3.0 (TID 24)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 20.0 in stage 3.0 (TID 23) in 29 ms on localhost (executor driver) (21/23)
2019-01-22 19:22:53 INFO  Executor:54 - Finished task 21.0 in stage 3.0 (TID 24). 4486 bytes result sent to driver
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Starting task 22.0 in stage 3.0 (TID 25, localhost, executor driver, partition 22, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:22:53 INFO  Executor:54 - Running task 22.0 in stage 3.0 (TID 25)
2019-01-22 19:22:53 INFO  TaskSetManager:54 - Finished task 21.0 in stage 3.0 (TID 24) in 13 ms on localhost (executor driver) (22/23)
2019-01-22 19:22:54 INFO  Executor:54 - Finished task 22.0 in stage 3.0 (TID 25). 4529 bytes result sent to driver
2019-01-22 19:22:54 INFO  TaskSetManager:54 - Finished task 22.0 in stage 3.0 (TID 25) in 15 ms on localhost (executor driver) (23/23)
2019-01-22 19:22:54 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2019-01-22 19:22:54 INFO  DAGScheduler:54 - ShuffleMapStage 3 (treeAggregate at IDF.scala:54) finished in 1.570 s
2019-01-22 19:22:54 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-01-22 19:22:54 INFO  DAGScheduler:54 - running: Set()
2019-01-22 19:22:54 INFO  DAGScheduler:54 - waiting: Set(ResultStage 4)
2019-01-22 19:22:54 INFO  DAGScheduler:54 - failed: Set()
2019-01-22 19:22:54 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-22 19:22:54 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 118.1 KB, free 1993.8 MB)
2019-01-22 19:22:54 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 30.4 KB, free 1993.8 MB)
2019-01-22 19:22:54 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on AshCloud-D1:53166 (size: 30.4 KB, free: 1996.0 MB)
2019-01-22 19:22:54 INFO  SparkContext:54 - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:22:54 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-01-22 19:22:54 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 4 tasks
2019-01-22 19:22:54 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 26, localhost, executor driver, partition 0, ANY, 7649 bytes)
2019-01-22 19:22:54 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 26)
2019-01-22 19:22:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-22 19:22:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 5 ms
2019-01-22 19:22:54 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 26). 4745 bytes result sent to driver
2019-01-22 19:22:54 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 27, localhost, executor driver, partition 1, ANY, 7649 bytes)
2019-01-22 19:22:54 INFO  Executor:54 - Running task 1.0 in stage 4.0 (TID 27)
2019-01-22 19:22:54 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 26) in 48 ms on localhost (executor driver) (1/4)
2019-01-22 19:22:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-22 19:22:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2019-01-22 19:22:54 INFO  MemoryStore:54 - Block taskresult_27 stored as bytes in memory (estimated size 2.0 MB, free 1991.8 MB)
2019-01-22 19:22:54 INFO  BlockManagerInfo:54 - Added taskresult_27 in memory on AshCloud-D1:53166 (size: 2.0 MB, free: 1993.9 MB)
2019-01-22 19:22:54 INFO  Executor:54 - Finished task 1.0 in stage 4.0 (TID 27). 2112329 bytes result sent via BlockManager)
2019-01-22 19:22:54 INFO  TaskSetManager:54 - Starting task 2.0 in stage 4.0 (TID 28, localhost, executor driver, partition 2, ANY, 7649 bytes)
2019-01-22 19:22:54 INFO  Executor:54 - Running task 2.0 in stage 4.0 (TID 28)
2019-01-22 19:22:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-22 19:22:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2019-01-22 19:22:54 INFO  MemoryStore:54 - Block taskresult_28 stored as bytes in memory (estimated size 2.0 MB, free 1989.8 MB)
2019-01-22 19:22:54 INFO  BlockManagerInfo:54 - Added taskresult_28 in memory on AshCloud-D1:53166 (size: 2.0 MB, free: 1991.9 MB)
2019-01-22 19:22:54 INFO  Executor:54 - Finished task 2.0 in stage 4.0 (TID 28). 2112329 bytes result sent via BlockManager)
2019-01-22 19:22:54 INFO  TaskSetManager:54 - Starting task 3.0 in stage 4.0 (TID 29, localhost, executor driver, partition 3, ANY, 7649 bytes)
2019-01-22 19:22:54 INFO  Executor:54 - Running task 3.0 in stage 4.0 (TID 29)
2019-01-22 19:22:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 5 non-empty blocks out of 23 blocks
2019-01-22 19:22:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2019-01-22 19:22:54 INFO  Executor:54 - Finished task 3.0 in stage 4.0 (TID 29). 4745 bytes result sent to driver
2019-01-22 19:22:54 INFO  TaskSetManager:54 - Finished task 3.0 in stage 4.0 (TID 29) in 15 ms on localhost (executor driver) (2/4)
2019-01-22 19:22:54 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:53166 after 53 ms (0 ms spent in bootstraps)
2019-01-22 19:22:54 INFO  TaskSetManager:54 - Finished task 2.0 in stage 4.0 (TID 28) in 158 ms on localhost (executor driver) (3/4)
2019-01-22 19:22:54 INFO  BlockManagerInfo:54 - Removed taskresult_28 on AshCloud-D1:53166 in memory (size: 2.0 MB, free: 1993.9 MB)
2019-01-22 19:22:54 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 27) in 206 ms on localhost (executor driver) (4/4)
2019-01-22 19:22:54 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2019-01-22 19:22:54 INFO  BlockManagerInfo:54 - Removed taskresult_27 on AshCloud-D1:53166 in memory (size: 2.0 MB, free: 1996.0 MB)
2019-01-22 19:22:54 INFO  DAGScheduler:54 - ResultStage 4 (treeAggregate at IDF.scala:54) finished in 0.294 s
2019-01-22 19:22:54 INFO  DAGScheduler:54 - Job 3 finished: treeAggregate at IDF.scala:54, took 1.894517 s
2019-01-22 19:23:07 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on AshCloud-D1:53166 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 123
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 127
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 193
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 190
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 164
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 141
2019-01-22 19:23:07 INFO  BlockManagerInfo:54 - Removed broadcast_15_piece0 on AshCloud-D1:53166 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 178
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 163
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 137
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 172
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 175
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 173
2019-01-22 19:23:07 INFO  BlockManagerInfo:54 - Removed broadcast_16_piece0 on AshCloud-D1:53166 in memory (size: 29.9 KB, free: 1996.0 MB)
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 132
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 155
2019-01-22 19:23:07 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on AshCloud-D1:53166 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 136
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 112
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 159
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 154
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 195
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 120
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 151
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 113
2019-01-22 19:23:07 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on AshCloud-D1:53166 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 119
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 188
2019-01-22 19:23:07 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on AshCloud-D1:53166 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 146
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned shuffle 0
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 134
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 131
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 126
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 138
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 168
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 176
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 157
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 194
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 149
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 169
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 199
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 203
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 142
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 204
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 167
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 143
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 162
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 150
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 180
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 135
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 128
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 158
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 124
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 202
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 153
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 122
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 186
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 185
2019-01-22 19:23:07 INFO  BlockManagerInfo:54 - Removed broadcast_17_piece0 on AshCloud-D1:53166 in memory (size: 30.4 KB, free: 1996.1 MB)
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 165
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 108
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 114
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 177
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 191
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 156
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 144
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 152
2019-01-22 19:23:07 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on AshCloud-D1:53166 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 179
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 196
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 200
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 145
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 198
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 118
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 174
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 160
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 130
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 166
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 181
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 140
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 183
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 182
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 171
2019-01-22 19:23:07 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on AshCloud-D1:53166 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 192
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 133
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 116
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 161
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 197
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 147
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 110
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 184
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 129
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 139
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 111
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 115
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 189
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 201
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 187
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 109
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 121
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 148
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 170
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 117
2019-01-22 19:23:07 INFO  ContextCleaner:54 - Cleaned accumulator 125
2019-01-22 19:23:08 INFO  column remover:43 - removing column commit_content
2019-01-22 19:23:08 INFO  column remover:43 - removing column issue_content
2019-01-22 19:23:08 INFO  column remover:43 - removing column s_tokens
2019-01-22 19:23:08 INFO  column remover:43 - removing column t_tokens
2019-01-22 19:23:08 INFO  column remover:43 - removing column s_htf
2019-01-22 19:23:08 INFO  column remover:43 - removing column t_htf
2019-01-22 19:23:09 INFO  column remover:43 - removing column commit_content
2019-01-22 19:23:09 INFO  column remover:43 - removing column issue_content
2019-01-22 19:23:09 INFO  column remover:43 - removing column s_tokens
2019-01-22 19:23:09 INFO  column remover:43 - removing column t_tokens
2019-01-22 19:23:09 INFO  column remover:43 - removing column s_htf
2019-01-22 19:23:09 INFO  column remover:43 - removing column t_htf
2019-01-22 19:23:10 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-22 19:23:10 INFO  AbstractConnector:318 - Stopped Spark@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 19:23:10 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-22 19:23:10 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-22 19:23:10 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-22 19:23:10 INFO  BlockManager:54 - BlockManager stopped
2019-01-22 19:23:10 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-22 19:23:10 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-22 19:23:10 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-22 19:23:10 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-22 19:23:10 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-e1293c4d-cabb-4ece-bb7c-65e77f8192e0
2019-01-22 19:53:37 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 19:53:37 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 19:53:37 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 19:53:37 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 19:53:38 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 19:53:38 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 19:53:38 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 19:53:38 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 19:53:38 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 19:53:39 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 53472.
2019-01-22 19:53:39 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 19:53:39 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 19:53:39 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 19:53:39 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 19:53:39 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-50a17e10-8893-40b4-9a4f-cba3a23ff7a5
2019-01-22 19:53:39 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 19:53:39 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 19:53:39 INFO  log:192 - Logging initialized @7143ms
2019-01-22 19:53:39 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 19:53:39 INFO  Server:419 - Started @7198ms
2019-01-22 19:53:39 INFO  AbstractConnector:278 - Started ServerConnector@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 19:53:39 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26221bad{/jobs,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@468dda3e{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1729ec00{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/static,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3062f9f4{/api,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 19:53:39 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 19:53:39 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53485.
2019-01-22 19:53:39 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:53485
2019-01-22 19:53:39 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 19:53:39 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 53485, None)
2019-01-22 19:53:39 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:53485 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 53485, None)
2019-01-22 19:53:39 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 53485, None)
2019-01-22 19:53:39 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 53485, None)
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12ad1b2a{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 19:53:39 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1624775{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@712ac7e6{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 19:53:39 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e43bfe{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 19:53:40 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-22 19:53:42 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:53:42 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-22 19:53:42 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:53:42 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:53:42 INFO  CodeGenerator:54 - Code generated in 169.437401 ms
2019-01-22 19:53:42 INFO  CodeGenerator:54 - Code generated in 16.958 ms
2019-01-22 19:53:42 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-22 19:53:42 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-22 19:53:42 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:53:42 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-22 19:53:42 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:53:42 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 19:53:42 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 19:53:42 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-22 19:53:42 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:53:42 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:53:42 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-22 19:53:43 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:53485 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 19:53:43 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:53:43 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-22 19:53:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-22 19:53:43 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-22 19:53:43 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 19:53:43 INFO  CodeGenerator:54 - Code generated in 9.3423 ms
2019-01-22 19:53:43 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2019-01-22 19:53:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 124 ms on localhost (executor driver) (1/1)
2019-01-22 19:53:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-22 19:53:43 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.201 s
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.241613 s
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:53:43 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:53:43 INFO  CodeGenerator:54 - Code generated in 5.726201 ms
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-22 19:53:43 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:53:43 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-22 19:53:43 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:53:43 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 19:53:43 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:43 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-22 19:53:43 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:53:43 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-22 19:53:43 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:53485 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:53:43 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:53:43 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-22 19:53:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-22 19:53:43 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-22 19:53:43 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:53:43 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1333 bytes result sent to driver
2019-01-22 19:53:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 9 ms on localhost (executor driver) (1/1)
2019-01-22 19:53:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-22 19:53:43 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.019 s
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.021391 s
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:53:43 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 19:53:43 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:43 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-22 19:53:43 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:53:43 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 19:53:43 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:43 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-22 19:53:43 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:53:43 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-22 19:53:43 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:53485 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:53:43 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:53:43 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-22 19:53:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-22 19:53:43 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-22 19:53:43 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-22 19:53:43 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1248 bytes result sent to driver
2019-01-22 19:53:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 11 ms on localhost (executor driver) (1/1)
2019-01-22 19:53:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-22 19:53:43 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.019 s
2019-01-22 19:53:43 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.020820 s
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 19:53:43 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:53:43 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 19:53:43 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-22 19:53:43 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:43 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-22 19:53:43 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:53:43 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_f4b26bc00c1b inputCol, its NullRemover's IO params are set to null
2019-01-22 19:53:43 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_045594997d4a inputCol, its NullRemover's IO params are set to null
2019-01-22 19:53:43 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 19:53:43 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_9cdd62328486 inputCol, its NullRemover's IO params are set to null
2019-01-22 19:53:43 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_4c4ffe6915de inputCol, its NullRemover's IO params are set to null
2019-01-22 19:53:43 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 19:53:43 INFO  column remover:43 - removing column commit_content
2019-01-22 19:53:43 INFO  column remover:43 - removing column issue_content
2019-01-22 19:53:43 INFO  column remover:43 - removing column s_tokens
2019-01-22 19:53:43 INFO  column remover:43 - removing column t_tokens
2019-01-22 19:53:43 INFO  column remover:43 - removing column s_htf
2019-01-22 19:53:43 INFO  column remover:43 - removing column t_htf
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 63
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 90
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 70
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 60
2019-01-22 19:53:44 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:53485 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 75
2019-01-22 19:53:44 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on AshCloud-D1:53485 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 68
2019-01-22 19:53:44 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 104
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 106
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 54
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 65
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 74
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 55
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 66
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 44
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 41
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 93
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 19
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 28
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 73
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 45
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 71
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 12
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 51
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 6
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 26
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 82
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 94
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 100
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 40
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 72
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 64
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 17
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 59
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 11
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 91
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 79
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 97
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 62
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 87
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 69
2019-01-22 19:53:44 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 85
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 103
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 8
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 18
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 38
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 46
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 99
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 15
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 49
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 10
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 88
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 37
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 29
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 9
2019-01-22 19:53:44 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on AshCloud-D1:53485 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 107
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 58
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 43
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 98
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 77
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 22
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 30
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 105
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 25
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 36
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 47
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 16
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 96
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 56
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 84
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 13
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 39
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 92
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 102
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 61
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 14
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 83
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 76
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 95
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 23
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 21
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 80
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 89
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 78
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 42
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 50
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 86
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 67
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 24
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 48
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 7
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 81
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 53
2019-01-22 19:53:44 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 27
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 20
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 57
2019-01-22 19:53:44 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 101
2019-01-22 19:53:44 INFO  ContextCleaner:54 - Cleaned accumulator 52
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnotnull(UDF(UDF(commit_content#17)))
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:53:45 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:53:45 INFO  CodeGenerator:54 - Code generated in 36.611 ms
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 19:53:45 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:45 INFO  SparkContext:54 - Created broadcast 9 from rdd at IDF.scala:89
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:53:45 INFO  CodeGenerator:54 - Code generated in 27.9224 ms
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.3 MB)
2019-01-22 19:53:45 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:45 INFO  SparkContext:54 - Created broadcast 10 from rdd at IDF.scala:89
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:53:45 INFO  CodeGenerator:54 - Code generated in 28.631 ms
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 19:53:45 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:45 INFO  SparkContext:54 - Created broadcast 11 from rdd at IDF.scala:89
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:53:45 INFO  CodeGenerator:54 - Code generated in 23.244499 ms
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-22 19:53:45 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:45 INFO  SparkContext:54 - Created broadcast 12 from rdd at IDF.scala:89
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:53:45 INFO  CodeGenerator:54 - Code generated in 19.599 ms
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 220.9 KB, free 1994.6 MB)
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.5 MB)
2019-01-22 19:53:45 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:45 INFO  SparkContext:54 - Created broadcast 13 from rdd at IDF.scala:89
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:53:45 INFO  CodeGenerator:54 - Code generated in 24.1085 ms
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 220.9 KB, free 1994.3 MB)
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.3 MB)
2019-01-22 19:53:45 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:53:45 INFO  SparkContext:54 - Created broadcast 14 from rdd at IDF.scala:89
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:53:45 INFO  CodeGenerator:54 - Code generated in 18.5811 ms
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 220.9 KB, free 1994.1 MB)
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.1 MB)
2019-01-22 19:53:45 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:53:45 INFO  SparkContext:54 - Created broadcast 15 from rdd at IDF.scala:89
2019-01-22 19:53:45 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:53:45 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2019-01-22 19:53:45 INFO  DAGScheduler:54 - Registering RDD 67 (treeAggregate at IDF.scala:54)
2019-01-22 19:53:45 INFO  DAGScheduler:54 - Got job 3 (treeAggregate at IDF.scala:54) with 4 output partitions
2019-01-22 19:53:45 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (treeAggregate at IDF.scala:54)
2019-01-22 19:53:45 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 3)
2019-01-22 19:53:45 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 3)
2019-01-22 19:53:45 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 117.2 KB, free 1994.0 MB)
2019-01-22 19:53:45 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.9 KB, free 1993.9 MB)
2019-01-22 19:53:45 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on AshCloud-D1:53485 (size: 29.9 KB, free: 1996.0 MB)
2019-01-22 19:53:45 INFO  SparkContext:54 - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:53:45 INFO  DAGScheduler:54 - Submitting 23 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2019-01-22 19:53:45 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 23 tasks
2019-01-22 19:53:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:45 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2019-01-22 19:53:45 INFO  CodeGenerator:54 - Code generated in 10.122701 ms
2019-01-22 19:53:45 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 4615 bytes result sent to driver
2019-01-22 19:53:45 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:45 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 4)
2019-01-22 19:53:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 87 ms on localhost (executor driver) (1/23)
2019-01-22 19:53:45 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 4). 4529 bytes result sent to driver
2019-01-22 19:53:45 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 5, localhost, executor driver, partition 2, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:53:45 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 5)
2019-01-22 19:53:45 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 4) in 30 ms on localhost (executor driver) (2/23)
2019-01-22 19:53:45 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:53:45 INFO  CodeGenerator:54 - Code generated in 5.5173 ms
2019-01-22 19:53:46 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 5). 4658 bytes result sent to driver
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Starting task 3.0 in stage 3.0 (TID 6, localhost, executor driver, partition 3, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:46 INFO  Executor:54 - Running task 3.0 in stage 3.0 (TID 6)
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 5) in 523 ms on localhost (executor driver) (3/23)
2019-01-22 19:53:46 INFO  Executor:54 - Finished task 3.0 in stage 3.0 (TID 6). 4529 bytes result sent to driver
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Starting task 4.0 in stage 3.0 (TID 7, localhost, executor driver, partition 4, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:46 INFO  Executor:54 - Running task 4.0 in stage 3.0 (TID 7)
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Finished task 3.0 in stage 3.0 (TID 6) in 15 ms on localhost (executor driver) (4/23)
2019-01-22 19:53:46 INFO  Executor:54 - Finished task 4.0 in stage 3.0 (TID 7). 4529 bytes result sent to driver
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Starting task 5.0 in stage 3.0 (TID 8, localhost, executor driver, partition 5, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:46 INFO  Executor:54 - Running task 5.0 in stage 3.0 (TID 8)
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Finished task 4.0 in stage 3.0 (TID 7) in 14 ms on localhost (executor driver) (5/23)
2019-01-22 19:53:46 INFO  Executor:54 - Finished task 5.0 in stage 3.0 (TID 8). 4486 bytes result sent to driver
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Starting task 6.0 in stage 3.0 (TID 9, localhost, executor driver, partition 6, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:46 INFO  Executor:54 - Running task 6.0 in stage 3.0 (TID 9)
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Finished task 5.0 in stage 3.0 (TID 8) in 18 ms on localhost (executor driver) (6/23)
2019-01-22 19:53:46 INFO  Executor:54 - Finished task 6.0 in stage 3.0 (TID 9). 4529 bytes result sent to driver
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Starting task 7.0 in stage 3.0 (TID 10, localhost, executor driver, partition 7, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:53:46 INFO  Executor:54 - Running task 7.0 in stage 3.0 (TID 10)
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Finished task 6.0 in stage 3.0 (TID 9) in 15 ms on localhost (executor driver) (7/23)
2019-01-22 19:53:46 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:53:46 INFO  Executor:54 - Finished task 7.0 in stage 3.0 (TID 10). 4615 bytes result sent to driver
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Starting task 8.0 in stage 3.0 (TID 11, localhost, executor driver, partition 8, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:46 INFO  Executor:54 - Running task 8.0 in stage 3.0 (TID 11)
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Finished task 7.0 in stage 3.0 (TID 10) in 47 ms on localhost (executor driver) (8/23)
2019-01-22 19:53:46 INFO  Executor:54 - Finished task 8.0 in stage 3.0 (TID 11). 4529 bytes result sent to driver
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Starting task 9.0 in stage 3.0 (TID 12, localhost, executor driver, partition 9, PROCESS_LOCAL, 8437 bytes)
2019-01-22 19:53:46 INFO  Executor:54 - Running task 9.0 in stage 3.0 (TID 12)
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Finished task 8.0 in stage 3.0 (TID 11) in 17 ms on localhost (executor driver) (9/23)
2019-01-22 19:53:46 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 19:53:46 INFO  Executor:54 - Finished task 9.0 in stage 3.0 (TID 12). 4658 bytes result sent to driver
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Starting task 10.0 in stage 3.0 (TID 13, localhost, executor driver, partition 10, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:53:46 INFO  Executor:54 - Running task 10.0 in stage 3.0 (TID 13)
2019-01-22 19:53:46 INFO  TaskSetManager:54 - Finished task 9.0 in stage 3.0 (TID 12) in 455 ms on localhost (executor driver) (10/23)
2019-01-22 19:53:46 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 10.0 in stage 3.0 (TID 13). 4615 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 11.0 in stage 3.0 (TID 14, localhost, executor driver, partition 11, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 11.0 in stage 3.0 (TID 14)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 10.0 in stage 3.0 (TID 13) in 32 ms on localhost (executor driver) (11/23)
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 11.0 in stage 3.0 (TID 14). 4529 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 12.0 in stage 3.0 (TID 15, localhost, executor driver, partition 12, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 12.0 in stage 3.0 (TID 15)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 11.0 in stage 3.0 (TID 14) in 15 ms on localhost (executor driver) (12/23)
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 12.0 in stage 3.0 (TID 15). 4486 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 13.0 in stage 3.0 (TID 16, localhost, executor driver, partition 13, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 13.0 in stage 3.0 (TID 16)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 12.0 in stage 3.0 (TID 15) in 15 ms on localhost (executor driver) (13/23)
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 13.0 in stage 3.0 (TID 16). 4529 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 14.0 in stage 3.0 (TID 17, localhost, executor driver, partition 14, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 14.0 in stage 3.0 (TID 17)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 13.0 in stage 3.0 (TID 16) in 13 ms on localhost (executor driver) (14/23)
2019-01-22 19:53:47 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 14.0 in stage 3.0 (TID 17). 4615 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 15.0 in stage 3.0 (TID 18, localhost, executor driver, partition 15, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 15.0 in stage 3.0 (TID 18)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 14.0 in stage 3.0 (TID 17) in 67 ms on localhost (executor driver) (15/23)
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 15.0 in stage 3.0 (TID 18). 4529 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 16.0 in stage 3.0 (TID 19, localhost, executor driver, partition 16, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 16.0 in stage 3.0 (TID 19)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 15.0 in stage 3.0 (TID 18) in 20 ms on localhost (executor driver) (16/23)
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 16.0 in stage 3.0 (TID 19). 4529 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 17.0 in stage 3.0 (TID 20, localhost, executor driver, partition 17, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 17.0 in stage 3.0 (TID 20)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 16.0 in stage 3.0 (TID 19) in 13 ms on localhost (executor driver) (17/23)
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 17.0 in stage 3.0 (TID 20). 4529 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 18.0 in stage 3.0 (TID 21, localhost, executor driver, partition 18, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 18.0 in stage 3.0 (TID 21)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 17.0 in stage 3.0 (TID 20) in 14 ms on localhost (executor driver) (18/23)
2019-01-22 19:53:47 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 18.0 in stage 3.0 (TID 21). 4615 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 19.0 in stage 3.0 (TID 22, localhost, executor driver, partition 19, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 19.0 in stage 3.0 (TID 22)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 18.0 in stage 3.0 (TID 21) in 25 ms on localhost (executor driver) (19/23)
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 19.0 in stage 3.0 (TID 22). 4529 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 20.0 in stage 3.0 (TID 23, localhost, executor driver, partition 20, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 20.0 in stage 3.0 (TID 23)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 19.0 in stage 3.0 (TID 22) in 16 ms on localhost (executor driver) (20/23)
2019-01-22 19:53:47 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 20.0 in stage 3.0 (TID 23). 4615 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 21.0 in stage 3.0 (TID 24, localhost, executor driver, partition 21, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 21.0 in stage 3.0 (TID 24)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 20.0 in stage 3.0 (TID 23) in 27 ms on localhost (executor driver) (21/23)
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 21.0 in stage 3.0 (TID 24). 4529 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 22.0 in stage 3.0 (TID 25, localhost, executor driver, partition 22, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 22.0 in stage 3.0 (TID 25)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 21.0 in stage 3.0 (TID 24) in 15 ms on localhost (executor driver) (22/23)
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 22.0 in stage 3.0 (TID 25). 4529 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 22.0 in stage 3.0 (TID 25) in 16 ms on localhost (executor driver) (23/23)
2019-01-22 19:53:47 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2019-01-22 19:53:47 INFO  DAGScheduler:54 - ShuffleMapStage 3 (treeAggregate at IDF.scala:54) finished in 1.498 s
2019-01-22 19:53:47 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-01-22 19:53:47 INFO  DAGScheduler:54 - running: Set()
2019-01-22 19:53:47 INFO  DAGScheduler:54 - waiting: Set(ResultStage 4)
2019-01-22 19:53:47 INFO  DAGScheduler:54 - failed: Set()
2019-01-22 19:53:47 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-22 19:53:47 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 118.1 KB, free 1993.8 MB)
2019-01-22 19:53:47 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 30.4 KB, free 1993.8 MB)
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on AshCloud-D1:53485 (size: 30.4 KB, free: 1996.0 MB)
2019-01-22 19:53:47 INFO  SparkContext:54 - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:53:47 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-01-22 19:53:47 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 4 tasks
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 26, localhost, executor driver, partition 0, ANY, 7649 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 26)
2019-01-22 19:53:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-22 19:53:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 5 ms
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 26). 4745 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 27, localhost, executor driver, partition 1, ANY, 7649 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 1.0 in stage 4.0 (TID 27)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 26) in 40 ms on localhost (executor driver) (1/4)
2019-01-22 19:53:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-22 19:53:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2019-01-22 19:53:47 INFO  MemoryStore:54 - Block taskresult_27 stored as bytes in memory (estimated size 2.0 MB, free 1991.8 MB)
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Added taskresult_27 in memory on AshCloud-D1:53485 (size: 2.0 MB, free: 1993.9 MB)
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 1.0 in stage 4.0 (TID 27). 2112329 bytes result sent via BlockManager)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 2.0 in stage 4.0 (TID 28, localhost, executor driver, partition 2, ANY, 7649 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 2.0 in stage 4.0 (TID 28)
2019-01-22 19:53:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-22 19:53:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-22 19:53:47 INFO  MemoryStore:54 - Block taskresult_28 stored as bytes in memory (estimated size 2.0 MB, free 1989.8 MB)
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Added taskresult_28 in memory on AshCloud-D1:53485 (size: 2.0 MB, free: 1991.9 MB)
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 2.0 in stage 4.0 (TID 28). 2112329 bytes result sent via BlockManager)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Starting task 3.0 in stage 4.0 (TID 29, localhost, executor driver, partition 3, ANY, 7649 bytes)
2019-01-22 19:53:47 INFO  Executor:54 - Running task 3.0 in stage 4.0 (TID 29)
2019-01-22 19:53:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 5 non-empty blocks out of 23 blocks
2019-01-22 19:53:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-22 19:53:47 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:53485 after 47 ms (0 ms spent in bootstraps)
2019-01-22 19:53:47 INFO  Executor:54 - Finished task 3.0 in stage 4.0 (TID 29). 4745 bytes result sent to driver
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 3.0 in stage 4.0 (TID 29) in 13 ms on localhost (executor driver) (2/4)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 27) in 201 ms on localhost (executor driver) (3/4)
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Removed taskresult_27 on AshCloud-D1:53485 in memory (size: 2.0 MB, free: 1993.9 MB)
2019-01-22 19:53:47 INFO  TaskSetManager:54 - Finished task 2.0 in stage 4.0 (TID 28) in 172 ms on localhost (executor driver) (4/4)
2019-01-22 19:53:47 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Removed taskresult_28 on AshCloud-D1:53485 in memory (size: 2.0 MB, free: 1996.0 MB)
2019-01-22 19:53:47 INFO  DAGScheduler:54 - ResultStage 4 (treeAggregate at IDF.scala:54) finished in 0.288 s
2019-01-22 19:53:47 INFO  DAGScheduler:54 - Job 3 finished: treeAggregate at IDF.scala:54, took 1.814495 s
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Removed broadcast_16_piece0 on AshCloud-D1:53485 in memory (size: 29.9 KB, free: 1996.0 MB)
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Removed broadcast_15_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Removed broadcast_17_piece0 on AshCloud-D1:53485 in memory (size: 30.4 KB, free: 1996.1 MB)
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:53:47 INFO  ContextCleaner:54 - Cleaned shuffle 0
2019-01-22 19:53:47 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:53:48 INFO  column remover:43 - removing column commit_content
2019-01-22 19:53:48 INFO  column remover:43 - removing column issue_content
2019-01-22 19:53:48 INFO  column remover:43 - removing column s_tokens
2019-01-22 19:53:48 INFO  column remover:43 - removing column t_tokens
2019-01-22 19:53:48 INFO  column remover:43 - removing column s_htf
2019-01-22 19:53:48 INFO  column remover:43 - removing column t_htf
2019-01-22 19:53:49 INFO  column remover:43 - removing column commit_content
2019-01-22 19:53:49 INFO  column remover:43 - removing column issue_content
2019-01-22 19:53:49 INFO  column remover:43 - removing column s_tokens
2019-01-22 19:53:49 INFO  column remover:43 - removing column t_tokens
2019-01-22 19:53:49 INFO  column remover:43 - removing column s_htf
2019-01-22 19:53:49 INFO  column remover:43 - removing column t_htf
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48))),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_resolution#48))),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48))),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnotnull(UDF(UDF(commit_content#17)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_resolution#48))),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnull(UDF(UDF(commit_content#17)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_summary#54))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnull(UDF(commit_content#17))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnull(UDF(issue_resolution#48))
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(commit_content#17)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(commit_content)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnull(issue_summary#54)
2019-01-22 19:54:01 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 10.392799 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 7.953401 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 5.557799 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 4.8479 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 4.4379 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 4.657 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 5.594099 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 12.282501 ms
2019-01-22 19:54:01 INFO  MemoryStore:54 - Block broadcast_18 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 19:54:01 INFO  MemoryStore:54 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 19:54:01 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:01 INFO  SparkContext:54 - Created broadcast 18 from show at SparkTraceTask.java:239
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 4.3882 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 4.6047 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 4.317799 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 4.644501 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 4.1216 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 9.5027 ms
2019-01-22 19:54:01 INFO  MemoryStore:54 - Block broadcast_19 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 19:54:01 INFO  MemoryStore:54 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.3 MB)
2019-01-22 19:54:01 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:01 INFO  SparkContext:54 - Created broadcast 19 from show at SparkTraceTask.java:239
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 4.7396 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 5.231101 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 6.7365 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 11.1904 ms
2019-01-22 19:54:01 INFO  MemoryStore:54 - Block broadcast_20 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 19:54:01 INFO  MemoryStore:54 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 19:54:01 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:01 INFO  SparkContext:54 - Created broadcast 20 from show at SparkTraceTask.java:239
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 7.8272 ms
2019-01-22 19:54:01 INFO  MemoryStore:54 - Block broadcast_21 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 19:54:01 INFO  MemoryStore:54 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-22 19:54:01 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:01 INFO  SparkContext:54 - Created broadcast 21 from show at SparkTraceTask.java:239
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 3.9421 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 3.887601 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 4.331 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 3.8464 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 3.7801 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 4.5291 ms
2019-01-22 19:54:01 INFO  CodeGenerator:54 - Code generated in 9.779099 ms
2019-01-22 19:54:01 INFO  MemoryStore:54 - Block broadcast_22 stored as values in memory (estimated size 220.9 KB, free 1994.6 MB)
2019-01-22 19:54:01 INFO  MemoryStore:54 - Block broadcast_22_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.5 MB)
2019-01-22 19:54:01 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:01 INFO  SparkContext:54 - Created broadcast 22 from show at SparkTraceTask.java:239
2019-01-22 19:54:01 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 6.3174 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.6388 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 6.003699 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.1856 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 10.513999 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_23 stored as values in memory (estimated size 220.9 KB, free 1994.3 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_23_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.3 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 23 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.4292 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 4.837899 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 8.340501 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_24 stored as values in memory (estimated size 220.9 KB, free 1994.1 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_24_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.1 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_24_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 24 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 8.413001 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_25 stored as values in memory (estimated size 220.9 KB, free 1993.9 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_25_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.8 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_25_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 25 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 3.9772 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 4.179699 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 4.1835 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 4.2098 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.3128 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 8.615 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_26 stored as values in memory (estimated size 220.9 KB, free 1993.6 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_26_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.6 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_26_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 26 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.278701 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.634201 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.1986 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 9.7145 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_27 stored as values in memory (estimated size 220.9 KB, free 1993.4 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_27_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.4 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_27_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 27 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 9.3132 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_28 stored as values in memory (estimated size 220.9 KB, free 1993.2 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_28_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.1 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_28_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 28 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.716799 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 6.2198 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 7.4243 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.968699 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 8.5145 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_29 stored as values in memory (estimated size 220.9 KB, free 1992.9 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_29_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.9 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_29_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 29 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.0128 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.9383 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 8.115599 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_30 stored as values in memory (estimated size 220.9 KB, free 1992.7 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_30_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.7 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_30_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 30 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 8.823599 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_31 stored as values in memory (estimated size 220.9 KB, free 1992.4 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_31_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.4 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_31_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 31 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.831799 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.395201 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.551799 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 9.556 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_32 stored as values in memory (estimated size 220.9 KB, free 1992.2 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_32_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.2 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_32_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 32 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 4.7378 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 7.386901 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_33 stored as values in memory (estimated size 220.9 KB, free 1992.0 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_33_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.0 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_33_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 33 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.3911 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.035901 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 7.6153 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_34 stored as values in memory (estimated size 220.9 KB, free 1991.7 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_34_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.7 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_34_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 34 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 8.2229 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_35 stored as values in memory (estimated size 220.9 KB, free 1991.5 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_35_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.5 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_35_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 35 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 6.066199 ms
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 11.049701 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_36 stored as values in memory (estimated size 220.9 KB, free 1991.3 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_36_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.2 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_36_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 36 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  CodeGenerator:54 - Code generated in 5.528199 ms
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_37 stored as values in memory (estimated size 220.9 KB, free 1991.0 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_37_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.0 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_37_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 37 from show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:02 INFO  SparkContext:54 - Starting job: show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Got job 4 (show at SparkTraceTask.java:239) with 1 output partitions
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (show at SparkTraceTask.java:239)
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[268] at show at SparkTraceTask.java:239), which has no missing parents
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_38 stored as values in memory (estimated size 208.1 KB, free 1990.8 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_38_piece0 stored as bytes in memory (estimated size 37.9 KB, free 1990.8 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_38_piece0 in memory on AshCloud-D1:53485 (size: 37.9 KB, free: 1995.7 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[268] at show at SparkTraceTask.java:239) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:54:02 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2019-01-22 19:54:02 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 8079 bytes)
2019-01-22 19:54:02 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 30)
2019-01-22 19:54:02 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 30). 11287 bytes result sent to driver
2019-01-22 19:54:02 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 30) in 12 ms on localhost (executor driver) (1/1)
2019-01-22 19:54:02 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2019-01-22 19:54:02 INFO  DAGScheduler:54 - ResultStage 5 (show at SparkTraceTask.java:239) finished in 0.021 s
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Job 4 finished: show at SparkTraceTask.java:239, took 0.026019 s
2019-01-22 19:54:02 INFO  SparkContext:54 - Starting job: show at SparkTraceTask.java:239
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Got job 5 (show at SparkTraceTask.java:239) with 4 output partitions
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (show at SparkTraceTask.java:239)
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Submitting ResultStage 6 (MapPartitionsRDD[268] at show at SparkTraceTask.java:239), which has no missing parents
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_39 stored as values in memory (estimated size 208.1 KB, free 1990.6 MB)
2019-01-22 19:54:02 INFO  MemoryStore:54 - Block broadcast_39_piece0 stored as bytes in memory (estimated size 37.9 KB, free 1990.5 MB)
2019-01-22 19:54:02 INFO  BlockManagerInfo:54 - Added broadcast_39_piece0 in memory on AshCloud-D1:53485 (size: 37.9 KB, free: 1995.7 MB)
2019-01-22 19:54:02 INFO  SparkContext:54 - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 6 (MapPartitionsRDD[268] at show at SparkTraceTask.java:239) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
2019-01-22 19:54:02 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 4 tasks
2019-01-22 19:54:02 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 8542 bytes)
2019-01-22 19:54:02 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 31)
2019-01-22 19:54:02 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:54:02 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 31). 11423 bytes result sent to driver
2019-01-22 19:54:02 INFO  TaskSetManager:54 - Starting task 1.0 in stage 6.0 (TID 32, localhost, executor driver, partition 2, PROCESS_LOCAL, 8064 bytes)
2019-01-22 19:54:02 INFO  Executor:54 - Running task 1.0 in stage 6.0 (TID 32)
2019-01-22 19:54:02 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 31) in 21 ms on localhost (executor driver) (1/4)
2019-01-22 19:54:02 INFO  Executor:54 - Finished task 1.0 in stage 6.0 (TID 32). 11287 bytes result sent to driver
2019-01-22 19:54:02 INFO  TaskSetManager:54 - Starting task 2.0 in stage 6.0 (TID 33, localhost, executor driver, partition 3, PROCESS_LOCAL, 8049 bytes)
2019-01-22 19:54:02 INFO  Executor:54 - Running task 2.0 in stage 6.0 (TID 33)
2019-01-22 19:54:02 INFO  TaskSetManager:54 - Finished task 1.0 in stage 6.0 (TID 32) in 5 ms on localhost (executor driver) (2/4)
2019-01-22 19:54:02 INFO  Executor:54 - Finished task 2.0 in stage 6.0 (TID 33). 11287 bytes result sent to driver
2019-01-22 19:54:02 INFO  TaskSetManager:54 - Starting task 3.0 in stage 6.0 (TID 34, localhost, executor driver, partition 4, PROCESS_LOCAL, 8034 bytes)
2019-01-22 19:54:02 INFO  Executor:54 - Running task 3.0 in stage 6.0 (TID 34)
2019-01-22 19:54:02 INFO  TaskSetManager:54 - Finished task 2.0 in stage 6.0 (TID 33) in 6 ms on localhost (executor driver) (3/4)
2019-01-22 19:54:02 INFO  Executor:54 - Finished task 3.0 in stage 6.0 (TID 34). 11244 bytes result sent to driver
2019-01-22 19:54:02 INFO  TaskSetManager:54 - Finished task 3.0 in stage 6.0 (TID 34) in 5 ms on localhost (executor driver) (4/4)
2019-01-22 19:54:02 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2019-01-22 19:54:02 INFO  DAGScheduler:54 - ResultStage 6 (show at SparkTraceTask.java:239) finished in 0.041 s
2019-01-22 19:54:02 INFO  DAGScheduler:54 - Job 5 finished: show at SparkTraceTask.java:239, took 0.046245 s
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 226
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 262
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 232
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 341
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 235
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 259
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 428
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 349
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 411
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 299
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 254
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 297
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 313
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 283
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 423
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 398
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 424
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 256
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 207
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 437
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 379
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 233
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 425
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 420
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 229
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 294
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 215
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 326
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 329
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 438
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 393
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 250
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 280
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 288
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 397
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 422
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 218
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 253
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 268
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 364
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 380
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_21_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.7 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 404
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 418
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 303
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 238
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 360
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 317
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 276
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 206
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 244
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 427
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_39_piece0 on AshCloud-D1:53485 in memory (size: 37.9 KB, free: 1995.7 MB)
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_32_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 223
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_27_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 348
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 205
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 222
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 225
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 344
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 447
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 210
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 440
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 287
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 320
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 231
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 298
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 381
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 272
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 366
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 291
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 275
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 445
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 306
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 343
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 220
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 282
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 274
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 328
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 392
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 305
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 292
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 335
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 433
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 374
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 439
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 216
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 219
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 324
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 322
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 358
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 387
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 354
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 399
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 390
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 345
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_30_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_31_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 385
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 405
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_36_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 304
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 409
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 312
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 308
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 450
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 357
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 416
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 413
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_20_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 242
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 396
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 325
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 284
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 271
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_29_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 295
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 310
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 369
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 309
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 421
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 412
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 214
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 208
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_18_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 395
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 373
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 302
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 263
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 372
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 248
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 388
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 389
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 394
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_35_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 378
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 230
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 376
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 279
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_37_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 237
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 241
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 361
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 441
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 240
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 339
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_34_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 286
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 336
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 432
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 350
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 211
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 224
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 386
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 327
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 290
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 410
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 362
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 258
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 267
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_24_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 307
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 371
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 401
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 337
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 435
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 356
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 265
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 301
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 236
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 249
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 311
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 217
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 365
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 430
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 446
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 239
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 403
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 419
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 451
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 260
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 377
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 227
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 443
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 277
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 285
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 434
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 383
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 367
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 408
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 212
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 264
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 368
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 452
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 314
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 375
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_23_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 319
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 426
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 363
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 270
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 323
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 243
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 281
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 382
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 429
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 234
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 252
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 316
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 340
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 436
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 293
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 355
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 269
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 296
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 338
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_19_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 245
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_33_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 342
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 315
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 246
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 391
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_28_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 221
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_22_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 209
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 332
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 289
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 346
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 257
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 384
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 442
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 402
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_38_piece0 on AshCloud-D1:53485 in memory (size: 37.9 KB, free: 1996.1 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 273
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 449
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 261
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 370
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 330
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 417
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 431
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 359
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 415
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 318
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 353
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 255
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 347
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 351
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 444
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 414
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 251
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 407
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_26_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 331
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 228
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 300
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 321
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Removed broadcast_25_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 247
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 266
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 352
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 400
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 448
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 406
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 333
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 278
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 213
2019-01-22 19:54:20 INFO  ContextCleaner:54 - Cleaned accumulator 334
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48))),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_resolution#48))),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48))),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnotnull(UDF(UDF(commit_content#17)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_resolution#48))),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnull(UDF(UDF(commit_content#17)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_summary#54))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnull(UDF(commit_content#17))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnull(UDF(issue_resolution#48))
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(commit_content#17)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(commit_content)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnull(issue_summary#54)
2019-01-22 19:54:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:54:20 INFO  MemoryStore:54 - Block broadcast_40 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 19:54:20 INFO  MemoryStore:54 - Block broadcast_40_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Added broadcast_40_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:20 INFO  SparkContext:54 - Created broadcast 40 from show at SparkTraceTask.java:239
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:20 INFO  MemoryStore:54 - Block broadcast_41 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 19:54:20 INFO  MemoryStore:54 - Block broadcast_41_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.3 MB)
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Added broadcast_41_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:20 INFO  SparkContext:54 - Created broadcast 41 from show at SparkTraceTask.java:239
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:20 INFO  MemoryStore:54 - Block broadcast_42 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 19:54:20 INFO  MemoryStore:54 - Block broadcast_42_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Added broadcast_42_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:20 INFO  SparkContext:54 - Created broadcast 42 from show at SparkTraceTask.java:239
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:20 INFO  MemoryStore:54 - Block broadcast_43 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 19:54:20 INFO  MemoryStore:54 - Block broadcast_43_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-22 19:54:20 INFO  BlockManagerInfo:54 - Added broadcast_43_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:20 INFO  SparkContext:54 - Created broadcast 43 from show at SparkTraceTask.java:239
2019-01-22 19:54:20 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_44 stored as values in memory (estimated size 220.9 KB, free 1994.6 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_44_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.5 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_44_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 44 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_45 stored as values in memory (estimated size 220.9 KB, free 1994.3 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_45_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.3 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_45_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 45 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_46 stored as values in memory (estimated size 220.9 KB, free 1994.1 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_46_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.1 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_46_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 46 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_47 stored as values in memory (estimated size 220.9 KB, free 1993.9 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_47_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.8 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_47_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 47 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_48 stored as values in memory (estimated size 220.9 KB, free 1993.6 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_48_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.6 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_48_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 48 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_49 stored as values in memory (estimated size 220.9 KB, free 1993.4 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_49_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.4 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_49_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 49 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_50 stored as values in memory (estimated size 220.9 KB, free 1993.2 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_50_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.1 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_50_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 50 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_51 stored as values in memory (estimated size 220.9 KB, free 1992.9 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_51_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.9 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_51_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 51 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_52 stored as values in memory (estimated size 220.9 KB, free 1992.7 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_52_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.7 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_52_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 52 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_53 stored as values in memory (estimated size 220.9 KB, free 1992.4 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_53_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.4 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_53_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 53 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_54 stored as values in memory (estimated size 220.9 KB, free 1992.2 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_54_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.2 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_54_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 54 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_55 stored as values in memory (estimated size 220.9 KB, free 1992.0 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_55_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.0 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_55_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 55 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_56 stored as values in memory (estimated size 220.9 KB, free 1991.7 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_56_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.7 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_56_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 56 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_57 stored as values in memory (estimated size 220.9 KB, free 1991.5 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_57_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.5 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_57_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 57 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_58 stored as values in memory (estimated size 220.9 KB, free 1991.3 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_58_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.2 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_58_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 58 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_59 stored as values in memory (estimated size 220.9 KB, free 1991.0 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_59_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.0 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_59_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 59 from show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:21 INFO  SparkContext:54 - Starting job: show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Got job 6 (show at SparkTraceTask.java:239) with 1 output partitions
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (show at SparkTraceTask.java:239)
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Submitting ResultStage 7 (MapPartitionsRDD[467] at show at SparkTraceTask.java:239), which has no missing parents
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_60 stored as values in memory (estimated size 208.1 KB, free 1990.8 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_60_piece0 stored as bytes in memory (estimated size 37.8 KB, free 1990.8 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_60_piece0 in memory on AshCloud-D1:53485 (size: 37.8 KB, free: 1995.7 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 60 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[467] at show at SparkTraceTask.java:239) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:54:21 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 1 tasks
2019-01-22 19:54:21 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 8079 bytes)
2019-01-22 19:54:21 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 35)
2019-01-22 19:54:21 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 35). 11244 bytes result sent to driver
2019-01-22 19:54:21 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 35) in 4 ms on localhost (executor driver) (1/1)
2019-01-22 19:54:21 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2019-01-22 19:54:21 INFO  DAGScheduler:54 - ResultStage 7 (show at SparkTraceTask.java:239) finished in 0.019 s
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Job 6 finished: show at SparkTraceTask.java:239, took 0.023240 s
2019-01-22 19:54:21 INFO  SparkContext:54 - Starting job: show at SparkTraceTask.java:239
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Got job 7 (show at SparkTraceTask.java:239) with 4 output partitions
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Final stage: ResultStage 8 (show at SparkTraceTask.java:239)
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Submitting ResultStage 8 (MapPartitionsRDD[467] at show at SparkTraceTask.java:239), which has no missing parents
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_61 stored as values in memory (estimated size 208.1 KB, free 1990.6 MB)
2019-01-22 19:54:21 INFO  MemoryStore:54 - Block broadcast_61_piece0 stored as bytes in memory (estimated size 37.9 KB, free 1990.5 MB)
2019-01-22 19:54:21 INFO  BlockManagerInfo:54 - Added broadcast_61_piece0 in memory on AshCloud-D1:53485 (size: 37.9 KB, free: 1995.7 MB)
2019-01-22 19:54:21 INFO  SparkContext:54 - Created broadcast 61 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 8 (MapPartitionsRDD[467] at show at SparkTraceTask.java:239) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
2019-01-22 19:54:21 INFO  TaskSchedulerImpl:54 - Adding task set 8.0 with 4 tasks
2019-01-22 19:54:21 INFO  TaskSetManager:54 - Starting task 0.0 in stage 8.0 (TID 36, localhost, executor driver, partition 1, PROCESS_LOCAL, 8542 bytes)
2019-01-22 19:54:21 INFO  Executor:54 - Running task 0.0 in stage 8.0 (TID 36)
2019-01-22 19:54:21 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:54:21 INFO  Executor:54 - Finished task 0.0 in stage 8.0 (TID 36). 11423 bytes result sent to driver
2019-01-22 19:54:21 INFO  TaskSetManager:54 - Starting task 1.0 in stage 8.0 (TID 37, localhost, executor driver, partition 2, PROCESS_LOCAL, 8064 bytes)
2019-01-22 19:54:21 INFO  Executor:54 - Running task 1.0 in stage 8.0 (TID 37)
2019-01-22 19:54:21 INFO  TaskSetManager:54 - Finished task 0.0 in stage 8.0 (TID 36) in 22 ms on localhost (executor driver) (1/4)
2019-01-22 19:54:21 INFO  Executor:54 - Finished task 1.0 in stage 8.0 (TID 37). 11244 bytes result sent to driver
2019-01-22 19:54:21 INFO  TaskSetManager:54 - Starting task 2.0 in stage 8.0 (TID 38, localhost, executor driver, partition 3, PROCESS_LOCAL, 8049 bytes)
2019-01-22 19:54:21 INFO  Executor:54 - Running task 2.0 in stage 8.0 (TID 38)
2019-01-22 19:54:21 INFO  TaskSetManager:54 - Finished task 1.0 in stage 8.0 (TID 37) in 6 ms on localhost (executor driver) (2/4)
2019-01-22 19:54:21 INFO  Executor:54 - Finished task 2.0 in stage 8.0 (TID 38). 11287 bytes result sent to driver
2019-01-22 19:54:21 INFO  TaskSetManager:54 - Starting task 3.0 in stage 8.0 (TID 39, localhost, executor driver, partition 4, PROCESS_LOCAL, 8034 bytes)
2019-01-22 19:54:21 INFO  Executor:54 - Running task 3.0 in stage 8.0 (TID 39)
2019-01-22 19:54:21 INFO  TaskSetManager:54 - Finished task 2.0 in stage 8.0 (TID 38) in 4 ms on localhost (executor driver) (3/4)
2019-01-22 19:54:21 INFO  Executor:54 - Finished task 3.0 in stage 8.0 (TID 39). 11287 bytes result sent to driver
2019-01-22 19:54:21 INFO  TaskSetManager:54 - Finished task 3.0 in stage 8.0 (TID 39) in 5 ms on localhost (executor driver) (4/4)
2019-01-22 19:54:21 INFO  TaskSchedulerImpl:54 - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2019-01-22 19:54:21 INFO  DAGScheduler:54 - ResultStage 8 (show at SparkTraceTask.java:239) finished in 0.043 s
2019-01-22 19:54:21 INFO  DAGScheduler:54 - Job 7 finished: show at SparkTraceTask.java:239, took 0.045385 s
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 495
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 525
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 624
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 505
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 697
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 615
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 470
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 575
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 534
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 657
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 514
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 677
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 609
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 599
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 555
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 639
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 661
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 660
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 656
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 462
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_42_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.7 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 473
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 541
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 553
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 640
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 499
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 517
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 651
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 694
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 524
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 506
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 696
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 611
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 502
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_46_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.7 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 513
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 685
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 494
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 636
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 579
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_51_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.7 MB)
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_61_piece0 on AshCloud-D1:53485 in memory (size: 37.9 KB, free: 1995.8 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 466
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 583
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 515
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 600
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 501
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_58_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 613
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 539
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 649
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 681
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 700
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 489
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 522
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 601
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 546
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_41_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 454
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 520
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 692
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 674
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 665
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 637
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 563
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 568
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 671
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 673
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 455
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_52_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 468
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 486
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 596
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 537
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 561
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 619
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 604
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_47_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 475
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 632
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 650
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 616
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 680
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 558
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 622
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 543
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 669
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 645
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 693
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 578
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 691
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 646
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 531
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 480
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 608
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 607
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 509
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 482
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 618
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 516
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_60_piece0 on AshCloud-D1:53485 in memory (size: 37.8 KB, free: 1995.9 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 686
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 573
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 602
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 523
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 533
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 614
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 631
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 570
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 557
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 549
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 625
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 642
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 556
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 698
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 456
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 626
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 508
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 621
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 586
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 458
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 610
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 597
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 472
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 590
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 574
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 593
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 572
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 551
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 577
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 490
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 550
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 566
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 588
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 560
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 511
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 690
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 481
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 641
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_56_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 483
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 529
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 581
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 559
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 571
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 594
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 662
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 666
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 554
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 648
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 598
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 687
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 484
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 655
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 526
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 684
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 569
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 630
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 567
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 664
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 540
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 678
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_59_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 504
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 659
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 453
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 585
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 479
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 663
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 528
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 635
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 605
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 628
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 547
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 465
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 653
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 562
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 695
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 682
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 469
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 564
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 652
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 552
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 467
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 497
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_44_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 500
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_53_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 518
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 548
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 643
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 474
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 591
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 492
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 457
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 485
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 496
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 617
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_40_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 679
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_55_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 527
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 620
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 532
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 612
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 638
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 460
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 471
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 488
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 676
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 587
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 629
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 545
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 627
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 699
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 658
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 675
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 576
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_49_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 476
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 498
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 510
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 582
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 633
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 683
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 493
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_54_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 459
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 463
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_57_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_48_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 503
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 544
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_43_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 536
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 565
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 584
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 589
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 647
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 530
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 491
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 477
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 542
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 672
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 478
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 670
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 521
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 519
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 644
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 507
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 688
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 654
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 464
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 512
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 461
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 535
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 592
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_45_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 634
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 538
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 603
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 606
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 595
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 487
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 580
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 668
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 667
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 689
2019-01-22 19:54:57 INFO  BlockManagerInfo:54 - Removed broadcast_50_piece0 on AshCloud-D1:53485 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:54:57 INFO  ContextCleaner:54 - Cleaned accumulator 623
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48))),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_resolution#48))),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48))),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnotnull(UDF(UDF(commit_content#17)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_id: string, commit_date: string, commit_content: string, commit_author: string, commit_type: string ... 3 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_resolution#48))),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnull(UDF(UDF(commit_content#17)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_id: string, commit_date: string, commit_content: string, commit_author: string, commit_type: string ... 3 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_summary#54))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnull(UDF(commit_content#17))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_id: string, commit_date: string, commit_content: string, commit_author: string, commit_type: string ... 3 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnull(UDF(issue_resolution#48))
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(commit_content#17)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_id: string, commit_date: string, commit_content: string, commit_author: string, commit_type: string ... 3 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(commit_content)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnull(issue_summary#54)
2019-01-22 19:54:58 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 13.144901 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 8.1184 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 7.0146 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 6.8191 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 8.4387 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 7.7657 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 6.9966 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 17.8704 ms
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_62 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_62_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 19:54:58 INFO  BlockManagerInfo:54 - Added broadcast_62_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:58 INFO  SparkContext:54 - Created broadcast 62 from show at SparkTraceTask.java:239
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 6.343 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 5.958 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 6.213501 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 7.8042 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 6.6075 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 13.938201 ms
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_63 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_63_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.3 MB)
2019-01-22 19:54:58 INFO  BlockManagerInfo:54 - Added broadcast_63_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:58 INFO  SparkContext:54 - Created broadcast 63 from show at SparkTraceTask.java:239
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 6.3034 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 6.281499 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 10.931 ms
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_64 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_64_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 19:54:58 INFO  BlockManagerInfo:54 - Added broadcast_64_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:58 INFO  SparkContext:54 - Created broadcast 64 from show at SparkTraceTask.java:239
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 9.4337 ms
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_65 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_65_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-22 19:54:58 INFO  BlockManagerInfo:54 - Added broadcast_65_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:58 INFO  SparkContext:54 - Created broadcast 65 from show at SparkTraceTask.java:239
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 6.1942 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 6.1067 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 6.756199 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 5.805301 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 5.4665 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 5.401501 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 9.5703 ms
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_66 stored as values in memory (estimated size 220.9 KB, free 1994.6 MB)
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_66_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.5 MB)
2019-01-22 19:54:58 INFO  BlockManagerInfo:54 - Added broadcast_66_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:54:58 INFO  SparkContext:54 - Created broadcast 66 from show at SparkTraceTask.java:239
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 5.3186 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 6.3689 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 7.663299 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 8.707999 ms
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_67 stored as values in memory (estimated size 220.9 KB, free 1994.3 MB)
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_67_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.3 MB)
2019-01-22 19:54:58 INFO  BlockManagerInfo:54 - Added broadcast_67_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:58 INFO  SparkContext:54 - Created broadcast 67 from show at SparkTraceTask.java:239
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 10.2063 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 14.625901 ms
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_68 stored as values in memory (estimated size 220.9 KB, free 1994.1 MB)
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_68_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.1 MB)
2019-01-22 19:54:58 INFO  BlockManagerInfo:54 - Added broadcast_68_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:58 INFO  SparkContext:54 - Created broadcast 68 from show at SparkTraceTask.java:239
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 13.9676 ms
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_69 stored as values in memory (estimated size 220.9 KB, free 1993.9 MB)
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_69_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.8 MB)
2019-01-22 19:54:58 INFO  BlockManagerInfo:54 - Added broadcast_69_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:58 INFO  SparkContext:54 - Created broadcast 69 from show at SparkTraceTask.java:239
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 5.816099 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 7.4727 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 5.4692 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 7.435299 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 7.594001 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 9.724 ms
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_70 stored as values in memory (estimated size 220.9 KB, free 1993.6 MB)
2019-01-22 19:54:58 INFO  MemoryStore:54 - Block broadcast_70_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.6 MB)
2019-01-22 19:54:58 INFO  BlockManagerInfo:54 - Added broadcast_70_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:58 INFO  SparkContext:54 - Created broadcast 70 from show at SparkTraceTask.java:239
2019-01-22 19:54:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 12.761099 ms
2019-01-22 19:54:58 INFO  CodeGenerator:54 - Code generated in 6.3058 ms
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 8.041 ms
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_71 stored as values in memory (estimated size 220.9 KB, free 1993.4 MB)
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_71_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.4 MB)
2019-01-22 19:54:59 INFO  BlockManagerInfo:54 - Added broadcast_71_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:54:59 INFO  SparkContext:54 - Created broadcast 71 from show at SparkTraceTask.java:239
2019-01-22 19:54:59 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 7.1249 ms
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_72 stored as values in memory (estimated size 220.9 KB, free 1993.2 MB)
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_72_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.1 MB)
2019-01-22 19:54:59 INFO  BlockManagerInfo:54 - Added broadcast_72_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:59 INFO  SparkContext:54 - Created broadcast 72 from show at SparkTraceTask.java:239
2019-01-22 19:54:59 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 5.5718 ms
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 5.6793 ms
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 5.388501 ms
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 8.0173 ms
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_73 stored as values in memory (estimated size 220.9 KB, free 1992.9 MB)
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_73_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.9 MB)
2019-01-22 19:54:59 INFO  BlockManagerInfo:54 - Added broadcast_73_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:59 INFO  SparkContext:54 - Created broadcast 73 from show at SparkTraceTask.java:239
2019-01-22 19:54:59 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 5.361201 ms
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 8.0613 ms
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_74 stored as values in memory (estimated size 220.9 KB, free 1992.7 MB)
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_74_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.7 MB)
2019-01-22 19:54:59 INFO  BlockManagerInfo:54 - Added broadcast_74_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:59 INFO  SparkContext:54 - Created broadcast 74 from show at SparkTraceTask.java:239
2019-01-22 19:54:59 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 6.6973 ms
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_75 stored as values in memory (estimated size 220.9 KB, free 1992.4 MB)
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_75_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.4 MB)
2019-01-22 19:54:59 INFO  BlockManagerInfo:54 - Added broadcast_75_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:59 INFO  SparkContext:54 - Created broadcast 75 from show at SparkTraceTask.java:239
2019-01-22 19:54:59 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 5.2583 ms
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 6.3451 ms
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 5.6319 ms
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_76 stored as values in memory (estimated size 220.9 KB, free 1992.2 MB)
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_76_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.2 MB)
2019-01-22 19:54:59 INFO  BlockManagerInfo:54 - Added broadcast_76_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:54:59 INFO  SparkContext:54 - Created broadcast 76 from show at SparkTraceTask.java:239
2019-01-22 19:54:59 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 6.447601 ms
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_77 stored as values in memory (estimated size 220.9 KB, free 1992.0 MB)
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_77_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.0 MB)
2019-01-22 19:54:59 INFO  BlockManagerInfo:54 - Added broadcast_77_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:59 INFO  SparkContext:54 - Created broadcast 77 from show at SparkTraceTask.java:239
2019-01-22 19:54:59 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 5.2287 ms
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 5.6559 ms
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_78 stored as values in memory (estimated size 220.9 KB, free 1991.7 MB)
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_78_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.7 MB)
2019-01-22 19:54:59 INFO  BlockManagerInfo:54 - Added broadcast_78_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:59 INFO  SparkContext:54 - Created broadcast 78 from show at SparkTraceTask.java:239
2019-01-22 19:54:59 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 6.7972 ms
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_79 stored as values in memory (estimated size 220.9 KB, free 1991.5 MB)
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_79_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.5 MB)
2019-01-22 19:54:59 INFO  BlockManagerInfo:54 - Added broadcast_79_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:59 INFO  SparkContext:54 - Created broadcast 79 from show at SparkTraceTask.java:239
2019-01-22 19:54:59 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 5.746 ms
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_80 stored as values in memory (estimated size 220.9 KB, free 1991.3 MB)
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_80_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.2 MB)
2019-01-22 19:54:59 INFO  BlockManagerInfo:54 - Added broadcast_80_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:59 INFO  SparkContext:54 - Created broadcast 80 from show at SparkTraceTask.java:239
2019-01-22 19:54:59 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 5.286401 ms
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_81 stored as values in memory (estimated size 220.9 KB, free 1991.0 MB)
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_81_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.0 MB)
2019-01-22 19:54:59 INFO  BlockManagerInfo:54 - Added broadcast_81_piece0 in memory on AshCloud-D1:53485 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:54:59 INFO  SparkContext:54 - Created broadcast 81 from show at SparkTraceTask.java:239
2019-01-22 19:54:59 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:54:59 INFO  SparkContext:54 - Starting job: show at SparkTraceTask.java:239
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Got job 8 (show at SparkTraceTask.java:239) with 1 output partitions
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Final stage: ResultStage 9 (show at SparkTraceTask.java:239)
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Submitting ResultStage 9 (MapPartitionsRDD[646] at show at SparkTraceTask.java:239), which has no missing parents
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_82 stored as values in memory (estimated size 2.5 MB, free 1988.5 MB)
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_82_piece0 stored as bytes in memory (estimated size 193.4 KB, free 1988.3 MB)
2019-01-22 19:54:59 INFO  BlockManagerInfo:54 - Added broadcast_82_piece0 in memory on AshCloud-D1:53485 (size: 193.4 KB, free: 1995.6 MB)
2019-01-22 19:54:59 INFO  SparkContext:54 - Created broadcast 82 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[646] at show at SparkTraceTask.java:239) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:54:59 INFO  TaskSchedulerImpl:54 - Adding task set 9.0 with 1 tasks
2019-01-22 19:54:59 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 8079 bytes)
2019-01-22 19:54:59 INFO  Executor:54 - Running task 0.0 in stage 9.0 (TID 40)
2019-01-22 19:54:59 INFO  Executor:54 - Finished task 0.0 in stage 9.0 (TID 40). 10473 bytes result sent to driver
2019-01-22 19:54:59 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 40) in 20 ms on localhost (executor driver) (1/1)
2019-01-22 19:54:59 INFO  TaskSchedulerImpl:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2019-01-22 19:54:59 INFO  DAGScheduler:54 - ResultStage 9 (show at SparkTraceTask.java:239) finished in 0.036 s
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Job 8 finished: show at SparkTraceTask.java:239, took 0.040117 s
2019-01-22 19:54:59 INFO  SparkContext:54 - Starting job: show at SparkTraceTask.java:239
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Got job 9 (show at SparkTraceTask.java:239) with 4 output partitions
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Final stage: ResultStage 10 (show at SparkTraceTask.java:239)
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Submitting ResultStage 10 (MapPartitionsRDD[646] at show at SparkTraceTask.java:239), which has no missing parents
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_83 stored as values in memory (estimated size 2.5 MB, free 1985.8 MB)
2019-01-22 19:54:59 INFO  MemoryStore:54 - Block broadcast_83_piece0 stored as bytes in memory (estimated size 193.5 KB, free 1985.6 MB)
2019-01-22 19:54:59 INFO  BlockManagerInfo:54 - Added broadcast_83_piece0 in memory on AshCloud-D1:53485 (size: 193.5 KB, free: 1995.4 MB)
2019-01-22 19:54:59 INFO  SparkContext:54 - Created broadcast 83 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 10 (MapPartitionsRDD[646] at show at SparkTraceTask.java:239) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
2019-01-22 19:54:59 INFO  TaskSchedulerImpl:54 - Adding task set 10.0 with 4 tasks
2019-01-22 19:54:59 INFO  TaskSetManager:54 - Starting task 0.0 in stage 10.0 (TID 41, localhost, executor driver, partition 1, PROCESS_LOCAL, 8542 bytes)
2019-01-22 19:54:59 INFO  Executor:54 - Running task 0.0 in stage 10.0 (TID 41)
2019-01-22 19:54:59 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:54:59 INFO  CodeGenerator:54 - Code generated in 4.5323 ms
2019-01-22 19:54:59 INFO  Executor:54 - Finished task 0.0 in stage 10.0 (TID 41). 20142 bytes result sent to driver
2019-01-22 19:54:59 INFO  TaskSetManager:54 - Starting task 1.0 in stage 10.0 (TID 42, localhost, executor driver, partition 2, PROCESS_LOCAL, 8064 bytes)
2019-01-22 19:54:59 INFO  Executor:54 - Running task 1.0 in stage 10.0 (TID 42)
2019-01-22 19:54:59 INFO  TaskSetManager:54 - Finished task 0.0 in stage 10.0 (TID 41) in 38 ms on localhost (executor driver) (1/4)
2019-01-22 19:54:59 INFO  Executor:54 - Finished task 1.0 in stage 10.0 (TID 42). 10430 bytes result sent to driver
2019-01-22 19:54:59 INFO  TaskSetManager:54 - Starting task 2.0 in stage 10.0 (TID 43, localhost, executor driver, partition 3, PROCESS_LOCAL, 8049 bytes)
2019-01-22 19:54:59 INFO  Executor:54 - Running task 2.0 in stage 10.0 (TID 43)
2019-01-22 19:54:59 INFO  TaskSetManager:54 - Finished task 1.0 in stage 10.0 (TID 42) in 7 ms on localhost (executor driver) (2/4)
2019-01-22 19:54:59 INFO  Executor:54 - Finished task 2.0 in stage 10.0 (TID 43). 10387 bytes result sent to driver
2019-01-22 19:54:59 INFO  TaskSetManager:54 - Starting task 3.0 in stage 10.0 (TID 44, localhost, executor driver, partition 4, PROCESS_LOCAL, 8034 bytes)
2019-01-22 19:54:59 INFO  Executor:54 - Running task 3.0 in stage 10.0 (TID 44)
2019-01-22 19:54:59 INFO  TaskSetManager:54 - Finished task 2.0 in stage 10.0 (TID 43) in 8 ms on localhost (executor driver) (3/4)
2019-01-22 19:54:59 INFO  Executor:54 - Finished task 3.0 in stage 10.0 (TID 44). 10387 bytes result sent to driver
2019-01-22 19:54:59 INFO  TaskSetManager:54 - Finished task 3.0 in stage 10.0 (TID 44) in 7 ms on localhost (executor driver) (4/4)
2019-01-22 19:54:59 INFO  TaskSchedulerImpl:54 - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2019-01-22 19:54:59 INFO  DAGScheduler:54 - ResultStage 10 (show at SparkTraceTask.java:239) finished in 0.071 s
2019-01-22 19:54:59 INFO  DAGScheduler:54 - Job 9 finished: show at SparkTraceTask.java:239, took 0.073939 s
2019-01-22 19:55:59 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-22 19:55:59 INFO  AbstractConnector:318 - Stopped Spark@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 19:55:59 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-22 19:55:59 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-22 19:56:07 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 19:56:07 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 19:56:07 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 19:56:07 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 19:56:07 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 19:56:07 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 19:56:07 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 19:56:07 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 19:56:07 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 19:56:08 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 53547.
2019-01-22 19:56:08 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 19:56:08 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 19:56:08 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 19:56:08 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 19:56:08 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-2c5b01a1-90af-48b9-bbd0-10570c9edbce
2019-01-22 19:56:08 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 19:56:08 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 19:56:08 INFO  log:192 - Logging initialized @7246ms
2019-01-22 19:56:08 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 19:56:08 INFO  Server:419 - Started @7307ms
2019-01-22 19:56:09 INFO  AbstractConnector:278 - Started ServerConnector@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 19:56:09 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26221bad{/jobs,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@468dda3e{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1729ec00{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/static,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3062f9f4{/api,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 19:56:09 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 19:56:09 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53560.
2019-01-22 19:56:09 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:53560
2019-01-22 19:56:09 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 19:56:09 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 53560, None)
2019-01-22 19:56:09 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:53560 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 53560, None)
2019-01-22 19:56:09 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 53560, None)
2019-01-22 19:56:09 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 53560, None)
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12ad1b2a{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 19:56:09 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1624775{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@712ac7e6{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 19:56:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e43bfe{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 19:56:10 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-22 19:56:11 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:11 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-22 19:56:11 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:56:11 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:56:12 INFO  CodeGenerator:54 - Code generated in 176.2783 ms
2019-01-22 19:56:12 INFO  CodeGenerator:54 - Code generated in 21.8316 ms
2019-01-22 19:56:12 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-22 19:56:12 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-22 19:56:12 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:56:12 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-22 19:56:12 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:12 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 19:56:12 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 19:56:12 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-22 19:56:12 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:56:12 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:56:12 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 19:56:12 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-22 19:56:12 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-22 19:56:12 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:53560 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 19:56:12 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:56:12 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:56:12 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-22 19:56:13 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-22 19:56:13 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-22 19:56:13 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 19:56:13 INFO  CodeGenerator:54 - Code generated in 8.6857 ms
2019-01-22 19:56:13 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2019-01-22 19:56:13 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 127 ms on localhost (executor driver) (1/1)
2019-01-22 19:56:13 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-22 19:56:13 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.207 s
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.251494 s
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:56:13 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:56:13 INFO  CodeGenerator:54 - Code generated in 4.9951 ms
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-22 19:56:13 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:56:13 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-22 19:56:13 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:56:13 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 19:56:13 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:56:13 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-22 19:56:13 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:13 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-22 19:56:13 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:53560 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:56:13 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:56:13 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-22 19:56:13 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-22 19:56:13 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-22 19:56:13 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:56:13 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1333 bytes result sent to driver
2019-01-22 19:56:13 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 9 ms on localhost (executor driver) (1/1)
2019-01-22 19:56:13 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-22 19:56:13 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.018 s
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.021099 s
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:56:13 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 19:56:13 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:56:13 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-22 19:56:13 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:56:13 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 19:56:13 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:56:13 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-22 19:56:13 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:13 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-22 19:56:13 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:53560 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:56:13 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:56:13 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-22 19:56:13 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-22 19:56:13 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-22 19:56:13 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-22 19:56:13 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1248 bytes result sent to driver
2019-01-22 19:56:13 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 8 ms on localhost (executor driver) (1/1)
2019-01-22 19:56:13 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-22 19:56:13 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.015 s
2019-01-22 19:56:13 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.017997 s
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 19:56:13 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:56:13 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 19:56:13 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-22 19:56:13 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:56:13 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-22 19:56:13 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:13 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_4cf7449a42bf inputCol, its NullRemover's IO params are set to null
2019-01-22 19:56:13 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_2a8c7b23fbdf inputCol, its NullRemover's IO params are set to null
2019-01-22 19:56:13 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 19:56:13 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_92962e0f7c16 inputCol, its NullRemover's IO params are set to null
2019-01-22 19:56:13 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_bb0058243707 inputCol, its NullRemover's IO params are set to null
2019-01-22 19:56:13 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 19:56:13 INFO  column remover:43 - removing column commit_content
2019-01-22 19:56:13 INFO  column remover:43 - removing column issue_content
2019-01-22 19:56:13 INFO  column remover:43 - removing column s_tokens
2019-01-22 19:56:13 INFO  column remover:43 - removing column t_tokens
2019-01-22 19:56:13 INFO  column remover:43 - removing column t_htf
2019-01-22 19:56:13 INFO  column remover:43 - removing column s_htf
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 57
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 42
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 8
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 18
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 6
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 13
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 16
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 30
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 68
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 49
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 48
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 40
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 73
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 94
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 25
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 96
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 89
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 58
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 104
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 72
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 39
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 45
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 69
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 97
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 41
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 61
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 50
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 63
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 38
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 91
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 10
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 81
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 83
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 102
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 66
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 7
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 64
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 106
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 95
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 20
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 52
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 76
2019-01-22 19:56:14 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on AshCloud-D1:53560 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 24
2019-01-22 19:56:14 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on AshCloud-D1:53560 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 101
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 67
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 36
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 17
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 15
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 105
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 78
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 44
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 79
2019-01-22 19:56:14 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on AshCloud-D1:53560 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 71
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 75
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 22
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 62
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 46
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 27
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 82
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 103
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 65
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 85
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 80
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 98
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 59
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 28
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 87
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 37
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 92
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 70
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 14
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 88
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 99
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 21
2019-01-22 19:56:14 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on AshCloud-D1:53560 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 47
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 9
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 29
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 74
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 54
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 51
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 100
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 19
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 23
2019-01-22 19:56:14 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:53560 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 60
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 86
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 90
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 11
2019-01-22 19:56:14 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on AshCloud-D1:53560 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:56:14 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on AshCloud-D1:53560 in memory (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 107
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 53
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 12
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 43
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 77
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 55
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 93
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 56
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 26
2019-01-22 19:56:14 INFO  ContextCleaner:54 - Cleaned accumulator 84
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnotnull(UDF(UDF(commit_content#17)))
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:56:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:56:15 INFO  CodeGenerator:54 - Code generated in 34.470101 ms
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 19:56:15 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:56:15 INFO  SparkContext:54 - Created broadcast 9 from rdd at IDF.scala:89
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:15 INFO  CodeGenerator:54 - Code generated in 24.029101 ms
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.3 MB)
2019-01-22 19:56:15 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:56:15 INFO  SparkContext:54 - Created broadcast 10 from rdd at IDF.scala:89
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:15 INFO  CodeGenerator:54 - Code generated in 21.969 ms
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 19:56:15 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:56:15 INFO  SparkContext:54 - Created broadcast 11 from rdd at IDF.scala:89
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:15 INFO  CodeGenerator:54 - Code generated in 22.2758 ms
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-22 19:56:15 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:56:15 INFO  SparkContext:54 - Created broadcast 12 from rdd at IDF.scala:89
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:15 INFO  CodeGenerator:54 - Code generated in 27.858599 ms
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 220.9 KB, free 1994.6 MB)
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.5 MB)
2019-01-22 19:56:15 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:56:15 INFO  SparkContext:54 - Created broadcast 13 from rdd at IDF.scala:89
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:15 INFO  CodeGenerator:54 - Code generated in 20.642599 ms
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 220.9 KB, free 1994.3 MB)
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.3 MB)
2019-01-22 19:56:15 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:56:15 INFO  SparkContext:54 - Created broadcast 14 from rdd at IDF.scala:89
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:15 INFO  CodeGenerator:54 - Code generated in 21.4169 ms
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 220.9 KB, free 1994.1 MB)
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.1 MB)
2019-01-22 19:56:15 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1996.0 MB)
2019-01-22 19:56:15 INFO  SparkContext:54 - Created broadcast 15 from rdd at IDF.scala:89
2019-01-22 19:56:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:15 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2019-01-22 19:56:15 INFO  DAGScheduler:54 - Registering RDD 67 (treeAggregate at IDF.scala:54)
2019-01-22 19:56:15 INFO  DAGScheduler:54 - Got job 3 (treeAggregate at IDF.scala:54) with 4 output partitions
2019-01-22 19:56:15 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (treeAggregate at IDF.scala:54)
2019-01-22 19:56:15 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 3)
2019-01-22 19:56:15 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 3)
2019-01-22 19:56:15 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 117.2 KB, free 1994.0 MB)
2019-01-22 19:56:15 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 30.5 KB, free 1993.9 MB)
2019-01-22 19:56:15 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on AshCloud-D1:53560 (size: 30.5 KB, free: 1996.0 MB)
2019-01-22 19:56:15 INFO  SparkContext:54 - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:56:15 INFO  DAGScheduler:54 - Submitting 23 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2019-01-22 19:56:15 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 23 tasks
2019-01-22 19:56:15 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:15 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2019-01-22 19:56:15 INFO  CodeGenerator:54 - Code generated in 7.3199 ms
2019-01-22 19:56:15 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 4615 bytes result sent to driver
2019-01-22 19:56:15 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:15 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 4)
2019-01-22 19:56:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 82 ms on localhost (executor driver) (1/23)
2019-01-22 19:56:15 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 4). 4572 bytes result sent to driver
2019-01-22 19:56:15 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 5, localhost, executor driver, partition 2, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:56:15 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 5)
2019-01-22 19:56:15 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 4) in 20 ms on localhost (executor driver) (2/23)
2019-01-22 19:56:15 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:56:15 INFO  CodeGenerator:54 - Code generated in 4.8638 ms
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 5). 4615 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 3.0 in stage 3.0 (TID 6, localhost, executor driver, partition 3, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 3.0 in stage 3.0 (TID 6)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 5) in 497 ms on localhost (executor driver) (3/23)
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 3.0 in stage 3.0 (TID 6). 4529 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 4.0 in stage 3.0 (TID 7, localhost, executor driver, partition 4, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 4.0 in stage 3.0 (TID 7)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 3.0 in stage 3.0 (TID 6) in 17 ms on localhost (executor driver) (4/23)
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 4.0 in stage 3.0 (TID 7). 4529 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 5.0 in stage 3.0 (TID 8, localhost, executor driver, partition 5, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 5.0 in stage 3.0 (TID 8)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 4.0 in stage 3.0 (TID 7) in 17 ms on localhost (executor driver) (5/23)
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 5.0 in stage 3.0 (TID 8). 4572 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 6.0 in stage 3.0 (TID 9, localhost, executor driver, partition 6, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 6.0 in stage 3.0 (TID 9)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 5.0 in stage 3.0 (TID 8) in 21 ms on localhost (executor driver) (6/23)
2019-01-22 19:56:16 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 6.0 in stage 3.0 (TID 9). 4615 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 7.0 in stage 3.0 (TID 10, localhost, executor driver, partition 7, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 7.0 in stage 3.0 (TID 10)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 6.0 in stage 3.0 (TID 9) in 39 ms on localhost (executor driver) (7/23)
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 7.0 in stage 3.0 (TID 10). 4529 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 8.0 in stage 3.0 (TID 11, localhost, executor driver, partition 8, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 8.0 in stage 3.0 (TID 11)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 7.0 in stage 3.0 (TID 10) in 17 ms on localhost (executor driver) (8/23)
2019-01-22 19:56:16 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 8.0 in stage 3.0 (TID 11). 4658 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 9.0 in stage 3.0 (TID 12, localhost, executor driver, partition 9, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 9.0 in stage 3.0 (TID 12)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 8.0 in stage 3.0 (TID 11) in 31 ms on localhost (executor driver) (9/23)
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 9.0 in stage 3.0 (TID 12). 4529 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 10.0 in stage 3.0 (TID 13, localhost, executor driver, partition 10, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 10.0 in stage 3.0 (TID 13)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 9.0 in stage 3.0 (TID 12) in 15 ms on localhost (executor driver) (10/23)
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 10.0 in stage 3.0 (TID 13). 4529 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 11.0 in stage 3.0 (TID 14, localhost, executor driver, partition 11, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 11.0 in stage 3.0 (TID 14)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 10.0 in stage 3.0 (TID 13) in 14 ms on localhost (executor driver) (11/23)
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 11.0 in stage 3.0 (TID 14). 4529 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 12.0 in stage 3.0 (TID 15, localhost, executor driver, partition 12, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 12.0 in stage 3.0 (TID 15)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 11.0 in stage 3.0 (TID 14) in 16 ms on localhost (executor driver) (12/23)
2019-01-22 19:56:16 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 12.0 in stage 3.0 (TID 15). 4615 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 13.0 in stage 3.0 (TID 16, localhost, executor driver, partition 13, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 13.0 in stage 3.0 (TID 16)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 12.0 in stage 3.0 (TID 15) in 49 ms on localhost (executor driver) (13/23)
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 13.0 in stage 3.0 (TID 16). 4529 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 14.0 in stage 3.0 (TID 17, localhost, executor driver, partition 14, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 14.0 in stage 3.0 (TID 17)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 13.0 in stage 3.0 (TID 16) in 16 ms on localhost (executor driver) (14/23)
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 14.0 in stage 3.0 (TID 17). 4529 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 15.0 in stage 3.0 (TID 18, localhost, executor driver, partition 15, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 15.0 in stage 3.0 (TID 18)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 14.0 in stage 3.0 (TID 17) in 15 ms on localhost (executor driver) (15/23)
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 15.0 in stage 3.0 (TID 18). 4529 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 16.0 in stage 3.0 (TID 19, localhost, executor driver, partition 16, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 16.0 in stage 3.0 (TID 19)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 15.0 in stage 3.0 (TID 18) in 16 ms on localhost (executor driver) (16/23)
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 16.0 in stage 3.0 (TID 19). 4529 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 17.0 in stage 3.0 (TID 20, localhost, executor driver, partition 17, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 17.0 in stage 3.0 (TID 20)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 16.0 in stage 3.0 (TID 19) in 12 ms on localhost (executor driver) (17/23)
2019-01-22 19:56:16 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 17.0 in stage 3.0 (TID 20). 4615 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 18.0 in stage 3.0 (TID 21, localhost, executor driver, partition 18, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 18.0 in stage 3.0 (TID 21)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 17.0 in stage 3.0 (TID 20) in 29 ms on localhost (executor driver) (18/23)
2019-01-22 19:56:16 INFO  Executor:54 - Finished task 18.0 in stage 3.0 (TID 21). 4529 bytes result sent to driver
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Starting task 19.0 in stage 3.0 (TID 22, localhost, executor driver, partition 19, PROCESS_LOCAL, 8437 bytes)
2019-01-22 19:56:16 INFO  Executor:54 - Running task 19.0 in stage 3.0 (TID 22)
2019-01-22 19:56:16 INFO  TaskSetManager:54 - Finished task 18.0 in stage 3.0 (TID 21) in 16 ms on localhost (executor driver) (19/23)
2019-01-22 19:56:16 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 19:56:17 INFO  Executor:54 - Finished task 19.0 in stage 3.0 (TID 22). 4658 bytes result sent to driver
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Starting task 20.0 in stage 3.0 (TID 23, localhost, executor driver, partition 20, PROCESS_LOCAL, 8441 bytes)
2019-01-22 19:56:17 INFO  Executor:54 - Running task 20.0 in stage 3.0 (TID 23)
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Finished task 19.0 in stage 3.0 (TID 22) in 489 ms on localhost (executor driver) (20/23)
2019-01-22 19:56:17 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:56:17 INFO  Executor:54 - Finished task 20.0 in stage 3.0 (TID 23). 4615 bytes result sent to driver
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Starting task 21.0 in stage 3.0 (TID 24, localhost, executor driver, partition 21, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:17 INFO  Executor:54 - Running task 21.0 in stage 3.0 (TID 24)
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Finished task 20.0 in stage 3.0 (TID 23) in 31 ms on localhost (executor driver) (21/23)
2019-01-22 19:56:17 INFO  Executor:54 - Finished task 21.0 in stage 3.0 (TID 24). 4529 bytes result sent to driver
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Starting task 22.0 in stage 3.0 (TID 25, localhost, executor driver, partition 22, PROCESS_LOCAL, 7978 bytes)
2019-01-22 19:56:17 INFO  Executor:54 - Running task 22.0 in stage 3.0 (TID 25)
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Finished task 21.0 in stage 3.0 (TID 24) in 17 ms on localhost (executor driver) (22/23)
2019-01-22 19:56:17 INFO  Executor:54 - Finished task 22.0 in stage 3.0 (TID 25). 4486 bytes result sent to driver
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Finished task 22.0 in stage 3.0 (TID 25) in 15 ms on localhost (executor driver) (23/23)
2019-01-22 19:56:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2019-01-22 19:56:17 INFO  DAGScheduler:54 - ShuffleMapStage 3 (treeAggregate at IDF.scala:54) finished in 1.496 s
2019-01-22 19:56:17 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-01-22 19:56:17 INFO  DAGScheduler:54 - running: Set()
2019-01-22 19:56:17 INFO  DAGScheduler:54 - waiting: Set(ResultStage 4)
2019-01-22 19:56:17 INFO  DAGScheduler:54 - failed: Set()
2019-01-22 19:56:17 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-22 19:56:17 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 118.1 KB, free 1993.8 MB)
2019-01-22 19:56:17 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 31.2 KB, free 1993.8 MB)
2019-01-22 19:56:17 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on AshCloud-D1:53560 (size: 31.2 KB, free: 1996.0 MB)
2019-01-22 19:56:17 INFO  SparkContext:54 - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:56:17 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-01-22 19:56:17 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 4 tasks
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 26, localhost, executor driver, partition 0, ANY, 7649 bytes)
2019-01-22 19:56:17 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 26)
2019-01-22 19:56:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-22 19:56:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2019-01-22 19:56:17 INFO  MemoryStore:54 - Block taskresult_26 stored as bytes in memory (estimated size 2.0 MB, free 1991.8 MB)
2019-01-22 19:56:17 INFO  BlockManagerInfo:54 - Added taskresult_26 in memory on AshCloud-D1:53560 (size: 2.0 MB, free: 1993.9 MB)
2019-01-22 19:56:17 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 26). 2112329 bytes result sent via BlockManager)
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 27, localhost, executor driver, partition 1, ANY, 7649 bytes)
2019-01-22 19:56:17 INFO  Executor:54 - Running task 1.0 in stage 4.0 (TID 27)
2019-01-22 19:56:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-22 19:56:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2019-01-22 19:56:17 INFO  Executor:54 - Finished task 1.0 in stage 4.0 (TID 27). 4745 bytes result sent to driver
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Starting task 2.0 in stage 4.0 (TID 28, localhost, executor driver, partition 2, ANY, 7649 bytes)
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 27) in 12 ms on localhost (executor driver) (1/4)
2019-01-22 19:56:17 INFO  Executor:54 - Running task 2.0 in stage 4.0 (TID 28)
2019-01-22 19:56:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-22 19:56:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-22 19:56:17 INFO  MemoryStore:54 - Block taskresult_28 stored as bytes in memory (estimated size 2.0 MB, free 1989.8 MB)
2019-01-22 19:56:17 INFO  BlockManagerInfo:54 - Added taskresult_28 in memory on AshCloud-D1:53560 (size: 2.0 MB, free: 1991.9 MB)
2019-01-22 19:56:17 INFO  Executor:54 - Finished task 2.0 in stage 4.0 (TID 28). 2112329 bytes result sent via BlockManager)
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Starting task 3.0 in stage 4.0 (TID 29, localhost, executor driver, partition 3, ANY, 7649 bytes)
2019-01-22 19:56:17 INFO  Executor:54 - Running task 3.0 in stage 4.0 (TID 29)
2019-01-22 19:56:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 5 non-empty blocks out of 23 blocks
2019-01-22 19:56:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2019-01-22 19:56:17 INFO  MemoryStore:54 - Block taskresult_29 stored as bytes in memory (estimated size 2.0 MB, free 1987.7 MB)
2019-01-22 19:56:17 INFO  BlockManagerInfo:54 - Added taskresult_29 in memory on AshCloud-D1:53560 (size: 2.0 MB, free: 1989.9 MB)
2019-01-22 19:56:17 INFO  Executor:54 - Finished task 3.0 in stage 4.0 (TID 29). 2112286 bytes result sent via BlockManager)
2019-01-22 19:56:17 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:53560 after 48 ms (0 ms spent in bootstraps)
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Finished task 3.0 in stage 4.0 (TID 29) in 109 ms on localhost (executor driver) (2/4)
2019-01-22 19:56:17 INFO  BlockManagerInfo:54 - Removed taskresult_29 on AshCloud-D1:53560 in memory (size: 2.0 MB, free: 1991.9 MB)
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 26) in 214 ms on localhost (executor driver) (3/4)
2019-01-22 19:56:17 INFO  BlockManagerInfo:54 - Removed taskresult_26 on AshCloud-D1:53560 in memory (size: 2.0 MB, free: 1993.9 MB)
2019-01-22 19:56:17 INFO  TaskSetManager:54 - Finished task 2.0 in stage 4.0 (TID 28) in 163 ms on localhost (executor driver) (4/4)
2019-01-22 19:56:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2019-01-22 19:56:17 INFO  BlockManagerInfo:54 - Removed taskresult_28 on AshCloud-D1:53560 in memory (size: 2.0 MB, free: 1996.0 MB)
2019-01-22 19:56:17 INFO  DAGScheduler:54 - ResultStage 4 (treeAggregate at IDF.scala:54) finished in 0.263 s
2019-01-22 19:56:17 INFO  DAGScheduler:54 - Job 3 finished: treeAggregate at IDF.scala:54, took 1.787086 s
2019-01-22 19:56:18 INFO  column remover:43 - removing column commit_content
2019-01-22 19:56:18 INFO  column remover:43 - removing column issue_content
2019-01-22 19:56:18 INFO  column remover:43 - removing column s_tokens
2019-01-22 19:56:18 INFO  column remover:43 - removing column t_tokens
2019-01-22 19:56:18 INFO  column remover:43 - removing column t_htf
2019-01-22 19:56:18 INFO  column remover:43 - removing column s_htf
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54))),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54))),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnotnull(UDF(UDF(commit_content#17)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_id: string, commit_date: string, commit_content: string, commit_author: string, commit_type: string ... 3 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54))),isnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54))),isnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnull(UDF(UDF(commit_content#17)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_id: string, commit_date: string, commit_content: string, commit_author: string, commit_type: string ... 3 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(UDF(issue_resolution#48)))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_summary#54))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnull(UDF(commit_content#17))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_id: string, commit_date: string, commit_content: string, commit_author: string, commit_type: string ... 3 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnull(UDF(issue_resolution#48))
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(commit_content#17)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_id: string, commit_date: string, commit_content: string, commit_author: string, commit_type: string ... 3 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(commit_content)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnull(issue_summary#54)
2019-01-22 19:56:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNull(issue_summary)
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 28.761099 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 27.272001 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 23.0673 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 12.757099 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 9.000999 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 11.330399 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 12.093 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 18.2701 ms
2019-01-22 19:56:27 INFO  MemoryStore:54 - Block broadcast_18 stored as values in memory (estimated size 220.9 KB, free 1993.6 MB)
2019-01-22 19:56:27 INFO  MemoryStore:54 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.6 MB)
2019-01-22 19:56:27 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:56:27 INFO  SparkContext:54 - Created broadcast 18 from show at SparkTraceTask.java:201
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 8.7886 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 8.9133 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 8.8077 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 7.578799 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 7.731201 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 16.738701 ms
2019-01-22 19:56:27 INFO  MemoryStore:54 - Block broadcast_19 stored as values in memory (estimated size 220.9 KB, free 1993.3 MB)
2019-01-22 19:56:27 INFO  MemoryStore:54 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.3 MB)
2019-01-22 19:56:27 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:56:27 INFO  SparkContext:54 - Created broadcast 19 from show at SparkTraceTask.java:201
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 8.392 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 8.804 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 8.3408 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 13.4436 ms
2019-01-22 19:56:27 INFO  MemoryStore:54 - Block broadcast_20 stored as values in memory (estimated size 220.9 KB, free 1993.1 MB)
2019-01-22 19:56:27 INFO  MemoryStore:54 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.1 MB)
2019-01-22 19:56:27 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:56:27 INFO  SparkContext:54 - Created broadcast 20 from show at SparkTraceTask.java:201
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 7.228 ms
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 13.183299 ms
2019-01-22 19:56:27 INFO  MemoryStore:54 - Block broadcast_21 stored as values in memory (estimated size 220.9 KB, free 1992.9 MB)
2019-01-22 19:56:27 INFO  MemoryStore:54 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.8 MB)
2019-01-22 19:56:27 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:56:27 INFO  SparkContext:54 - Created broadcast 21 from show at SparkTraceTask.java:201
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:27 INFO  CodeGenerator:54 - Code generated in 14.697699 ms
2019-01-22 19:56:27 INFO  MemoryStore:54 - Block broadcast_22 stored as values in memory (estimated size 220.9 KB, free 1992.6 MB)
2019-01-22 19:56:27 INFO  MemoryStore:54 - Block broadcast_22_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.6 MB)
2019-01-22 19:56:27 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.9 MB)
2019-01-22 19:56:27 INFO  SparkContext:54 - Created broadcast 22 from show at SparkTraceTask.java:201
2019-01-22 19:56:27 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 10.1489 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.492299 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.8605 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 8.6674 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.3903 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.1843 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 16.255401 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_23 stored as values in memory (estimated size 220.9 KB, free 1992.4 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_23_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.4 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 23 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 6.4515 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.0202 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 6.0443 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 10.375099 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_24 stored as values in memory (estimated size 220.9 KB, free 1992.2 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_24_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.1 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_24_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 24 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 9.4444 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_25 stored as values in memory (estimated size 220.9 KB, free 1991.9 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_25_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.9 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_25_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 25 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 5.664799 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 5.8134 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.656799 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.890099 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.9152 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 12.4956 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_26 stored as values in memory (estimated size 220.9 KB, free 1991.7 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_26_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.7 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_26_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 26 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 8.6528 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 6.220599 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 8.4621 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_27 stored as values in memory (estimated size 220.9 KB, free 1991.4 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_27_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.4 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_27_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.8 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 27 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.3048 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_28 stored as values in memory (estimated size 220.9 KB, free 1991.2 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_28_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.2 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_28_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.7 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 28 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.2251 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 5.9539 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 5.7038 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 8.8691 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_29 stored as values in memory (estimated size 220.9 KB, free 1991.0 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_29_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.0 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_29_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.7 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 29 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.836099 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 8.919999 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_30 stored as values in memory (estimated size 220.9 KB, free 1990.7 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_30_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1990.7 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_30_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.7 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 30 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.852801 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_31 stored as values in memory (estimated size 220.9 KB, free 1990.5 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_31_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1990.5 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_31_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.7 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 31 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 8.8075 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 8.0238 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 10.4869 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_32 stored as values in memory (estimated size 220.9 KB, free 1990.3 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_32_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1990.2 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_32_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.7 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 32 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 8.907699 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_33 stored as values in memory (estimated size 220.9 KB, free 1990.0 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_33_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1990.0 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_33_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.6 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 33 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.471 ms
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 12.530601 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_34 stored as values in memory (estimated size 220.9 KB, free 1989.8 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_34_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1989.8 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_34_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.6 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 34 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.251699 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_35 stored as values in memory (estimated size 220.9 KB, free 1989.6 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_35_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1989.5 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_35_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.6 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 35 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 6.507699 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_36 stored as values in memory (estimated size 220.9 KB, free 1989.3 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_36_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1989.3 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_36_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.6 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 36 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 7.083599 ms
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_37 stored as values in memory (estimated size 220.9 KB, free 1989.1 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_37_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1989.1 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_37_piece0 in memory on AshCloud-D1:53560 (size: 20.6 KB, free: 1995.6 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 37 from show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:56:28 INFO  SparkContext:54 - Starting job: show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Got job 4 (show at SparkTraceTask.java:201) with 1 output partitions
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (show at SparkTraceTask.java:201)
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[249] at show at SparkTraceTask.java:201), which has no missing parents
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_38 stored as values in memory (estimated size 2.5 MB, free 1986.6 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_38_piece0 stored as bytes in memory (estimated size 193.1 KB, free 1986.4 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_38_piece0 in memory on AshCloud-D1:53560 (size: 193.1 KB, free: 1995.4 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[249] at show at SparkTraceTask.java:201) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:56:28 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2019-01-22 19:56:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 8079 bytes)
2019-01-22 19:56:28 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 30)
2019-01-22 19:56:28 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 30). 10458 bytes result sent to driver
2019-01-22 19:56:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 30) in 19 ms on localhost (executor driver) (1/1)
2019-01-22 19:56:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2019-01-22 19:56:28 INFO  DAGScheduler:54 - ResultStage 5 (show at SparkTraceTask.java:201) finished in 0.034 s
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Job 4 finished: show at SparkTraceTask.java:201, took 0.039797 s
2019-01-22 19:56:28 INFO  SparkContext:54 - Starting job: show at SparkTraceTask.java:201
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Got job 5 (show at SparkTraceTask.java:201) with 4 output partitions
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (show at SparkTraceTask.java:201)
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Submitting ResultStage 6 (MapPartitionsRDD[249] at show at SparkTraceTask.java:201), which has no missing parents
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_39 stored as values in memory (estimated size 2.5 MB, free 1983.8 MB)
2019-01-22 19:56:28 INFO  MemoryStore:54 - Block broadcast_39_piece0 stored as bytes in memory (estimated size 193.2 KB, free 1983.7 MB)
2019-01-22 19:56:28 INFO  BlockManagerInfo:54 - Added broadcast_39_piece0 in memory on AshCloud-D1:53560 (size: 193.2 KB, free: 1995.2 MB)
2019-01-22 19:56:28 INFO  SparkContext:54 - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 6 (MapPartitionsRDD[249] at show at SparkTraceTask.java:201) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
2019-01-22 19:56:28 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 4 tasks
2019-01-22 19:56:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 8542 bytes)
2019-01-22 19:56:28 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 31)
2019-01-22 19:56:28 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:56:28 INFO  CodeGenerator:54 - Code generated in 4.7902 ms
2019-01-22 19:56:28 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 31). 20224 bytes result sent to driver
2019-01-22 19:56:28 INFO  TaskSetManager:54 - Starting task 1.0 in stage 6.0 (TID 32, localhost, executor driver, partition 2, PROCESS_LOCAL, 8064 bytes)
2019-01-22 19:56:28 INFO  Executor:54 - Running task 1.0 in stage 6.0 (TID 32)
2019-01-22 19:56:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 31) in 33 ms on localhost (executor driver) (1/4)
2019-01-22 19:56:28 INFO  Executor:54 - Finished task 1.0 in stage 6.0 (TID 32). 10415 bytes result sent to driver
2019-01-22 19:56:28 INFO  TaskSetManager:54 - Starting task 2.0 in stage 6.0 (TID 33, localhost, executor driver, partition 3, PROCESS_LOCAL, 8049 bytes)
2019-01-22 19:56:28 INFO  Executor:54 - Running task 2.0 in stage 6.0 (TID 33)
2019-01-22 19:56:28 INFO  TaskSetManager:54 - Finished task 1.0 in stage 6.0 (TID 32) in 10 ms on localhost (executor driver) (2/4)
2019-01-22 19:56:28 INFO  Executor:54 - Finished task 2.0 in stage 6.0 (TID 33). 10415 bytes result sent to driver
2019-01-22 19:56:28 INFO  TaskSetManager:54 - Starting task 3.0 in stage 6.0 (TID 34, localhost, executor driver, partition 4, PROCESS_LOCAL, 8034 bytes)
2019-01-22 19:56:28 INFO  Executor:54 - Running task 3.0 in stage 6.0 (TID 34)
2019-01-22 19:56:28 INFO  TaskSetManager:54 - Finished task 2.0 in stage 6.0 (TID 33) in 11 ms on localhost (executor driver) (3/4)
2019-01-22 19:56:28 INFO  Executor:54 - Finished task 3.0 in stage 6.0 (TID 34). 10415 bytes result sent to driver
2019-01-22 19:56:28 INFO  TaskSetManager:54 - Finished task 3.0 in stage 6.0 (TID 34) in 7 ms on localhost (executor driver) (4/4)
2019-01-22 19:56:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2019-01-22 19:56:28 INFO  DAGScheduler:54 - ResultStage 6 (show at SparkTraceTask.java:201) finished in 0.070 s
2019-01-22 19:56:28 INFO  DAGScheduler:54 - Job 5 finished: show at SparkTraceTask.java:201, took 0.073497 s
2019-01-22 19:58:21 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 19:58:21 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 19:58:21 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 19:58:21 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 19:58:21 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 19:58:21 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 19:58:21 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 19:58:21 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 19:58:21 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 19:58:22 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 53616.
2019-01-22 19:58:22 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 19:58:22 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 19:58:22 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 19:58:22 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 19:58:22 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-1bca00cd-ba93-4cee-8f31-1e69f92858b8
2019-01-22 19:58:22 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 19:58:23 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 19:58:23 INFO  log:192 - Logging initialized @7239ms
2019-01-22 19:58:23 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 19:58:23 INFO  Server:419 - Started @7294ms
2019-01-22 19:58:23 INFO  AbstractConnector:278 - Started ServerConnector@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 19:58:23 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26221bad{/jobs,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@468dda3e{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1729ec00{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/static,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3062f9f4{/api,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 19:58:23 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 19:58:23 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53629.
2019-01-22 19:58:23 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:53629
2019-01-22 19:58:23 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 19:58:23 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 53629, None)
2019-01-22 19:58:23 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:53629 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 53629, None)
2019-01-22 19:58:23 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 53629, None)
2019-01-22 19:58:23 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 53629, None)
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12ad1b2a{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 19:58:23 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1624775{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@712ac7e6{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 19:58:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e43bfe{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 19:58:24 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-22 19:58:25 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:58:25 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-22 19:58:25 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:58:25 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:58:26 INFO  CodeGenerator:54 - Code generated in 173.4351 ms
2019-01-22 19:58:26 INFO  CodeGenerator:54 - Code generated in 17.5007 ms
2019-01-22 19:58:26 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-22 19:58:26 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-22 19:58:26 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:53629 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:58:26 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-22 19:58:26 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:58:26 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 19:58:26 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 19:58:26 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-22 19:58:26 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:58:26 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:58:26 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 19:58:26 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-22 19:58:26 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-22 19:58:26 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:53629 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 19:58:26 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:58:26 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:58:26 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-22 19:58:26 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-22 19:58:26 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-22 19:58:26 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 19:58:26 INFO  CodeGenerator:54 - Code generated in 8.532501 ms
2019-01-22 19:58:27 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2019-01-22 19:58:27 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 129 ms on localhost (executor driver) (1/1)
2019-01-22 19:58:27 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-22 19:58:27 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.209 s
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.242817 s
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:58:27 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:58:27 INFO  CodeGenerator:54 - Code generated in 6.6748 ms
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-22 19:58:27 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:53629 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 19:58:27 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-22 19:58:27 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:58:27 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 19:58:27 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:53629 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:58:27 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-22 19:58:27 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:58:27 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-22 19:58:27 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:53629 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:58:27 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:58:27 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-22 19:58:27 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-22 19:58:27 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-22 19:58:27 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 19:58:27 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1204 bytes result sent to driver
2019-01-22 19:58:27 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 0 ms on localhost (executor driver) (1/1)
2019-01-22 19:58:27 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-22 19:58:27 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.016 s
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.019056 s
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:58:27 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 19:58:27 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:53629 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:58:27 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-22 19:58:27 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:58:27 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 19:58:27 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:53629 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:58:27 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-22 19:58:27 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:58:27 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-22 19:58:27 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:53629 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 19:58:27 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 19:58:27 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-22 19:58:27 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-22 19:58:27 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-22 19:58:27 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-22 19:58:27 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1205 bytes result sent to driver
2019-01-22 19:58:27 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 16 ms on localhost (executor driver) (1/1)
2019-01-22 19:58:27 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-22 19:58:27 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.016 s
2019-01-22 19:58:27 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.019017 s
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 19:58:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 19:58:27 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-22 19:58:27 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-22 19:58:27 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:53629 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 19:58:27 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-22 19:58:27 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 19:58:27 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_d40ef0b0cb86 inputCol, its NullRemover's IO params are set to null
2019-01-22 19:58:27 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_5111fd35eecb inputCol, its NullRemover's IO params are set to null
2019-01-22 19:59:05 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 19:59:07 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_c2368d0a1c91 inputCol, its NullRemover's IO params are set to null
2019-01-22 19:59:07 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_db8286fcdb75 inputCol, its NullRemover's IO params are set to null
2019-01-22 19:59:07 ERROR SDFGraph:78 - SDFNode shared_IDF type not assigned
2019-01-22 19:59:08 INFO  column remover:43 - removing column issue_content
2019-01-22 19:59:08 INFO  column remover:43 - removing column commit_content
2019-01-22 19:59:08 INFO  column remover:43 - removing column t_tokens
2019-01-22 19:59:08 INFO  column remover:43 - removing column s_tokens
2019-01-22 19:59:08 INFO  column remover:43 - removing column t_htf
2019-01-22 19:59:08 INFO  column remover:43 - removing column s_htf
2019-01-22 21:18:52 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 21:18:53 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 21:18:53 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 21:18:53 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 21:18:53 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 21:18:53 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 21:18:53 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 21:18:53 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 21:18:53 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 21:18:54 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 54663.
2019-01-22 21:18:54 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 21:18:54 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 21:18:54 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 21:18:54 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 21:18:54 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-867e8bb6-3714-47b8-8693-34f2a9af3189
2019-01-22 21:18:54 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 21:18:54 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 21:18:54 INFO  log:192 - Logging initialized @6964ms
2019-01-22 21:18:54 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 21:18:54 INFO  Server:419 - Started @7023ms
2019-01-22 21:18:54 INFO  AbstractConnector:278 - Started ServerConnector@7807ac2c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 21:18:54 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32fe9d0a{/jobs,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30ed9c6c{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@782a4fff{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae81e1{/stages,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2fd1731c{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae76500{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54709809{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a2da905{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@24f360b2{/storage,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60cf80e7{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@302fec27{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@770d0ea6{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@48c40605{/environment,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54107f42{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b11ef33{/executors,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@476aac9{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cea706c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a138fc5{/,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@379ab47b{/api,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4e4efc1b{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459f7aa3{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 21:18:54 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 21:19:09 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 21:19:09 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 21:19:09 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 21:19:09 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 21:19:09 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 21:19:09 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 21:19:09 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 21:19:09 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 21:19:09 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 21:19:10 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 54712.
2019-01-22 21:19:10 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 21:19:10 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 21:19:10 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 21:19:10 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 21:19:10 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-7d405e46-f715-4dea-b364-40b3260306cf
2019-01-22 21:19:10 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 21:19:10 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 21:19:10 INFO  log:192 - Logging initialized @7044ms
2019-01-22 21:19:10 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 21:19:10 INFO  Server:419 - Started @7103ms
2019-01-22 21:19:10 INFO  AbstractConnector:278 - Started ServerConnector@7807ac2c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 21:19:10 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32fe9d0a{/jobs,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30ed9c6c{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@782a4fff{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae81e1{/stages,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2fd1731c{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae76500{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54709809{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a2da905{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@24f360b2{/storage,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60cf80e7{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@302fec27{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@770d0ea6{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@48c40605{/environment,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54107f42{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b11ef33{/executors,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@476aac9{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cea706c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a138fc5{/,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@379ab47b{/api,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4e4efc1b{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459f7aa3{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 21:19:10 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 21:19:11 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 21:19:11 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54725.
2019-01-22 21:19:11 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:54725
2019-01-22 21:19:11 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 21:19:11 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 54725, None)
2019-01-22 21:19:11 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:54725 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 54725, None)
2019-01-22 21:19:11 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 54725, None)
2019-01-22 21:19:11 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 54725, None)
2019-01-22 21:19:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69e308c6{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:11 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 21:19:11 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 21:19:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@250b236d{/SQL,null,AVAILABLE,@Spark}
2019-01-22 21:19:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f3fbb8{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60e5272{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 21:19:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d755813{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60dd3c23{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 21:19:23 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-22 21:19:23 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-22 21:19:24 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-22 21:19:24 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-22 21:19:24 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-22 21:19:24 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-22 21:19:24 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-22 21:19:24 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-22 21:19:24 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-22 21:19:25 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 54766.
2019-01-22 21:19:25 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-22 21:19:25 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-22 21:19:25 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-22 21:19:25 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-22 21:19:25 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-93800b8b-e4b2-4295-84dc-bbaeae3a61e1
2019-01-22 21:19:25 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-22 21:19:25 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-22 21:19:25 INFO  log:192 - Logging initialized @6933ms
2019-01-22 21:19:25 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-22 21:19:25 INFO  Server:419 - Started @6986ms
2019-01-22 21:19:25 INFO  AbstractConnector:278 - Started ServerConnector@7807ac2c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 21:19:25 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32fe9d0a{/jobs,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30ed9c6c{/jobs/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@782a4fff{/jobs/job,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae81e1{/stages,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2fd1731c{/stages/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae76500{/stages/stage,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54709809{/stages/pool,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a2da905{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@24f360b2{/storage,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60cf80e7{/storage/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@302fec27{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@770d0ea6{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@48c40605{/environment,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54107f42{/environment/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b11ef33{/executors,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@476aac9{/executors/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cea706c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a138fc5{/,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@379ab47b{/api,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4e4efc1b{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459f7aa3{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-22 21:19:25 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-22 21:19:25 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54779.
2019-01-22 21:19:25 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:54779
2019-01-22 21:19:25 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-22 21:19:25 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 54779, None)
2019-01-22 21:19:25 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:54779 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 54779, None)
2019-01-22 21:19:25 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 54779, None)
2019-01-22 21:19:25 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 54779, None)
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69e308c6{/metrics/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-22 21:19:25 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@250b236d{/SQL,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f3fbb8{/SQL/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60e5272{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d755813{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-22 21:19:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60dd3c23{/static/sql,null,AVAILABLE,@Spark}
2019-01-22 21:19:26 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-22 21:19:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 21:19:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-22 21:19:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 21:19:27 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 21:19:28 INFO  CodeGenerator:54 - Code generated in 186.2805 ms
2019-01-22 21:19:28 INFO  CodeGenerator:54 - Code generated in 15.4041 ms
2019-01-22 21:19:28 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-22 21:19:28 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-22 21:19:28 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:54779 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 21:19:28 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-22 21:19:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 21:19:28 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 21:19:28 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 21:19:28 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-22 21:19:28 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 21:19:28 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 21:19:28 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 21:19:28 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-22 21:19:28 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-22 21:19:28 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:54779 (size: 4.4 KB, free: 1996.2 MB)
2019-01-22 21:19:28 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-22 21:19:28 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 21:19:28 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-22 21:19:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-22 21:19:28 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-22 21:19:28 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-22 21:19:28 INFO  CodeGenerator:54 - Code generated in 9.606801 ms
2019-01-22 21:19:28 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2019-01-22 21:19:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 127 ms on localhost (executor driver) (1/1)
2019-01-22 21:19:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-22 21:19:28 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.201 s
2019-01-22 21:19:28 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.238762 s
2019-01-22 21:19:28 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 21:19:28 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 21:19:28 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 21:19:28 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 21:19:28 INFO  CodeGenerator:54 - Code generated in 5.7864 ms
2019-01-22 21:19:28 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-22 21:19:28 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-22 21:19:28 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:54779 (size: 20.6 KB, free: 1996.2 MB)
2019-01-22 21:19:28 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-22 21:19:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 21:19:29 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 21:19:29 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-22 21:19:29 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 21:19:29 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 21:19:29 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-22 21:19:29 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-22 21:19:29 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:54779 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 21:19:29 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-22 21:19:29 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 21:19:29 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 21:19:29 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-22 21:19:29 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-22 21:19:29 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:54779 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 21:19:29 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 21:19:29 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-22 21:19:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-22 21:19:29 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-22 21:19:29 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-22 21:19:29 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1290 bytes result sent to driver
2019-01-22 21:19:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 10 ms on localhost (executor driver) (1/1)
2019-01-22 21:19:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-22 21:19:29 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.021 s
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.023379 s
2019-01-22 21:19:29 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 21:19:29 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 21:19:29 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 21:19:29 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 21:19:29 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 21:19:29 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 21:19:29 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:54779 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 21:19:29 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-22 21:19:29 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 21:19:29 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 21:19:29 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-22 21:19:29 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 21:19:29 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 21:19:29 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-22 21:19:29 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-22 21:19:29 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:54779 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 21:19:29 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-22 21:19:29 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 26
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 56
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 10
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 20
2019-01-22 21:19:29 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-22 21:19:29 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.2 MB)
2019-01-22 21:19:29 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.2 MB)
2019-01-22 21:19:29 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on AshCloud-D1:54779 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 21:19:29 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:54779 (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 21:19:29 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 27
2019-01-22 21:19:29 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 61
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 8
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 70
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 13
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 45
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 38
2019-01-22 21:19:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-22 21:19:29 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-22 21:19:29 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on AshCloud-D1:54779 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 52
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 53
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 65
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 12
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 37
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 66
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 43
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 17
2019-01-22 21:19:29 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on AshCloud-D1:54779 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 40
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 59
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 62
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 55
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 67
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 39
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 71
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 57
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 14
2019-01-22 21:19:29 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 63
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 36
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 48
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 19
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 22
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 15
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 29
2019-01-22 21:19:29 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:54779 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 28
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 6
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 23
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 25
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 51
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 24
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 9
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 68
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 44
2019-01-22 21:19:29 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1205 bytes result sent to driver
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 30
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 69
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 7
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 58
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 47
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 50
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 42
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 49
2019-01-22 21:19:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 9 ms on localhost (executor driver) (1/1)
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 18
2019-01-22 21:19:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 64
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 41
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 60
2019-01-22 21:19:29 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.017 s
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 46
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 16
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 21
2019-01-22 21:19:29 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.019053 s
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 54
2019-01-22 21:19:29 INFO  ContextCleaner:54 - Cleaned accumulator 11
2019-01-22 21:19:29 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-22 21:19:29 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-22 21:19:29 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-22 21:19:29 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-22 21:19:29 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-22 21:19:29 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-22 21:19:29 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:54779 (size: 20.6 KB, free: 1996.1 MB)
2019-01-22 21:19:29 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-22 21:19:29 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-22 21:19:29 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-22 21:19:29 INFO  AbstractConnector:318 - Stopped Spark@7807ac2c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-22 21:19:29 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-22 21:19:29 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-22 21:19:29 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-22 21:19:29 INFO  BlockManager:54 - BlockManager stopped
2019-01-22 21:19:29 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-22 21:19:29 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-22 21:19:29 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-22 21:19:29 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-22 21:19:29 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-8abf45d4-73a6-4d64-a1b6-665509625a35
2019-01-24 13:59:31 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-24 13:59:31 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-24 13:59:32 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-24 13:59:32 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-24 13:59:32 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-24 13:59:32 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-24 13:59:32 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-24 13:59:32 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-24 13:59:32 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-24 13:59:33 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 55243.
2019-01-24 13:59:33 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-24 13:59:33 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-24 13:59:33 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-24 13:59:33 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-24 13:59:33 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-9bbade69-59da-4386-a627-5bf3c8e967b2
2019-01-24 13:59:33 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-24 13:59:33 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-24 13:59:33 INFO  log:192 - Logging initialized @7453ms
2019-01-24 13:59:33 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-24 13:59:33 INFO  Server:419 - Started @7526ms
2019-01-24 13:59:33 INFO  AbstractConnector:278 - Started ServerConnector@7807ac2c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-24 13:59:33 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32fe9d0a{/jobs,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30ed9c6c{/jobs/json,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@782a4fff{/jobs/job,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae81e1{/stages,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2fd1731c{/stages/json,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae76500{/stages/stage,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54709809{/stages/pool,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a2da905{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@24f360b2{/storage,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60cf80e7{/storage/json,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@302fec27{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@770d0ea6{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@48c40605{/environment,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54107f42{/environment/json,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b11ef33{/executors,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@476aac9{/executors/json,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cea706c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a138fc5{/,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@379ab47b{/api,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4e4efc1b{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459f7aa3{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-24 13:59:33 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-24 13:59:33 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-24 13:59:33 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55256.
2019-01-24 13:59:33 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:55256
2019-01-24 13:59:33 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-24 13:59:33 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55256, None)
2019-01-24 13:59:33 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:55256 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 55256, None)
2019-01-24 13:59:33 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55256, None)
2019-01-24 13:59:33 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 55256, None)
2019-01-24 13:59:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69e308c6{/metrics/json,null,AVAILABLE,@Spark}
2019-01-24 13:59:34 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-24 13:59:34 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-24 13:59:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78de58ea{/SQL,null,AVAILABLE,@Spark}
2019-01-24 13:59:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60e5272{/SQL/json,null,AVAILABLE,@Spark}
2019-01-24 13:59:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@173373b4{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-24 13:59:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40d10481{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-24 13:59:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f1cae23{/static/sql,null,AVAILABLE,@Spark}
2019-01-24 13:59:34 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-24 13:59:36 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 13:59:36 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-24 13:59:36 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 13:59:36 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 13:59:36 INFO  CodeGenerator:54 - Code generated in 185.645 ms
2019-01-24 13:59:37 INFO  CodeGenerator:54 - Code generated in 13.1875 ms
2019-01-24 13:59:37 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-24 13:59:37 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-24 13:59:37 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:55256 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 13:59:37 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-24 13:59:37 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 13:59:37 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 13:59:37 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-24 13:59:37 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-24 13:59:37 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:55256 (size: 4.4 KB, free: 1996.2 MB)
2019-01-24 13:59:37 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 13:59:37 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-24 13:59:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-24 13:59:37 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-24 13:59:37 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-24 13:59:37 INFO  CodeGenerator:54 - Code generated in 7.8823 ms
2019-01-24 13:59:37 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1218 bytes result sent to driver
2019-01-24 13:59:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 139 ms on localhost (executor driver) (1/1)
2019-01-24 13:59:37 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-24 13:59:37 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.220 s
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.266002 s
2019-01-24 13:59:37 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 13:59:37 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 13:59:37 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 13:59:37 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 13:59:37 INFO  CodeGenerator:54 - Code generated in 4.4356 ms
2019-01-24 13:59:37 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-24 13:59:37 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-24 13:59:37 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:55256 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 13:59:37 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-24 13:59:37 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 13:59:37 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 13:59:37 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-24 13:59:37 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 13:59:37 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 13:59:37 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-24 13:59:37 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-24 13:59:37 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:55256 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 13:59:37 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-24 13:59:37 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 13:59:37 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 13:59:37 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-24 13:59:37 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-24 13:59:37 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:55256 (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 13:59:37 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 13:59:37 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-24 13:59:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-24 13:59:37 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-24 13:59:37 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 13:59:37 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1290 bytes result sent to driver
2019-01-24 13:59:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 93 ms on localhost (executor driver) (1/1)
2019-01-24 13:59:37 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-24 13:59:37 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.109 s
2019-01-24 13:59:37 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.110059 s
2019-01-24 13:59:38 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 13:59:38 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 13:59:38 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 13:59:38 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 13:59:38 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-24 13:59:38 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-24 13:59:38 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:55256 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 13:59:38 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-24 13:59:38 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 13:59:38 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 13:59:38 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-24 13:59:38 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 13:59:38 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 13:59:38 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 37
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 59
2019-01-24 13:59:38 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 26
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 28
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 15
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 66
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 52
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 48
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 39
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 17
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 43
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 60
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 61
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 69
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 58
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 30
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 65
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 45
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 9
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 12
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 38
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 27
2019-01-24 13:59:38 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:55256 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 10
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 40
2019-01-24 13:59:38 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-24 13:59:38 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 13:59:38 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 13:59:38 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 13:59:38 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-24 13:59:38 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 13:59:38 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 13:59:38 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 13:59:38 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-24 13:59:38 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on AshCloud-D1:55256 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 13:59:38 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.2 MB)
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 51
2019-01-24 13:59:38 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:55256 (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 13:59:38 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-24 13:59:38 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 13:59:38 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-24 13:59:38 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on AshCloud-D1:55256 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 41
2019-01-24 13:59:38 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 44
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 14
2019-01-24 13:59:38 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 24
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 70
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 6
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 22
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 55
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 19
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 57
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 13
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 36
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 20
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 18
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 23
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 49
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 8
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 67
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 71
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 68
2019-01-24 13:59:38 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on AshCloud-D1:55256 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 53
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 16
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 29
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 56
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 50
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 25
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 64
2019-01-24 13:59:38 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-24 13:59:38 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:55256 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 54
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 42
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 11
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 62
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 46
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 7
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 47
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 63
2019-01-24 13:59:38 INFO  ContextCleaner:54 - Cleaned accumulator 21
2019-01-24 13:59:38 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1291 bytes result sent to driver
2019-01-24 13:59:38 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 31 ms on localhost (executor driver) (1/1)
2019-01-24 13:59:38 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-24 13:59:38 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.031 s
2019-01-24 13:59:38 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.029429 s
2019-01-24 13:59:38 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 13:59:38 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 13:59:38 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 13:59:38 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 13:59:38 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-24 13:59:38 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-24 13:59:38 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:55256 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 13:59:38 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-24 13:59:38 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 13:59:38 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_02d997a53d13 inputCol, its NullRemover's IO params are set to null
2019-01-24 13:59:38 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_4e2f3e9c86fd inputCol, its NullRemover's IO params are set to null
2019-01-24 13:59:38 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_f2f65bb06709 inputCol, its NullRemover's IO params are set to null
2019-01-24 13:59:38 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_3412dfb87b78 inputCol, its NullRemover's IO params are set to null
2019-01-24 13:59:38 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-24 13:59:38 INFO  AbstractConnector:318 - Stopped Spark@7807ac2c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-24 13:59:38 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-24 13:59:38 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-24 13:59:38 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-24 13:59:38 INFO  BlockManager:54 - BlockManager stopped
2019-01-24 13:59:38 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-24 13:59:38 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-24 13:59:38 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-24 13:59:38 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-24 13:59:38 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-2c1e2caf-8859-42aa-9736-3b2d0503fe82
2019-01-24 14:01:34 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-24 14:01:34 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-24 14:01:34 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-24 14:01:35 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-24 14:01:35 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-24 14:01:35 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-24 14:01:35 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-24 14:01:35 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-24 14:01:35 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-24 14:01:36 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 55315.
2019-01-24 14:01:36 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-24 14:01:36 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-24 14:01:36 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-24 14:01:36 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-24 14:01:36 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-07823ba0-b5e3-41ce-8ae9-b3072bb4076e
2019-01-24 14:01:36 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-24 14:01:36 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-24 14:01:36 INFO  log:192 - Logging initialized @6908ms
2019-01-24 14:01:36 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-24 14:01:36 INFO  Server:419 - Started @6959ms
2019-01-24 14:01:36 INFO  AbstractConnector:278 - Started ServerConnector@7807ac2c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-24 14:01:36 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32fe9d0a{/jobs,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30ed9c6c{/jobs/json,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@782a4fff{/jobs/job,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae81e1{/stages,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2fd1731c{/stages/json,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ae76500{/stages/stage,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54709809{/stages/pool,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a2da905{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@24f360b2{/storage,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60cf80e7{/storage/json,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@302fec27{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@770d0ea6{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@48c40605{/environment,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54107f42{/environment/json,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b11ef33{/executors,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@476aac9{/executors/json,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cea706c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a138fc5{/,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@379ab47b{/api,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4e4efc1b{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459f7aa3{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-24 14:01:36 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-24 14:01:36 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55328.
2019-01-24 14:01:36 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:55328
2019-01-24 14:01:36 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-24 14:01:36 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55328, None)
2019-01-24 14:01:36 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:55328 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 55328, None)
2019-01-24 14:01:36 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55328, None)
2019-01-24 14:01:36 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 55328, None)
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69e308c6{/metrics/json,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-24 14:01:36 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@250b236d{/SQL,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f3fbb8{/SQL/json,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60e5272{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d755813{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-24 14:01:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60dd3c23{/static/sql,null,AVAILABLE,@Spark}
2019-01-24 14:01:37 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-24 14:01:38 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:01:38 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-24 14:01:38 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:01:38 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:01:38 INFO  CodeGenerator:54 - Code generated in 147.7719 ms
2019-01-24 14:01:39 INFO  CodeGenerator:54 - Code generated in 14.5926 ms
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-24 14:01:39 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:55328 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:01:39 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-24 14:01:39 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:01:39 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-24 14:01:39 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:55328 (size: 4.4 KB, free: 1996.2 MB)
2019-01-24 14:01:39 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:01:39 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-24 14:01:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-24 14:01:39 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-24 14:01:39 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-24 14:01:39 INFO  CodeGenerator:54 - Code generated in 10.8005 ms
2019-01-24 14:01:39 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2019-01-24 14:01:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 138 ms on localhost (executor driver) (1/1)
2019-01-24 14:01:39 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-24 14:01:39 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.191 s
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.235911 s
2019-01-24 14:01:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:01:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:01:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:01:39 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:01:39 INFO  CodeGenerator:54 - Code generated in 5.3102 ms
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-24 14:01:39 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:55328 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:01:39 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-24 14:01:39 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:01:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:01:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-24 14:01:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:01:39 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-24 14:01:39 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:55328 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:39 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-24 14:01:39 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:01:39 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-24 14:01:39 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:55328 (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:01:39 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:01:39 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-24 14:01:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-24 14:01:39 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-24 14:01:39 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:01:39 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1290 bytes result sent to driver
2019-01-24 14:01:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 16 ms on localhost (executor driver) (1/1)
2019-01-24 14:01:39 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-24 14:01:39 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.016 s
2019-01-24 14:01:39 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.019944 s
2019-01-24 14:01:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:01:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:01:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:01:39 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-24 14:01:39 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:55328 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:39 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-24 14:01:39 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:01:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:01:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-24 14:01:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:01:39 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-24 14:01:39 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-24 14:01:39 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:55328 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:39 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-24 14:01:39 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:01:40 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:01:40 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:01:40 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:01:40 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:01:40 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:01:40 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:01:40 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 16
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 9
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 29
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 17
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 54
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 20
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 14
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 53
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 13
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 41
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 30
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 62
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 47
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 64
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 22
2019-01-24 14:01:40 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-24 14:01:40 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:55328 (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:01:40 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:01:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:01:40 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-24 14:01:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-24 14:01:40 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-24 14:01:40 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on AshCloud-D1:55328 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:40 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 48
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 70
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 42
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 38
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 51
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 15
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 6
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 18
2019-01-24 14:01:40 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:55328 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 43
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 50
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 59
2019-01-24 14:01:40 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1205 bytes result sent to driver
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 23
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 56
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 60
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 37
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 52
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 58
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 49
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 8
2019-01-24 14:01:40 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on AshCloud-D1:55328 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 15 ms on localhost (executor driver) (1/1)
2019-01-24 14:01:40 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-24 14:01:40 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.031 s
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 12
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 21
2019-01-24 14:01:40 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.026733 s
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 40
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 44
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 28
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 26
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 67
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 39
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 66
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 71
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 11
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 7
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 46
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 36
2019-01-24 14:01:40 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on AshCloud-D1:55328 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 19
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 24
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 27
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 45
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 65
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 61
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 10
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 63
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 55
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 25
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 68
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 57
2019-01-24 14:01:40 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 69
2019-01-24 14:01:40 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:01:40 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:01:40 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:01:40 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-24 14:01:40 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-24 14:01:40 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:55328 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:40 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-24 14:01:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:01:40 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_877b27787dd8 inputCol, its NullRemover's IO params are set to null
2019-01-24 14:01:40 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_1beabc3b9424 inputCol, its NullRemover's IO params are set to null
2019-01-24 14:01:40 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_72aeb3991663 inputCol, its NullRemover's IO params are set to null
2019-01-24 14:01:40 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_f9fb94019221 inputCol, its NullRemover's IO params are set to null
2019-01-24 14:01:40 INFO  column remover:43 - removing column commit_content
2019-01-24 14:01:40 INFO  column remover:43 - removing column issue_content
2019-01-24 14:01:40 INFO  column remover:43 - removing column s_tokens
2019-01-24 14:01:40 INFO  column remover:43 - removing column t_tokens
2019-01-24 14:01:40 INFO  column remover:43 - removing column s_htf
2019-01-24 14:01:40 INFO  column remover:43 - removing column t_htf
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 88
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 84
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 103
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 81
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 90
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 73
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 72
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 107
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 96
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 98
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 93
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 105
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 100
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 89
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 80
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 74
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 92
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 104
2019-01-24 14:01:40 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on AshCloud-D1:55328 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 75
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 106
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 79
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 78
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 83
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 77
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 76
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 87
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 101
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 86
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 94
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 99
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 82
2019-01-24 14:01:40 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on AshCloud-D1:55328 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 102
2019-01-24 14:01:40 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on AshCloud-D1:55328 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 91
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 85
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 95
2019-01-24 14:01:40 INFO  ContextCleaner:54 - Cleaned accumulator 97
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnotnull(UDF(UDF(commit_content#17)))
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:01:41 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:01:41 INFO  CodeGenerator:54 - Code generated in 26.7094 ms
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-24 14:01:41 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on AshCloud-D1:55328 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:41 INFO  SparkContext:54 - Created broadcast 9 from rdd at IDF.scala:89
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:01:41 INFO  CodeGenerator:54 - Code generated in 19.2595 ms
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.3 MB)
2019-01-24 14:01:41 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on AshCloud-D1:55328 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:41 INFO  SparkContext:54 - Created broadcast 10 from rdd at IDF.scala:89
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:01:41 INFO  CodeGenerator:54 - Code generated in 19.1015 ms
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-24 14:01:41 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on AshCloud-D1:55328 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:41 INFO  SparkContext:54 - Created broadcast 11 from rdd at IDF.scala:89
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:01:41 INFO  CodeGenerator:54 - Code generated in 14.8684 ms
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-24 14:01:41 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on AshCloud-D1:55328 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:41 INFO  SparkContext:54 - Created broadcast 12 from rdd at IDF.scala:89
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:01:41 INFO  CodeGenerator:54 - Code generated in 15.7011 ms
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 220.9 KB, free 1994.6 MB)
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.5 MB)
2019-01-24 14:01:41 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on AshCloud-D1:55328 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:41 INFO  SparkContext:54 - Created broadcast 13 from rdd at IDF.scala:89
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:01:41 INFO  CodeGenerator:54 - Code generated in 14.9907 ms
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 220.9 KB, free 1994.3 MB)
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.3 MB)
2019-01-24 14:01:41 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on AshCloud-D1:55328 (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:01:41 INFO  SparkContext:54 - Created broadcast 14 from rdd at IDF.scala:89
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:01:41 INFO  CodeGenerator:54 - Code generated in 17.2109 ms
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 220.9 KB, free 1994.1 MB)
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.1 MB)
2019-01-24 14:01:41 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on AshCloud-D1:55328 (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:01:41 INFO  SparkContext:54 - Created broadcast 15 from rdd at IDF.scala:89
2019-01-24 14:01:41 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:01:41 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2019-01-24 14:01:41 INFO  DAGScheduler:54 - Registering RDD 67 (treeAggregate at IDF.scala:54)
2019-01-24 14:01:41 INFO  DAGScheduler:54 - Got job 3 (treeAggregate at IDF.scala:54) with 4 output partitions
2019-01-24 14:01:41 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (treeAggregate at IDF.scala:54)
2019-01-24 14:01:41 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 3)
2019-01-24 14:01:41 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 3)
2019-01-24 14:01:41 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 117.2 KB, free 1994.0 MB)
2019-01-24 14:01:41 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.9 KB, free 1993.9 MB)
2019-01-24 14:01:41 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on AshCloud-D1:55328 (size: 29.9 KB, free: 1996.0 MB)
2019-01-24 14:01:41 INFO  SparkContext:54 - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:01:41 INFO  DAGScheduler:54 - Submitting 23 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2019-01-24 14:01:41 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 23 tasks
2019-01-24 14:01:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:41 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2019-01-24 14:01:41 INFO  CodeGenerator:54 - Code generated in 7.0953 ms
2019-01-24 14:01:42 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 4486 bytes result sent to driver
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:42 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 4)
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 63 ms on localhost (executor driver) (1/23)
2019-01-24 14:01:42 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 4). 4486 bytes result sent to driver
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 5, localhost, executor driver, partition 2, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:01:42 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 5)
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 4) in 15 ms on localhost (executor driver) (2/23)
2019-01-24 14:01:42 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:01:42 INFO  CodeGenerator:54 - Code generated in 6.246 ms
2019-01-24 14:01:42 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 5). 4615 bytes result sent to driver
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Starting task 3.0 in stage 3.0 (TID 6, localhost, executor driver, partition 3, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:42 INFO  Executor:54 - Running task 3.0 in stage 3.0 (TID 6)
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 5) in 595 ms on localhost (executor driver) (3/23)
2019-01-24 14:01:42 INFO  Executor:54 - Finished task 3.0 in stage 3.0 (TID 6). 4486 bytes result sent to driver
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Starting task 4.0 in stage 3.0 (TID 7, localhost, executor driver, partition 4, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:42 INFO  Executor:54 - Running task 4.0 in stage 3.0 (TID 7)
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Finished task 3.0 in stage 3.0 (TID 6) in 16 ms on localhost (executor driver) (4/23)
2019-01-24 14:01:42 INFO  Executor:54 - Finished task 4.0 in stage 3.0 (TID 7). 4486 bytes result sent to driver
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Starting task 5.0 in stage 3.0 (TID 8, localhost, executor driver, partition 5, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:42 INFO  Executor:54 - Running task 5.0 in stage 3.0 (TID 8)
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Finished task 4.0 in stage 3.0 (TID 7) in 18 ms on localhost (executor driver) (5/23)
2019-01-24 14:01:42 INFO  Executor:54 - Finished task 5.0 in stage 3.0 (TID 8). 4529 bytes result sent to driver
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Starting task 6.0 in stage 3.0 (TID 9, localhost, executor driver, partition 6, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:42 INFO  Executor:54 - Running task 6.0 in stage 3.0 (TID 9)
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Finished task 5.0 in stage 3.0 (TID 8) in 17 ms on localhost (executor driver) (6/23)
2019-01-24 14:01:42 INFO  Executor:54 - Finished task 6.0 in stage 3.0 (TID 9). 4529 bytes result sent to driver
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Starting task 7.0 in stage 3.0 (TID 10, localhost, executor driver, partition 7, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:01:42 INFO  Executor:54 - Running task 7.0 in stage 3.0 (TID 10)
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Finished task 6.0 in stage 3.0 (TID 9) in 11 ms on localhost (executor driver) (7/23)
2019-01-24 14:01:42 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:01:42 INFO  Executor:54 - Finished task 7.0 in stage 3.0 (TID 10). 4572 bytes result sent to driver
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Starting task 8.0 in stage 3.0 (TID 11, localhost, executor driver, partition 8, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:42 INFO  Executor:54 - Running task 8.0 in stage 3.0 (TID 11)
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Finished task 7.0 in stage 3.0 (TID 10) in 31 ms on localhost (executor driver) (8/23)
2019-01-24 14:01:42 INFO  Executor:54 - Finished task 8.0 in stage 3.0 (TID 11). 4486 bytes result sent to driver
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Starting task 9.0 in stage 3.0 (TID 12, localhost, executor driver, partition 9, PROCESS_LOCAL, 8437 bytes)
2019-01-24 14:01:42 INFO  Executor:54 - Running task 9.0 in stage 3.0 (TID 12)
2019-01-24 14:01:42 INFO  TaskSetManager:54 - Finished task 8.0 in stage 3.0 (TID 11) in 16 ms on localhost (executor driver) (9/23)
2019-01-24 14:01:42 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 9.0 in stage 3.0 (TID 12). 4615 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 10.0 in stage 3.0 (TID 13, localhost, executor driver, partition 10, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 10.0 in stage 3.0 (TID 13)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 9.0 in stage 3.0 (TID 12) in 312 ms on localhost (executor driver) (10/23)
2019-01-24 14:01:43 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 10.0 in stage 3.0 (TID 13). 4572 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 11.0 in stage 3.0 (TID 14, localhost, executor driver, partition 11, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 11.0 in stage 3.0 (TID 14)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 10.0 in stage 3.0 (TID 13) in 16 ms on localhost (executor driver) (11/23)
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 11.0 in stage 3.0 (TID 14). 4443 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 12.0 in stage 3.0 (TID 15, localhost, executor driver, partition 12, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 12.0 in stage 3.0 (TID 15)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 11.0 in stage 3.0 (TID 14) in 16 ms on localhost (executor driver) (12/23)
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 12.0 in stage 3.0 (TID 15). 4486 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 13.0 in stage 3.0 (TID 16, localhost, executor driver, partition 13, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 13.0 in stage 3.0 (TID 16)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 12.0 in stage 3.0 (TID 15) in 15 ms on localhost (executor driver) (13/23)
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 13.0 in stage 3.0 (TID 16). 4486 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 14.0 in stage 3.0 (TID 17, localhost, executor driver, partition 14, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 14.0 in stage 3.0 (TID 17)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 13.0 in stage 3.0 (TID 16) in 16 ms on localhost (executor driver) (14/23)
2019-01-24 14:01:43 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 14.0 in stage 3.0 (TID 17). 4572 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 15.0 in stage 3.0 (TID 18, localhost, executor driver, partition 15, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 15.0 in stage 3.0 (TID 18)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 14.0 in stage 3.0 (TID 17) in 62 ms on localhost (executor driver) (15/23)
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 15.0 in stage 3.0 (TID 18). 4486 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 16.0 in stage 3.0 (TID 19, localhost, executor driver, partition 16, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 16.0 in stage 3.0 (TID 19)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 15.0 in stage 3.0 (TID 18) in 16 ms on localhost (executor driver) (16/23)
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 16.0 in stage 3.0 (TID 19). 4400 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 17.0 in stage 3.0 (TID 20, localhost, executor driver, partition 17, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 17.0 in stage 3.0 (TID 20)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 16.0 in stage 3.0 (TID 19) in 0 ms on localhost (executor driver) (17/23)
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 17.0 in stage 3.0 (TID 20). 4486 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 18.0 in stage 3.0 (TID 21, localhost, executor driver, partition 18, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 18.0 in stage 3.0 (TID 21)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 17.0 in stage 3.0 (TID 20) in 16 ms on localhost (executor driver) (18/23)
2019-01-24 14:01:43 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 18.0 in stage 3.0 (TID 21). 4572 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 19.0 in stage 3.0 (TID 22, localhost, executor driver, partition 19, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 19.0 in stage 3.0 (TID 22)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 18.0 in stage 3.0 (TID 21) in 15 ms on localhost (executor driver) (19/23)
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 19.0 in stage 3.0 (TID 22). 4486 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 20.0 in stage 3.0 (TID 23, localhost, executor driver, partition 20, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 20.0 in stage 3.0 (TID 23)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 19.0 in stage 3.0 (TID 22) in 16 ms on localhost (executor driver) (20/23)
2019-01-24 14:01:43 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 20.0 in stage 3.0 (TID 23). 4572 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 21.0 in stage 3.0 (TID 24, localhost, executor driver, partition 21, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 21.0 in stage 3.0 (TID 24)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 20.0 in stage 3.0 (TID 23) in 31 ms on localhost (executor driver) (21/23)
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 21.0 in stage 3.0 (TID 24). 4486 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 22.0 in stage 3.0 (TID 25, localhost, executor driver, partition 22, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 22.0 in stage 3.0 (TID 25)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 21.0 in stage 3.0 (TID 24) in 16 ms on localhost (executor driver) (22/23)
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 22.0 in stage 3.0 (TID 25). 4400 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 22.0 in stage 3.0 (TID 25) in 15 ms on localhost (executor driver) (23/23)
2019-01-24 14:01:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2019-01-24 14:01:43 INFO  DAGScheduler:54 - ShuffleMapStage 3 (treeAggregate at IDF.scala:54) finished in 1.360 s
2019-01-24 14:01:43 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-01-24 14:01:43 INFO  DAGScheduler:54 - running: Set()
2019-01-24 14:01:43 INFO  DAGScheduler:54 - waiting: Set(ResultStage 4)
2019-01-24 14:01:43 INFO  DAGScheduler:54 - failed: Set()
2019-01-24 14:01:43 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-24 14:01:43 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 118.1 KB, free 1993.8 MB)
2019-01-24 14:01:43 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 30.4 KB, free 1993.8 MB)
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on AshCloud-D1:55328 (size: 30.4 KB, free: 1996.0 MB)
2019-01-24 14:01:43 INFO  SparkContext:54 - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:01:43 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-01-24 14:01:43 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 4 tasks
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 26, localhost, executor driver, partition 0, ANY, 7649 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 26)
2019-01-24 14:01:43 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-24 14:01:43 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 26). 4659 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 27, localhost, executor driver, partition 1, ANY, 7649 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 1.0 in stage 4.0 (TID 27)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 26) in 32 ms on localhost (executor driver) (1/4)
2019-01-24 14:01:43 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-24 14:01:43 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-24 14:01:43 INFO  MemoryStore:54 - Block taskresult_27 stored as bytes in memory (estimated size 2.0 MB, free 1991.8 MB)
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Added taskresult_27 in memory on AshCloud-D1:55328 (size: 2.0 MB, free: 1993.9 MB)
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 1.0 in stage 4.0 (TID 27). 2112286 bytes result sent via BlockManager)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 2.0 in stage 4.0 (TID 28, localhost, executor driver, partition 2, ANY, 7649 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 2.0 in stage 4.0 (TID 28)
2019-01-24 14:01:43 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-24 14:01:43 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-24 14:01:43 INFO  MemoryStore:54 - Block taskresult_28 stored as bytes in memory (estimated size 2.0 MB, free 1989.8 MB)
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Added taskresult_28 in memory on AshCloud-D1:55328 (size: 2.0 MB, free: 1991.9 MB)
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 2.0 in stage 4.0 (TID 28). 2112243 bytes result sent via BlockManager)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Starting task 3.0 in stage 4.0 (TID 29, localhost, executor driver, partition 3, ANY, 7649 bytes)
2019-01-24 14:01:43 INFO  Executor:54 - Running task 3.0 in stage 4.0 (TID 29)
2019-01-24 14:01:43 INFO  ShuffleBlockFetcherIterator:54 - Getting 5 non-empty blocks out of 23 blocks
2019-01-24 14:01:43 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-24 14:01:43 INFO  Executor:54 - Finished task 3.0 in stage 4.0 (TID 29). 4616 bytes result sent to driver
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 3.0 in stage 4.0 (TID 29) in 0 ms on localhost (executor driver) (2/4)
2019-01-24 14:01:43 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:55328 after 32 ms (0 ms spent in bootstraps)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 27) in 146 ms on localhost (executor driver) (3/4)
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Removed taskresult_27 on AshCloud-D1:55328 in memory (size: 2.0 MB, free: 1993.9 MB)
2019-01-24 14:01:43 INFO  TaskSetManager:54 - Finished task 2.0 in stage 4.0 (TID 28) in 128 ms on localhost (executor driver) (4/4)
2019-01-24 14:01:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2019-01-24 14:01:43 INFO  DAGScheduler:54 - ResultStage 4 (treeAggregate at IDF.scala:54) finished in 0.238 s
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Removed taskresult_28 on AshCloud-D1:55328 in memory (size: 2.0 MB, free: 1996.0 MB)
2019-01-24 14:01:43 INFO  DAGScheduler:54 - Job 3 finished: treeAggregate at IDF.scala:54, took 1.608714 s
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 154
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 125
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 178
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 122
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 143
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 167
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Removed broadcast_16_piece0 on AshCloud-D1:55328 in memory (size: 29.9 KB, free: 1996.0 MB)
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 162
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 175
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 169
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 189
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 116
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 117
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned shuffle 0
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 128
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on AshCloud-D1:55328 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 173
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 139
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Removed broadcast_15_piece0 on AshCloud-D1:55328 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 202
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 157
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 109
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 138
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 110
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 152
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 130
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 188
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 170
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 180
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 176
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 196
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 197
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 177
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 142
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 149
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 126
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 204
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 165
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 172
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 174
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 194
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 193
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 140
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 108
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 184
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 114
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 112
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 171
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 155
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 113
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 135
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 203
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 161
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 200
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on AshCloud-D1:55328 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 201
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 145
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 187
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 132
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 120
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 166
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 123
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 136
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 124
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 146
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Removed broadcast_17_piece0 on AshCloud-D1:55328 in memory (size: 30.4 KB, free: 1996.1 MB)
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 199
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on AshCloud-D1:55328 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 190
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on AshCloud-D1:55328 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 133
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 150
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 159
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 195
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 115
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 191
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 183
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 148
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 141
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 185
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 160
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 163
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 181
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 168
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 182
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 131
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on AshCloud-D1:55328 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 192
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 134
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 127
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 129
2019-01-24 14:01:43 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on AshCloud-D1:55328 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 121
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 147
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 153
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 186
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 198
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 179
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 144
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 118
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 111
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 158
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 119
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 164
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 156
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 137
2019-01-24 14:01:43 INFO  ContextCleaner:54 - Cleaned accumulator 151
2019-01-24 14:01:44 INFO  column remover:43 - removing column commit_content
2019-01-24 14:01:44 INFO  column remover:43 - removing column issue_content
2019-01-24 14:01:44 INFO  column remover:43 - removing column s_tokens
2019-01-24 14:01:44 INFO  column remover:43 - removing column t_tokens
2019-01-24 14:01:44 INFO  column remover:43 - removing column s_htf
2019-01-24 14:01:44 INFO  column remover:43 - removing column t_htf
2019-01-24 14:01:44 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-24 14:01:44 INFO  AbstractConnector:318 - Stopped Spark@7807ac2c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-24 14:01:44 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-24 14:01:45 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-24 14:01:45 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-24 14:01:45 INFO  BlockManager:54 - BlockManager stopped
2019-01-24 14:01:45 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-24 14:01:45 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-24 14:01:45 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-24 14:01:45 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-24 14:01:45 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-872b0952-fb32-4f54-a1d8-f4178ec6333e
2019-01-24 14:02:25 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-24 14:02:25 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-24 14:02:25 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-24 14:02:25 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-24 14:02:25 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-24 14:02:25 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-24 14:02:25 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-24 14:02:25 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-24 14:02:25 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-24 14:02:26 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 55380.
2019-01-24 14:02:26 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-24 14:02:26 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-24 14:02:26 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-24 14:02:26 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-24 14:02:26 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-6e3e5c46-e323-4695-bf72-00b23998c932
2019-01-24 14:02:26 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-24 14:02:26 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-24 14:02:26 INFO  log:192 - Logging initialized @7245ms
2019-01-24 14:02:26 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-24 14:02:26 INFO  Server:419 - Started @7299ms
2019-01-24 14:02:26 INFO  AbstractConnector:278 - Started ServerConnector@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-24 14:02:26 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26221bad{/jobs,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/json,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@468dda3e{/jobs/job,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/json,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1729ec00{/stages/stage,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/json,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/environment/json,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/json,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/static,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3062f9f4{/api,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-24 14:02:26 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-24 14:02:27 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-24 14:02:27 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55393.
2019-01-24 14:02:27 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:55393
2019-01-24 14:02:27 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-24 14:02:27 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55393, None)
2019-01-24 14:02:27 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:55393 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 55393, None)
2019-01-24 14:02:27 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55393, None)
2019-01-24 14:02:27 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 55393, None)
2019-01-24 14:02:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12ad1b2a{/metrics/json,null,AVAILABLE,@Spark}
2019-01-24 14:02:27 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-24 14:02:27 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-24 14:02:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL,null,AVAILABLE,@Spark}
2019-01-24 14:02:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1624775{/SQL/json,null,AVAILABLE,@Spark}
2019-01-24 14:02:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-24 14:02:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@712ac7e6{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-24 14:02:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e43bfe{/static/sql,null,AVAILABLE,@Spark}
2019-01-24 14:02:27 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-24 14:02:29 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:29 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-24 14:02:29 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:02:29 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:02:30 INFO  CodeGenerator:54 - Code generated in 167.2899 ms
2019-01-24 14:02:30 INFO  CodeGenerator:54 - Code generated in 14.5468 ms
2019-01-24 14:02:30 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-24 14:02:30 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-24 14:02:30 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:02:30 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-24 14:02:30 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:30 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:02:30 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:02:30 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:02:30 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:02:30 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:02:30 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:02:30 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-24 14:02:30 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-24 14:02:30 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:55393 (size: 4.4 KB, free: 1996.2 MB)
2019-01-24 14:02:30 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:02:30 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:02:30 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-24 14:02:30 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-24 14:02:30 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-24 14:02:30 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-24 14:02:30 INFO  CodeGenerator:54 - Code generated in 10.7813 ms
2019-01-24 14:02:30 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1218 bytes result sent to driver
2019-01-24 14:02:30 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 125 ms on localhost (executor driver) (1/1)
2019-01-24 14:02:30 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-24 14:02:30 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.203 s
2019-01-24 14:02:30 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.255304 s
2019-01-24 14:02:30 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:30 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:02:30 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:02:30 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:02:30 INFO  CodeGenerator:54 - Code generated in 5.1549 ms
2019-01-24 14:02:30 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-24 14:02:30 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-24 14:02:30 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:02:30 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-24 14:02:30 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:31 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:31 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-24 14:02:31 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:02:31 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:02:31 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-24 14:02:31 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-24 14:02:31 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:31 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-24 14:02:31 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:31 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:02:31 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-24 14:02:31 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-24 14:02:31 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:55393 (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:02:31 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:02:31 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-24 14:02:31 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-24 14:02:31 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-24 14:02:31 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:02:31 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1204 bytes result sent to driver
2019-01-24 14:02:31 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 0 ms on localhost (executor driver) (1/1)
2019-01-24 14:02:31 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-24 14:02:31 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.031 s
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.020760 s
2019-01-24 14:02:31 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:31 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:02:31 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:02:31 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:02:31 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-24 14:02:31 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-24 14:02:31 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:31 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-24 14:02:31 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:31 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:31 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-24 14:02:31 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:02:31 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:02:31 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-24 14:02:31 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-24 14:02:31 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:31 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-24 14:02:31 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:31 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:02:31 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-24 14:02:31 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-24 14:02:31 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:55393 (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:02:31 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:02:31 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-24 14:02:31 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-24 14:02:31 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-24 14:02:31 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-24 14:02:31 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1119 bytes result sent to driver
2019-01-24 14:02:31 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 0 ms on localhost (executor driver) (1/1)
2019-01-24 14:02:31 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-24 14:02:31 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.015 s
2019-01-24 14:02:31 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.019926 s
2019-01-24 14:02:31 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:31 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:02:31 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:02:31 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:02:31 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-24 14:02:31 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-24 14:02:31 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:31 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-24 14:02:31 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:31 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_4e421d263fde inputCol, its NullRemover's IO params are set to null
2019-01-24 14:02:31 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_2febd413f18a inputCol, its NullRemover's IO params are set to null
2019-01-24 14:02:31 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_94eebbcd138d inputCol, its NullRemover's IO params are set to null
2019-01-24 14:02:31 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_a5d66665b2e7 inputCol, its NullRemover's IO params are set to null
2019-01-24 14:02:31 INFO  column remover:43 - removing column commit_content
2019-01-24 14:02:31 INFO  column remover:43 - removing column issue_content
2019-01-24 14:02:31 INFO  column remover:43 - removing column s_tokens
2019-01-24 14:02:31 INFO  column remover:43 - removing column t_tokens
2019-01-24 14:02:31 INFO  column remover:43 - removing column t_htf
2019-01-24 14:02:31 INFO  column remover:43 - removing column s_htf
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 95
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 57
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 41
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 63
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 97
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 40
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 19
2019-01-24 14:02:31 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on AshCloud-D1:55393 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 79
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 51
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 44
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 24
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 85
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 70
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 21
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 10
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 75
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 12
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 92
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 80
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 25
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 48
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 86
2019-01-24 14:02:31 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on AshCloud-D1:55393 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 67
2019-01-24 14:02:31 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on AshCloud-D1:55393 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 87
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 27
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 100
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 88
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 59
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 56
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 37
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 29
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 50
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 46
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 18
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 45
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 78
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 38
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 68
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 89
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 94
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 58
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 96
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 98
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 103
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 105
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 39
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 60
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 61
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 15
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 23
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 52
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 104
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 47
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 36
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 91
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 8
2019-01-24 14:02:31 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on AshCloud-D1:55393 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 99
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 64
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 20
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 106
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 22
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 17
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 102
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 13
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 16
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 77
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 9
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 76
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 83
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 53
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 30
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 74
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 71
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 14
2019-01-24 14:02:31 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:55393 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 90
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 26
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 42
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 55
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 107
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 82
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 54
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 81
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 66
2019-01-24 14:02:31 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on AshCloud-D1:55393 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 6
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 72
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 65
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 84
2019-01-24 14:02:31 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on AshCloud-D1:55393 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 43
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 93
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 7
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 69
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 101
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 49
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 28
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 62
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 73
2019-01-24 14:02:31 INFO  ContextCleaner:54 - Cleaned accumulator 11
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:02:32 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:02:32 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:02:32 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:02:32 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:02:32 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnotnull(UDF(UDF(commit_content#17)))
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-24 14:02:32 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:02:32 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:02:32 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-24 14:02:32 INFO  CodeGenerator:54 - Code generated in 40.8146 ms
2019-01-24 14:02:32 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-24 14:02:32 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-24 14:02:32 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:32 INFO  SparkContext:54 - Created broadcast 9 from rdd at IDF.scala:89
2019-01-24 14:02:32 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:32 INFO  CodeGenerator:54 - Code generated in 23.69 ms
2019-01-24 14:02:32 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-24 14:02:32 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.3 MB)
2019-01-24 14:02:32 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:32 INFO  SparkContext:54 - Created broadcast 10 from rdd at IDF.scala:89
2019-01-24 14:02:32 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:32 INFO  CodeGenerator:54 - Code generated in 21.2299 ms
2019-01-24 14:02:32 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-24 14:02:33 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-24 14:02:33 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:33 INFO  SparkContext:54 - Created broadcast 11 from rdd at IDF.scala:89
2019-01-24 14:02:33 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:33 INFO  CodeGenerator:54 - Code generated in 24.4446 ms
2019-01-24 14:02:33 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-24 14:02:33 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-24 14:02:33 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:33 INFO  SparkContext:54 - Created broadcast 12 from rdd at IDF.scala:89
2019-01-24 14:02:33 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:33 INFO  CodeGenerator:54 - Code generated in 18.1132 ms
2019-01-24 14:02:33 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 220.9 KB, free 1994.6 MB)
2019-01-24 14:02:33 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.5 MB)
2019-01-24 14:02:33 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:33 INFO  SparkContext:54 - Created broadcast 13 from rdd at IDF.scala:89
2019-01-24 14:02:33 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:33 INFO  CodeGenerator:54 - Code generated in 17.4422 ms
2019-01-24 14:02:33 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 220.9 KB, free 1994.3 MB)
2019-01-24 14:02:33 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.3 MB)
2019-01-24 14:02:33 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:02:33 INFO  SparkContext:54 - Created broadcast 14 from rdd at IDF.scala:89
2019-01-24 14:02:33 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:33 INFO  CodeGenerator:54 - Code generated in 16.2982 ms
2019-01-24 14:02:33 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 220.9 KB, free 1994.1 MB)
2019-01-24 14:02:33 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.1 MB)
2019-01-24 14:02:33 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:02:33 INFO  SparkContext:54 - Created broadcast 15 from rdd at IDF.scala:89
2019-01-24 14:02:33 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:33 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2019-01-24 14:02:33 INFO  DAGScheduler:54 - Registering RDD 67 (treeAggregate at IDF.scala:54)
2019-01-24 14:02:33 INFO  DAGScheduler:54 - Got job 3 (treeAggregate at IDF.scala:54) with 4 output partitions
2019-01-24 14:02:33 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (treeAggregate at IDF.scala:54)
2019-01-24 14:02:33 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 3)
2019-01-24 14:02:33 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 3)
2019-01-24 14:02:33 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-24 14:02:33 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 117.2 KB, free 1994.0 MB)
2019-01-24 14:02:33 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 30.5 KB, free 1993.9 MB)
2019-01-24 14:02:33 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on AshCloud-D1:55393 (size: 30.5 KB, free: 1996.0 MB)
2019-01-24 14:02:33 INFO  SparkContext:54 - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:02:33 INFO  DAGScheduler:54 - Submitting 23 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2019-01-24 14:02:33 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 23 tasks
2019-01-24 14:02:33 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:33 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2019-01-24 14:02:33 INFO  CodeGenerator:54 - Code generated in 8.2191 ms
2019-01-24 14:02:33 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 4572 bytes result sent to driver
2019-01-24 14:02:33 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:33 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 4)
2019-01-24 14:02:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 78 ms on localhost (executor driver) (1/23)
2019-01-24 14:02:33 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 4). 4486 bytes result sent to driver
2019-01-24 14:02:33 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 5, localhost, executor driver, partition 2, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:02:33 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 5)
2019-01-24 14:02:33 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 4) in 16 ms on localhost (executor driver) (2/23)
2019-01-24 14:02:33 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:02:33 INFO  CodeGenerator:54 - Code generated in 6.0723 ms
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 5). 4701 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 3.0 in stage 3.0 (TID 6, localhost, executor driver, partition 3, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 3.0 in stage 3.0 (TID 6)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 5) in 545 ms on localhost (executor driver) (3/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 3.0 in stage 3.0 (TID 6). 4443 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 4.0 in stage 3.0 (TID 7, localhost, executor driver, partition 4, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 4.0 in stage 3.0 (TID 7)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 3.0 in stage 3.0 (TID 6) in 16 ms on localhost (executor driver) (4/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 4.0 in stage 3.0 (TID 7). 4443 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 5.0 in stage 3.0 (TID 8, localhost, executor driver, partition 5, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 5.0 in stage 3.0 (TID 8)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 4.0 in stage 3.0 (TID 7) in 16 ms on localhost (executor driver) (5/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 5.0 in stage 3.0 (TID 8). 4486 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 6.0 in stage 3.0 (TID 9, localhost, executor driver, partition 6, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 6.0 in stage 3.0 (TID 9)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 5.0 in stage 3.0 (TID 8) in 15 ms on localhost (executor driver) (6/23)
2019-01-24 14:02:34 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 6.0 in stage 3.0 (TID 9). 4572 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 7.0 in stage 3.0 (TID 10, localhost, executor driver, partition 7, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 7.0 in stage 3.0 (TID 10)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 6.0 in stage 3.0 (TID 9) in 32 ms on localhost (executor driver) (7/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 7.0 in stage 3.0 (TID 10). 4486 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 8.0 in stage 3.0 (TID 11, localhost, executor driver, partition 8, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 8.0 in stage 3.0 (TID 11)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 7.0 in stage 3.0 (TID 10) in 15 ms on localhost (executor driver) (8/23)
2019-01-24 14:02:34 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 8.0 in stage 3.0 (TID 11). 4572 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 9.0 in stage 3.0 (TID 12, localhost, executor driver, partition 9, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 9.0 in stage 3.0 (TID 12)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 8.0 in stage 3.0 (TID 11) in 47 ms on localhost (executor driver) (9/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 9.0 in stage 3.0 (TID 12). 4486 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 10.0 in stage 3.0 (TID 13, localhost, executor driver, partition 10, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 10.0 in stage 3.0 (TID 13)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 9.0 in stage 3.0 (TID 12) in 16 ms on localhost (executor driver) (10/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 10.0 in stage 3.0 (TID 13). 4400 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 11.0 in stage 3.0 (TID 14, localhost, executor driver, partition 11, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 11.0 in stage 3.0 (TID 14)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 10.0 in stage 3.0 (TID 13) in 15 ms on localhost (executor driver) (11/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 11.0 in stage 3.0 (TID 14). 4400 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 12.0 in stage 3.0 (TID 15, localhost, executor driver, partition 12, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 12.0 in stage 3.0 (TID 15)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 11.0 in stage 3.0 (TID 14) in 15 ms on localhost (executor driver) (12/23)
2019-01-24 14:02:34 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 12.0 in stage 3.0 (TID 15). 4658 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 13.0 in stage 3.0 (TID 16, localhost, executor driver, partition 13, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 13.0 in stage 3.0 (TID 16)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 12.0 in stage 3.0 (TID 15) in 47 ms on localhost (executor driver) (13/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 13.0 in stage 3.0 (TID 16). 4486 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 14.0 in stage 3.0 (TID 17, localhost, executor driver, partition 14, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 14.0 in stage 3.0 (TID 17)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 13.0 in stage 3.0 (TID 16) in 16 ms on localhost (executor driver) (14/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 14.0 in stage 3.0 (TID 17). 4486 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 15.0 in stage 3.0 (TID 18, localhost, executor driver, partition 15, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 15.0 in stage 3.0 (TID 18)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 14.0 in stage 3.0 (TID 17) in 15 ms on localhost (executor driver) (15/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 15.0 in stage 3.0 (TID 18). 4486 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 16.0 in stage 3.0 (TID 19, localhost, executor driver, partition 16, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 16.0 in stage 3.0 (TID 19)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 15.0 in stage 3.0 (TID 18) in 16 ms on localhost (executor driver) (16/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 16.0 in stage 3.0 (TID 19). 4486 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 17.0 in stage 3.0 (TID 20, localhost, executor driver, partition 17, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 17.0 in stage 3.0 (TID 20)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 16.0 in stage 3.0 (TID 19) in 16 ms on localhost (executor driver) (17/23)
2019-01-24 14:02:34 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 17.0 in stage 3.0 (TID 20). 4572 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 18.0 in stage 3.0 (TID 21, localhost, executor driver, partition 18, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 18.0 in stage 3.0 (TID 21)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 17.0 in stage 3.0 (TID 20) in 31 ms on localhost (executor driver) (18/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 18.0 in stage 3.0 (TID 21). 4486 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 19.0 in stage 3.0 (TID 22, localhost, executor driver, partition 19, PROCESS_LOCAL, 8437 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 19.0 in stage 3.0 (TID 22)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 18.0 in stage 3.0 (TID 21) in 16 ms on localhost (executor driver) (19/23)
2019-01-24 14:02:34 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 19.0 in stage 3.0 (TID 22). 4572 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 20.0 in stage 3.0 (TID 23, localhost, executor driver, partition 20, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 20.0 in stage 3.0 (TID 23)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 19.0 in stage 3.0 (TID 22) in 438 ms on localhost (executor driver) (20/23)
2019-01-24 14:02:34 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 20.0 in stage 3.0 (TID 23). 4572 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 21.0 in stage 3.0 (TID 24, localhost, executor driver, partition 21, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 21.0 in stage 3.0 (TID 24)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 20.0 in stage 3.0 (TID 23) in 15 ms on localhost (executor driver) (21/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 21.0 in stage 3.0 (TID 24). 4486 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 22.0 in stage 3.0 (TID 25, localhost, executor driver, partition 22, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 22.0 in stage 3.0 (TID 25)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 21.0 in stage 3.0 (TID 24) in 16 ms on localhost (executor driver) (22/23)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 22.0 in stage 3.0 (TID 25). 4486 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 22.0 in stage 3.0 (TID 25) in 16 ms on localhost (executor driver) (23/23)
2019-01-24 14:02:34 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2019-01-24 14:02:34 INFO  DAGScheduler:54 - ShuffleMapStage 3 (treeAggregate at IDF.scala:54) finished in 1.469 s
2019-01-24 14:02:34 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-01-24 14:02:34 INFO  DAGScheduler:54 - running: Set()
2019-01-24 14:02:34 INFO  DAGScheduler:54 - waiting: Set(ResultStage 4)
2019-01-24 14:02:34 INFO  DAGScheduler:54 - failed: Set()
2019-01-24 14:02:34 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-24 14:02:34 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 118.1 KB, free 1993.8 MB)
2019-01-24 14:02:34 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 31.3 KB, free 1993.8 MB)
2019-01-24 14:02:34 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on AshCloud-D1:55393 (size: 31.3 KB, free: 1996.0 MB)
2019-01-24 14:02:34 INFO  SparkContext:54 - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:02:34 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-01-24 14:02:34 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 4 tasks
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 26, localhost, executor driver, partition 0, ANY, 7649 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 26)
2019-01-24 14:02:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-24 14:02:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2019-01-24 14:02:34 INFO  BlockManagerInfo:54 - Removed broadcast_16_piece0 on AshCloud-D1:55393 in memory (size: 30.5 KB, free: 1996.0 MB)
2019-01-24 14:02:34 INFO  MemoryStore:54 - Block taskresult_26 stored as bytes in memory (estimated size 2.0 MB, free 1991.9 MB)
2019-01-24 14:02:34 INFO  BlockManagerInfo:54 - Added taskresult_26 in memory on AshCloud-D1:55393 (size: 2.0 MB, free: 1994.0 MB)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 26). 2112243 bytes result sent via BlockManager)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 27, localhost, executor driver, partition 1, ANY, 7649 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 1.0 in stage 4.0 (TID 27)
2019-01-24 14:02:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-24 14:02:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 1.0 in stage 4.0 (TID 27). 4702 bytes result sent to driver
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 2.0 in stage 4.0 (TID 28, localhost, executor driver, partition 2, ANY, 7649 bytes)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 27) in 16 ms on localhost (executor driver) (1/4)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 2.0 in stage 4.0 (TID 28)
2019-01-24 14:02:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-24 14:02:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-24 14:02:34 INFO  MemoryStore:54 - Block taskresult_28 stored as bytes in memory (estimated size 2.0 MB, free 1989.9 MB)
2019-01-24 14:02:34 INFO  BlockManagerInfo:54 - Added taskresult_28 in memory on AshCloud-D1:55393 (size: 2.0 MB, free: 1992.0 MB)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 2.0 in stage 4.0 (TID 28). 2112243 bytes result sent via BlockManager)
2019-01-24 14:02:34 INFO  TaskSetManager:54 - Starting task 3.0 in stage 4.0 (TID 29, localhost, executor driver, partition 3, ANY, 7649 bytes)
2019-01-24 14:02:34 INFO  Executor:54 - Running task 3.0 in stage 4.0 (TID 29)
2019-01-24 14:02:34 INFO  ShuffleBlockFetcherIterator:54 - Getting 5 non-empty blocks out of 23 blocks
2019-01-24 14:02:34 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-24 14:02:34 INFO  MemoryStore:54 - Block taskresult_29 stored as bytes in memory (estimated size 2.0 MB, free 1987.9 MB)
2019-01-24 14:02:34 INFO  BlockManagerInfo:54 - Added taskresult_29 in memory on AshCloud-D1:55393 (size: 2.0 MB, free: 1989.9 MB)
2019-01-24 14:02:34 INFO  Executor:54 - Finished task 3.0 in stage 4.0 (TID 29). 2112243 bytes result sent via BlockManager)
2019-01-24 14:02:34 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:55393 after 45 ms (0 ms spent in bootstraps)
2019-01-24 14:02:35 INFO  TaskSetManager:54 - Finished task 2.0 in stage 4.0 (TID 28) in 125 ms on localhost (executor driver) (2/4)
2019-01-24 14:02:35 INFO  BlockManagerInfo:54 - Removed taskresult_28 on AshCloud-D1:55393 in memory (size: 2.0 MB, free: 1992.0 MB)
2019-01-24 14:02:35 INFO  TaskSetManager:54 - Finished task 3.0 in stage 4.0 (TID 29) in 109 ms on localhost (executor driver) (3/4)
2019-01-24 14:02:35 INFO  BlockManagerInfo:54 - Removed taskresult_29 on AshCloud-D1:55393 in memory (size: 2.0 MB, free: 1994.0 MB)
2019-01-24 14:02:35 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 26) in 235 ms on localhost (executor driver) (4/4)
2019-01-24 14:02:35 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2019-01-24 14:02:35 INFO  DAGScheduler:54 - ResultStage 4 (treeAggregate at IDF.scala:54) finished in 0.281 s
2019-01-24 14:02:35 INFO  BlockManagerInfo:54 - Removed taskresult_26 on AshCloud-D1:55393 in memory (size: 2.0 MB, free: 1996.0 MB)
2019-01-24 14:02:35 INFO  DAGScheduler:54 - Job 3 finished: treeAggregate at IDF.scala:54, took 1.768504 s
2019-01-24 14:02:35 INFO  ContextCleaner:54 - Cleaned accumulator 117
2019-01-24 14:02:35 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on AshCloud-D1:55393 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:02:35 INFO  ContextCleaner:54 - Cleaned accumulator 119
2019-01-24 14:02:35 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on AshCloud-D1:55393 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:02:35 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on AshCloud-D1:55393 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:02:35 INFO  ContextCleaner:54 - Cleaned accumulator 169
2019-01-24 14:02:35 INFO  ContextCleaner:54 - Cleaned shuffle 0
2019-01-24 14:02:35 INFO  BlockManagerInfo:54 - Removed broadcast_17_piece0 on AshCloud-D1:55393 in memory (size: 31.3 KB, free: 1996.1 MB)
2019-01-24 14:02:35 INFO  ContextCleaner:54 - Cleaned accumulator 113
2019-01-24 14:02:35 INFO  ContextCleaner:54 - Cleaned accumulator 166
2019-01-24 14:02:35 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on AshCloud-D1:55393 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:35 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on AshCloud-D1:55393 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:35 INFO  ContextCleaner:54 - Cleaned accumulator 161
2019-01-24 14:02:35 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on AshCloud-D1:55393 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:35 INFO  ContextCleaner:54 - Cleaned accumulator 167
2019-01-24 14:02:35 INFO  BlockManagerInfo:54 - Removed broadcast_15_piece0 on AshCloud-D1:55393 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:02:35 INFO  column remover:43 - removing column commit_content
2019-01-24 14:02:35 INFO  column remover:43 - removing column issue_content
2019-01-24 14:02:35 INFO  column remover:43 - removing column s_tokens
2019-01-24 14:02:35 INFO  column remover:43 - removing column t_tokens
2019-01-24 14:02:35 INFO  column remover:43 - removing column t_htf
2019-01-24 14:02:35 INFO  column remover:43 - removing column s_htf
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54))),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54))),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnotnull(UDF(UDF(commit_content#17)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_id: string, commit_date: string, commit_content: string, commit_author: string, commit_type: string ... 3 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54))),isnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54))),isnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnull(UDF(UDF(commit_content#17)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_id: string, commit_date: string, commit_content: string, commit_author: string, commit_type: string ... 3 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_summary#54))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnull(UDF(commit_content#17))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_id: string, commit_date: string, commit_content: string, commit_author: string, commit_type: string ... 3 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnull(UDF(issue_resolution#48))
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(commit_content#17)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_id: string, commit_date: string, commit_content: string, commit_author: string, commit_type: string ... 3 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(commit_content)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnull(issue_summary#54)
2019-01-24 14:02:39 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_id: string, issue_resolved_date: string, issue_resolution: string, issue_content: string, issue_priority: string ... 9 more fields>
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNull(issue_summary)
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 14.0054 ms
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 18.2068 ms
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 14.0222 ms
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 10.6475 ms
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 13.3621 ms
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 11.0544 ms
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 11.4561 ms
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 21.465 ms
2019-01-24 14:02:39 INFO  MemoryStore:54 - Block broadcast_18 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-24 14:02:39 INFO  MemoryStore:54 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-24 14:02:39 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:39 INFO  SparkContext:54 - Created broadcast 18 from show at SparkTraceTask.java:200
2019-01-24 14:02:39 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 9.4274 ms
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 7.0547 ms
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 6.6399 ms
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 8.7404 ms
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 8.0337 ms
2019-01-24 14:02:39 INFO  CodeGenerator:54 - Code generated in 40.7069 ms
2019-01-24 14:02:39 INFO  MemoryStore:54 - Block broadcast_19 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.3 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 19 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 9.2387 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 7.7653 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 6.9419 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 11.4164 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_20 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 20 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 7.6629 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 11.4492 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_21 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 21 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 12.889 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_22 stored as values in memory (estimated size 220.9 KB, free 1994.6 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_22_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.5 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 22 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 11.0103 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 8.9168 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 9.4675 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 8.3234 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 9.0128 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 10.3542 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 22.2675 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_23 stored as values in memory (estimated size 220.9 KB, free 1994.3 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_23_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.3 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 23 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 7.7055 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 11.1632 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 8.023 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 15.6071 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_24 stored as values in memory (estimated size 220.9 KB, free 1994.1 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_24_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.1 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_24_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 24 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 18.9087 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_25 stored as values in memory (estimated size 220.9 KB, free 1993.9 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_25_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.8 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_25_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 25 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 6.8996 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 7.0281 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 7.7453 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 6.4289 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 6.5813 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 8.7736 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_26 stored as values in memory (estimated size 220.9 KB, free 1993.6 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_26_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.6 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_26_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 26 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 5.6794 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 5.3559 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 8.561 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_27 stored as values in memory (estimated size 220.9 KB, free 1993.4 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_27_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.4 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_27_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 27 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 9.2634 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_28 stored as values in memory (estimated size 220.9 KB, free 1993.2 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_28_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1993.1 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_28_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1995.9 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 28 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 5.4243 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 5.9853 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 5.6741 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 7.6573 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_29 stored as values in memory (estimated size 220.9 KB, free 1992.9 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_29_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.9 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_29_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1995.9 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 29 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 5.7179 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 7.5462 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_30 stored as values in memory (estimated size 220.9 KB, free 1992.7 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_30_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.7 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_30_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1995.9 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 30 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 7.1741 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_31 stored as values in memory (estimated size 220.9 KB, free 1992.4 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_31_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.4 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_31_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1995.9 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 31 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 5.511 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 6.3299 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 8.8848 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_32 stored as values in memory (estimated size 220.9 KB, free 1992.2 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_32_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.2 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_32_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1995.9 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 32 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 9.1304 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_33 stored as values in memory (estimated size 220.9 KB, free 1992.0 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_33_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1992.0 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_33_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1995.8 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 33 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 5.2813 ms
2019-01-24 14:02:40 INFO  CodeGenerator:54 - Code generated in 7.7844 ms
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_34 stored as values in memory (estimated size 220.9 KB, free 1991.7 MB)
2019-01-24 14:02:40 INFO  MemoryStore:54 - Block broadcast_34_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.7 MB)
2019-01-24 14:02:40 INFO  BlockManagerInfo:54 - Added broadcast_34_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1995.8 MB)
2019-01-24 14:02:40 INFO  SparkContext:54 - Created broadcast 34 from show at SparkTraceTask.java:200
2019-01-24 14:02:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:41 INFO  CodeGenerator:54 - Code generated in 8.8816 ms
2019-01-24 14:02:41 INFO  MemoryStore:54 - Block broadcast_35 stored as values in memory (estimated size 220.9 KB, free 1991.5 MB)
2019-01-24 14:02:41 INFO  MemoryStore:54 - Block broadcast_35_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.5 MB)
2019-01-24 14:02:41 INFO  BlockManagerInfo:54 - Added broadcast_35_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1995.8 MB)
2019-01-24 14:02:41 INFO  SparkContext:54 - Created broadcast 35 from show at SparkTraceTask.java:200
2019-01-24 14:02:41 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:41 INFO  CodeGenerator:54 - Code generated in 5.8513 ms
2019-01-24 14:02:41 INFO  MemoryStore:54 - Block broadcast_36 stored as values in memory (estimated size 220.9 KB, free 1991.3 MB)
2019-01-24 14:02:41 INFO  MemoryStore:54 - Block broadcast_36_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.2 MB)
2019-01-24 14:02:41 INFO  BlockManagerInfo:54 - Added broadcast_36_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1995.8 MB)
2019-01-24 14:02:41 INFO  SparkContext:54 - Created broadcast 36 from show at SparkTraceTask.java:200
2019-01-24 14:02:41 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:41 INFO  CodeGenerator:54 - Code generated in 7.2666 ms
2019-01-24 14:02:41 INFO  MemoryStore:54 - Block broadcast_37 stored as values in memory (estimated size 220.9 KB, free 1991.0 MB)
2019-01-24 14:02:41 INFO  MemoryStore:54 - Block broadcast_37_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1991.0 MB)
2019-01-24 14:02:41 INFO  BlockManagerInfo:54 - Added broadcast_37_piece0 in memory on AshCloud-D1:55393 (size: 20.6 KB, free: 1995.8 MB)
2019-01-24 14:02:41 INFO  SparkContext:54 - Created broadcast 37 from show at SparkTraceTask.java:200
2019-01-24 14:02:41 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:02:41 INFO  SparkContext:54 - Starting job: show at SparkTraceTask.java:200
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Got job 4 (show at SparkTraceTask.java:200) with 1 output partitions
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (show at SparkTraceTask.java:200)
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[249] at show at SparkTraceTask.java:200), which has no missing parents
2019-01-24 14:02:41 INFO  MemoryStore:54 - Block broadcast_38 stored as values in memory (estimated size 2.5 MB, free 1988.5 MB)
2019-01-24 14:02:41 INFO  MemoryStore:54 - Block broadcast_38_piece0 stored as bytes in memory (estimated size 193.2 KB, free 1988.3 MB)
2019-01-24 14:02:41 INFO  BlockManagerInfo:54 - Added broadcast_38_piece0 in memory on AshCloud-D1:55393 (size: 193.2 KB, free: 1995.6 MB)
2019-01-24 14:02:41 INFO  SparkContext:54 - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[249] at show at SparkTraceTask.java:200) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:02:41 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2019-01-24 14:02:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 8079 bytes)
2019-01-24 14:02:41 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 30)
2019-01-24 14:02:41 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 30). 10415 bytes result sent to driver
2019-01-24 14:02:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 30) in 31 ms on localhost (executor driver) (1/1)
2019-01-24 14:02:41 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2019-01-24 14:02:41 INFO  DAGScheduler:54 - ResultStage 5 (show at SparkTraceTask.java:200) finished in 0.047 s
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Job 4 finished: show at SparkTraceTask.java:200, took 0.045087 s
2019-01-24 14:02:41 INFO  SparkContext:54 - Starting job: show at SparkTraceTask.java:200
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Got job 5 (show at SparkTraceTask.java:200) with 4 output partitions
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (show at SparkTraceTask.java:200)
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Submitting ResultStage 6 (MapPartitionsRDD[249] at show at SparkTraceTask.java:200), which has no missing parents
2019-01-24 14:02:41 INFO  MemoryStore:54 - Block broadcast_39 stored as values in memory (estimated size 2.5 MB, free 1985.8 MB)
2019-01-24 14:02:41 INFO  MemoryStore:54 - Block broadcast_39_piece0 stored as bytes in memory (estimated size 193.2 KB, free 1985.6 MB)
2019-01-24 14:02:41 INFO  BlockManagerInfo:54 - Added broadcast_39_piece0 in memory on AshCloud-D1:55393 (size: 193.2 KB, free: 1995.4 MB)
2019-01-24 14:02:41 INFO  SparkContext:54 - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 6 (MapPartitionsRDD[249] at show at SparkTraceTask.java:200) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
2019-01-24 14:02:41 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 4 tasks
2019-01-24 14:02:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 8542 bytes)
2019-01-24 14:02:41 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 31)
2019-01-24 14:02:41 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:02:41 INFO  CodeGenerator:54 - Code generated in 6.2609 ms
2019-01-24 14:02:41 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 31). 20267 bytes result sent to driver
2019-01-24 14:02:41 INFO  TaskSetManager:54 - Starting task 1.0 in stage 6.0 (TID 32, localhost, executor driver, partition 2, PROCESS_LOCAL, 8064 bytes)
2019-01-24 14:02:41 INFO  Executor:54 - Running task 1.0 in stage 6.0 (TID 32)
2019-01-24 14:02:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 31) in 47 ms on localhost (executor driver) (1/4)
2019-01-24 14:02:41 INFO  Executor:54 - Finished task 1.0 in stage 6.0 (TID 32). 10415 bytes result sent to driver
2019-01-24 14:02:41 INFO  TaskSetManager:54 - Starting task 2.0 in stage 6.0 (TID 33, localhost, executor driver, partition 3, PROCESS_LOCAL, 8049 bytes)
2019-01-24 14:02:41 INFO  Executor:54 - Running task 2.0 in stage 6.0 (TID 33)
2019-01-24 14:02:41 INFO  TaskSetManager:54 - Finished task 1.0 in stage 6.0 (TID 32) in 15 ms on localhost (executor driver) (2/4)
2019-01-24 14:02:41 INFO  Executor:54 - Finished task 2.0 in stage 6.0 (TID 33). 10329 bytes result sent to driver
2019-01-24 14:02:41 INFO  TaskSetManager:54 - Starting task 3.0 in stage 6.0 (TID 34, localhost, executor driver, partition 4, PROCESS_LOCAL, 8034 bytes)
2019-01-24 14:02:41 INFO  Executor:54 - Running task 3.0 in stage 6.0 (TID 34)
2019-01-24 14:02:41 INFO  TaskSetManager:54 - Finished task 2.0 in stage 6.0 (TID 33) in 16 ms on localhost (executor driver) (3/4)
2019-01-24 14:02:41 INFO  Executor:54 - Finished task 3.0 in stage 6.0 (TID 34). 10329 bytes result sent to driver
2019-01-24 14:02:41 INFO  TaskSetManager:54 - Finished task 3.0 in stage 6.0 (TID 34) in 0 ms on localhost (executor driver) (4/4)
2019-01-24 14:02:41 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2019-01-24 14:02:41 INFO  DAGScheduler:54 - ResultStage 6 (show at SparkTraceTask.java:200) finished in 0.078 s
2019-01-24 14:02:41 INFO  DAGScheduler:54 - Job 5 finished: show at SparkTraceTask.java:200, took 0.092450 s
2019-01-24 14:05:01 WARN  Executor:87 - Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:785)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:814)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
2019-01-24 14:05:01 WARN  NettyRpcEnv:66 - Ignored message: HeartbeatResponse(false)
2019-01-24 14:05:01 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-24 14:05:01 INFO  AbstractConnector:318 - Stopped Spark@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-24 14:05:01 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-24 14:05:01 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-24 14:05:01 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-24 14:05:01 INFO  BlockManager:54 - BlockManager stopped
2019-01-24 14:05:01 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-24 14:05:01 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-24 14:05:01 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-24 14:05:01 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-24 14:05:01 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-70f7b8d8-15c2-4947-93e0-157c43a2f7be
2019-01-24 14:05:22 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-24 14:05:23 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-24 14:05:23 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-24 14:05:23 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-24 14:05:23 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-24 14:05:23 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-24 14:05:23 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-24 14:05:23 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-24 14:05:23 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-24 14:05:24 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 55492.
2019-01-24 14:05:24 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-24 14:05:24 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-24 14:05:24 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-24 14:05:24 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-24 14:05:24 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-6996ee03-ae5e-4884-943c-548d0ac4d069
2019-01-24 14:05:24 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-24 14:05:24 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-24 14:05:24 INFO  log:192 - Logging initialized @7295ms
2019-01-24 14:05:24 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-24 14:05:24 INFO  Server:419 - Started @7361ms
2019-01-24 14:05:24 INFO  AbstractConnector:278 - Started ServerConnector@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-24 14:05:24 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26221bad{/jobs,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/json,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@468dda3e{/jobs/job,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/json,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1729ec00{/stages/stage,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/json,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/environment/json,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/json,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/static,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3062f9f4{/api,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-24 14:05:24 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-24 14:05:24 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-24 14:05:24 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55505.
2019-01-24 14:05:24 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:55505
2019-01-24 14:05:24 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-24 14:05:24 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55505, None)
2019-01-24 14:05:24 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:55505 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 55505, None)
2019-01-24 14:05:24 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55505, None)
2019-01-24 14:05:24 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 55505, None)
2019-01-24 14:05:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12ad1b2a{/metrics/json,null,AVAILABLE,@Spark}
2019-01-24 14:05:25 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-24 14:05:25 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-24 14:05:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL,null,AVAILABLE,@Spark}
2019-01-24 14:05:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1624775{/SQL/json,null,AVAILABLE,@Spark}
2019-01-24 14:05:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-24 14:05:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@712ac7e6{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-24 14:05:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e43bfe{/static/sql,null,AVAILABLE,@Spark}
2019-01-24 14:05:25 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-24 14:05:27 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:05:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-24 14:05:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:05:27 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:05:27 INFO  CodeGenerator:54 - Code generated in 186.539 ms
2019-01-24 14:05:28 INFO  CodeGenerator:54 - Code generated in 21.7764 ms
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-24 14:05:28 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:55505 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:05:28 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-24 14:05:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:05:28 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-24 14:05:28 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:55505 (size: 4.4 KB, free: 1996.2 MB)
2019-01-24 14:05:28 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:05:28 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-24 14:05:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-24 14:05:28 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-24 14:05:28 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-24 14:05:28 INFO  CodeGenerator:54 - Code generated in 7.9656 ms
2019-01-24 14:05:28 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1261 bytes result sent to driver
2019-01-24 14:05:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 118 ms on localhost (executor driver) (1/1)
2019-01-24 14:05:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-24 14:05:28 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.206 s
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.264536 s
2019-01-24 14:05:28 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:05:28 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:05:28 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:05:28 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:05:28 INFO  CodeGenerator:54 - Code generated in 5.5325 ms
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-24 14:05:28 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:55505 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:05:28 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-24 14:05:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:05:28 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:05:28 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-24 14:05:28 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:05:28 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-24 14:05:28 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:55505 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:05:28 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-24 14:05:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:05:28 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-24 14:05:28 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:55505 (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:05:28 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:05:28 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-24 14:05:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-24 14:05:28 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-24 14:05:28 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:05:28 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1290 bytes result sent to driver
2019-01-24 14:05:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 9 ms on localhost (executor driver) (1/1)
2019-01-24 14:05:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-24 14:05:28 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.019 s
2019-01-24 14:05:28 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.021488 s
2019-01-24 14:05:28 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:05:28 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:05:28 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:05:28 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-24 14:05:28 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:55505 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:05:28 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-24 14:05:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:05:28 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:05:28 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-24 14:05:28 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:05:28 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-24 14:05:28 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-24 14:05:28 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:55505 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:05:28 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-24 14:05:28 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:05:29 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:05:29 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:05:29 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:05:29 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:05:29 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:05:29 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:05:29 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-24 14:05:29 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-24 14:05:29 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:55505 (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:05:29 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:05:29 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:05:29 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-24 14:05:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-24 14:05:29 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-24 14:05:29 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-24 14:05:29 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1205 bytes result sent to driver
2019-01-24 14:05:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 11 ms on localhost (executor driver) (1/1)
2019-01-24 14:05:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-24 14:05:29 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.020 s
2019-01-24 14:05:29 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.022239 s
2019-01-24 14:05:29 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:05:29 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:05:29 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:05:29 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:05:29 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-24 14:05:29 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-24 14:05:29 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:55505 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:05:29 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-24 14:05:29 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:05:29 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_b95945f540f5 inputCol, its NullRemover's IO params are set to null
2019-01-24 14:05:29 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_c59b6c6631a4 inputCol, its NullRemover's IO params are set to null
2019-01-24 14:05:29 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_808c4f0f5e3f inputCol, its NullRemover's IO params are set to null
2019-01-24 14:05:45 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_f10ec0f9a859 inputCol, its NullRemover's IO params are set to null
2019-01-24 14:08:01 WARN  Executor:87 - Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:785)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:814)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
2019-01-24 14:08:01 WARN  NettyRpcEnv:66 - Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from AshCloud-D1:55492 in 10 seconds
2019-01-24 14:08:01 INFO  column remover:43 - removing column commit_content
2019-01-24 14:08:01 INFO  column remover:43 - removing column issue_content
2019-01-24 14:08:01 INFO  column remover:43 - removing column s_tokens
2019-01-24 14:08:01 INFO  column remover:43 - removing column t_tokens
2019-01-24 14:08:01 INFO  column remover:43 - removing column t_htf
2019-01-24 14:08:01 INFO  column remover:43 - removing column s_htf
2019-01-24 14:14:09 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-24 14:14:10 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-24 14:14:10 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-24 14:14:10 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-24 14:14:10 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-24 14:14:10 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-24 14:14:10 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-24 14:14:10 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-24 14:14:10 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-24 14:14:11 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 55601.
2019-01-24 14:14:11 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-24 14:14:11 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-24 14:14:11 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-24 14:14:11 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-24 14:14:11 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-d3880658-cadc-41b3-9be6-25ec8b8a0718
2019-01-24 14:14:11 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-24 14:14:11 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-24 14:14:11 INFO  log:192 - Logging initialized @7315ms
2019-01-24 14:14:11 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-24 14:14:11 INFO  Server:419 - Started @7373ms
2019-01-24 14:14:11 INFO  AbstractConnector:278 - Started ServerConnector@38f03b80{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-24 14:14:11 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5c7668ba{/jobs,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10823d72{/jobs/json,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/job,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54cf7c6a{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/stages,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages/json,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/stage,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b10ace9{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/pool,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/storage,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage/json,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/environment,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment/json,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/executors,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors/json,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/static,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@665522c2{/,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/api,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a237731{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-24 14:14:11 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-24 14:14:11 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-24 14:14:11 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55614.
2019-01-24 14:14:11 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:55614
2019-01-24 14:14:11 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-24 14:14:11 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:14:11 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:55614 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:14:11 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:14:11 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:14:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1697f2b3{/metrics/json,null,AVAILABLE,@Spark}
2019-01-24 14:14:12 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-24 14:14:12 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-24 14:14:12 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10e5bf9c{/SQL,null,AVAILABLE,@Spark}
2019-01-24 14:14:12 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL/json,null,AVAILABLE,@Spark}
2019-01-24 14:14:12 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4346808{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-24 14:14:12 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-24 14:14:12 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@ab24484{/static/sql,null,AVAILABLE,@Spark}
2019-01-24 14:14:12 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-24 14:14:14 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:14:14 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-24 14:14:14 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:14:14 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:14:14 INFO  CodeGenerator:54 - Code generated in 174.7418 ms
2019-01-24 14:14:15 INFO  CodeGenerator:54 - Code generated in 20.7626 ms
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-24 14:14:15 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:14:15 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-24 14:14:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:14:15 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-24 14:14:15 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:55614 (size: 4.4 KB, free: 1996.2 MB)
2019-01-24 14:14:15 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:14:15 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-24 14:14:15 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-24 14:14:15 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-24 14:14:15 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-24 14:14:15 INFO  CodeGenerator:54 - Code generated in 9.7115 ms
2019-01-24 14:14:15 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2019-01-24 14:14:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 134 ms on localhost (executor driver) (1/1)
2019-01-24 14:14:15 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-24 14:14:15 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.223 s
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.267714 s
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:14:15 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:14:15 INFO  CodeGenerator:54 - Code generated in 7.0579 ms
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-24 14:14:15 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:14:15 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-24 14:14:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:14:15 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-24 14:14:15 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:15 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-24 14:14:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:14:15 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-24 14:14:15 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:55614 (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:14:15 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:14:15 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-24 14:14:15 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-24 14:14:15 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-24 14:14:15 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:14:15 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1333 bytes result sent to driver
2019-01-24 14:14:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 10 ms on localhost (executor driver) (1/1)
2019-01-24 14:14:15 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-24 14:14:15 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.019 s
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.021702 s
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:14:15 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-24 14:14:15 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:15 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-24 14:14:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:14:15 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-24 14:14:15 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:15 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-24 14:14:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:14:15 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-24 14:14:15 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:55614 (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:14:15 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:14:15 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-24 14:14:15 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-24 14:14:15 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-24 14:14:15 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-24 14:14:15 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1205 bytes result sent to driver
2019-01-24 14:14:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 11 ms on localhost (executor driver) (1/1)
2019-01-24 14:14:15 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-24 14:14:15 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.019 s
2019-01-24 14:14:15 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.021412 s
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:14:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:14:15 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-24 14:14:15 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-24 14:14:15 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:15 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-24 14:14:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:14:16 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_19b8099e02d3 inputCol, its NullRemover's IO params are set to null
2019-01-24 14:14:16 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_f02b2864466b inputCol, its NullRemover's IO params are set to null
2019-01-24 14:14:16 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_c2561db483d0 inputCol, its NullRemover's IO params are set to null
2019-01-24 14:14:16 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_ba17a76fbd9e inputCol, its NullRemover's IO params are set to null
2019-01-24 14:14:16 INFO  column remover:43 - removing column commit_content
2019-01-24 14:14:16 INFO  column remover:43 - removing column issue_content
2019-01-24 14:14:16 INFO  column remover:43 - removing column s_tokens
2019-01-24 14:14:16 INFO  column remover:43 - removing column t_tokens
2019-01-24 14:14:16 INFO  column remover:43 - removing column t_htf
2019-01-24 14:14:16 INFO  column remover:43 - removing column s_htf
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 21
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 9
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 22
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 84
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 89
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 104
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 12
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 62
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 7
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 23
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 28
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 94
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 40
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 102
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 20
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 78
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 56
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 103
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 91
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 6
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 50
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 101
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 67
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 54
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 14
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 79
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 51
2019-01-24 14:14:16 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on AshCloud-D1:55614 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 77
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 64
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 60
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 68
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 39
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 75
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 43
2019-01-24 14:14:16 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on AshCloud-D1:55614 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 96
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 92
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 107
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 44
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 98
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 49
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 93
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 69
2019-01-24 14:14:16 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on AshCloud-D1:55614 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 57
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 81
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 100
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 66
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 97
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 87
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 25
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 72
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 37
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 99
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 83
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 55
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 24
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 36
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 52
2019-01-24 14:14:16 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on AshCloud-D1:55614 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 105
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 65
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 70
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 10
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 80
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 74
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 30
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 27
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 53
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 106
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 46
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 88
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 48
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 26
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 73
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 38
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 41
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 15
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 29
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 47
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 86
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 18
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 19
2019-01-24 14:14:16 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:55614 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 58
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 42
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 11
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 76
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 17
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 59
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 82
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 45
2019-01-24 14:14:16 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on AshCloud-D1:55614 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 13
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 71
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 85
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 8
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 90
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 95
2019-01-24 14:14:16 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on AshCloud-D1:55614 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 16
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 61
2019-01-24 14:14:16 INFO  ContextCleaner:54 - Cleaned accumulator 63
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnotnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNotNull(issue_summary)
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnotnull(UDF(UDF(commit_content#17)))
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_resolution#48),isnull(issue_summary#54),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:14:17 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_resolution),IsNull(issue_summary)
2019-01-24 14:14:17 INFO  CodeGenerator:54 - Code generated in 37.5506 ms
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-24 14:14:17 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:17 INFO  SparkContext:54 - Created broadcast 9 from rdd at IDF.scala:89
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:14:17 INFO  CodeGenerator:54 - Code generated in 28.8833 ms
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.3 MB)
2019-01-24 14:14:17 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:17 INFO  SparkContext:54 - Created broadcast 10 from rdd at IDF.scala:89
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:14:17 INFO  CodeGenerator:54 - Code generated in 23.8241 ms
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-24 14:14:17 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:17 INFO  SparkContext:54 - Created broadcast 11 from rdd at IDF.scala:89
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:14:17 INFO  CodeGenerator:54 - Code generated in 23.0591 ms
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-24 14:14:17 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:17 INFO  SparkContext:54 - Created broadcast 12 from rdd at IDF.scala:89
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:14:17 INFO  CodeGenerator:54 - Code generated in 22.6031 ms
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 220.9 KB, free 1994.6 MB)
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.5 MB)
2019-01-24 14:14:17 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:17 INFO  SparkContext:54 - Created broadcast 13 from rdd at IDF.scala:89
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:14:17 INFO  CodeGenerator:54 - Code generated in 19.7815 ms
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 220.9 KB, free 1994.3 MB)
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.3 MB)
2019-01-24 14:14:17 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:14:17 INFO  SparkContext:54 - Created broadcast 14 from rdd at IDF.scala:89
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:14:17 INFO  CodeGenerator:54 - Code generated in 16.4185 ms
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 220.9 KB, free 1994.1 MB)
2019-01-24 14:14:17 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.1 MB)
2019-01-24 14:14:17 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:14:17 INFO  SparkContext:54 - Created broadcast 15 from rdd at IDF.scala:89
2019-01-24 14:14:17 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:14:18 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2019-01-24 14:14:18 INFO  DAGScheduler:54 - Registering RDD 67 (treeAggregate at IDF.scala:54)
2019-01-24 14:14:18 INFO  DAGScheduler:54 - Got job 3 (treeAggregate at IDF.scala:54) with 4 output partitions
2019-01-24 14:14:18 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (treeAggregate at IDF.scala:54)
2019-01-24 14:14:18 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 3)
2019-01-24 14:14:18 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 3)
2019-01-24 14:14:18 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-24 14:14:18 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 117.2 KB, free 1994.0 MB)
2019-01-24 14:14:18 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 30.5 KB, free 1993.9 MB)
2019-01-24 14:14:18 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on AshCloud-D1:55614 (size: 30.5 KB, free: 1996.0 MB)
2019-01-24 14:14:18 INFO  SparkContext:54 - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:14:18 INFO  DAGScheduler:54 - Submitting 23 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2019-01-24 14:14:18 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 23 tasks
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2019-01-24 14:14:18 INFO  CodeGenerator:54 - Code generated in 6.6359 ms
2019-01-24 14:14:18 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 4572 bytes result sent to driver
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 4)
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 78 ms on localhost (executor driver) (1/23)
2019-01-24 14:14:18 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 4). 4529 bytes result sent to driver
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 5, localhost, executor driver, partition 2, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 5)
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 4) in 18 ms on localhost (executor driver) (2/23)
2019-01-24 14:14:18 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:14:18 INFO  CodeGenerator:54 - Code generated in 5.9642 ms
2019-01-24 14:14:18 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 5). 4658 bytes result sent to driver
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 3.0 in stage 3.0 (TID 6, localhost, executor driver, partition 3, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 3.0 in stage 3.0 (TID 6)
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 5) in 543 ms on localhost (executor driver) (3/23)
2019-01-24 14:14:18 INFO  Executor:54 - Finished task 3.0 in stage 3.0 (TID 6). 4529 bytes result sent to driver
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 4.0 in stage 3.0 (TID 7, localhost, executor driver, partition 4, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 4.0 in stage 3.0 (TID 7)
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Finished task 3.0 in stage 3.0 (TID 6) in 17 ms on localhost (executor driver) (4/23)
2019-01-24 14:14:18 INFO  Executor:54 - Finished task 4.0 in stage 3.0 (TID 7). 4529 bytes result sent to driver
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 5.0 in stage 3.0 (TID 8, localhost, executor driver, partition 5, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 5.0 in stage 3.0 (TID 8)
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Finished task 4.0 in stage 3.0 (TID 7) in 15 ms on localhost (executor driver) (5/23)
2019-01-24 14:14:18 INFO  Executor:54 - Finished task 5.0 in stage 3.0 (TID 8). 4529 bytes result sent to driver
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 6.0 in stage 3.0 (TID 9, localhost, executor driver, partition 6, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 6.0 in stage 3.0 (TID 9)
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Finished task 5.0 in stage 3.0 (TID 8) in 20 ms on localhost (executor driver) (6/23)
2019-01-24 14:14:18 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:14:18 INFO  Executor:54 - Finished task 6.0 in stage 3.0 (TID 9). 4658 bytes result sent to driver
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 7.0 in stage 3.0 (TID 10, localhost, executor driver, partition 7, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 7.0 in stage 3.0 (TID 10)
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Finished task 6.0 in stage 3.0 (TID 9) in 34 ms on localhost (executor driver) (7/23)
2019-01-24 14:14:18 INFO  Executor:54 - Finished task 7.0 in stage 3.0 (TID 10). 4572 bytes result sent to driver
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 8.0 in stage 3.0 (TID 11, localhost, executor driver, partition 8, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 8.0 in stage 3.0 (TID 11)
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Finished task 7.0 in stage 3.0 (TID 10) in 19 ms on localhost (executor driver) (8/23)
2019-01-24 14:14:18 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:14:18 INFO  Executor:54 - Finished task 8.0 in stage 3.0 (TID 11). 4615 bytes result sent to driver
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 9.0 in stage 3.0 (TID 12, localhost, executor driver, partition 9, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 9.0 in stage 3.0 (TID 12)
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Finished task 8.0 in stage 3.0 (TID 11) in 33 ms on localhost (executor driver) (9/23)
2019-01-24 14:14:18 INFO  Executor:54 - Finished task 9.0 in stage 3.0 (TID 12). 4529 bytes result sent to driver
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 10.0 in stage 3.0 (TID 13, localhost, executor driver, partition 10, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 10.0 in stage 3.0 (TID 13)
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Finished task 9.0 in stage 3.0 (TID 12) in 19 ms on localhost (executor driver) (10/23)
2019-01-24 14:14:18 INFO  Executor:54 - Finished task 10.0 in stage 3.0 (TID 13). 4529 bytes result sent to driver
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 11.0 in stage 3.0 (TID 14, localhost, executor driver, partition 11, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 11.0 in stage 3.0 (TID 14)
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Finished task 10.0 in stage 3.0 (TID 13) in 14 ms on localhost (executor driver) (11/23)
2019-01-24 14:14:18 INFO  Executor:54 - Finished task 11.0 in stage 3.0 (TID 14). 4529 bytes result sent to driver
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 12.0 in stage 3.0 (TID 15, localhost, executor driver, partition 12, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 12.0 in stage 3.0 (TID 15)
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Finished task 11.0 in stage 3.0 (TID 14) in 16 ms on localhost (executor driver) (12/23)
2019-01-24 14:14:18 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:14:18 INFO  Executor:54 - Finished task 12.0 in stage 3.0 (TID 15). 4615 bytes result sent to driver
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Starting task 13.0 in stage 3.0 (TID 16, localhost, executor driver, partition 13, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:18 INFO  Executor:54 - Running task 13.0 in stage 3.0 (TID 16)
2019-01-24 14:14:18 INFO  TaskSetManager:54 - Finished task 12.0 in stage 3.0 (TID 15) in 47 ms on localhost (executor driver) (13/23)
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 13.0 in stage 3.0 (TID 16). 4529 bytes result sent to driver
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Starting task 14.0 in stage 3.0 (TID 17, localhost, executor driver, partition 14, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:19 INFO  Executor:54 - Running task 14.0 in stage 3.0 (TID 17)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 13.0 in stage 3.0 (TID 16) in 14 ms on localhost (executor driver) (14/23)
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 14.0 in stage 3.0 (TID 17). 4529 bytes result sent to driver
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Starting task 15.0 in stage 3.0 (TID 18, localhost, executor driver, partition 15, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:19 INFO  Executor:54 - Running task 15.0 in stage 3.0 (TID 18)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 14.0 in stage 3.0 (TID 17) in 18 ms on localhost (executor driver) (15/23)
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 15.0 in stage 3.0 (TID 18). 4486 bytes result sent to driver
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Starting task 16.0 in stage 3.0 (TID 19, localhost, executor driver, partition 16, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:19 INFO  Executor:54 - Running task 16.0 in stage 3.0 (TID 19)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 15.0 in stage 3.0 (TID 18) in 14 ms on localhost (executor driver) (16/23)
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 16.0 in stage 3.0 (TID 19). 4529 bytes result sent to driver
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Starting task 17.0 in stage 3.0 (TID 20, localhost, executor driver, partition 17, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:14:19 INFO  Executor:54 - Running task 17.0 in stage 3.0 (TID 20)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 16.0 in stage 3.0 (TID 19) in 13 ms on localhost (executor driver) (17/23)
2019-01-24 14:14:19 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 17.0 in stage 3.0 (TID 20). 4615 bytes result sent to driver
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Starting task 18.0 in stage 3.0 (TID 21, localhost, executor driver, partition 18, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:19 INFO  Executor:54 - Running task 18.0 in stage 3.0 (TID 21)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 17.0 in stage 3.0 (TID 20) in 30 ms on localhost (executor driver) (18/23)
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 18.0 in stage 3.0 (TID 21). 4486 bytes result sent to driver
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Starting task 19.0 in stage 3.0 (TID 22, localhost, executor driver, partition 19, PROCESS_LOCAL, 8437 bytes)
2019-01-24 14:14:19 INFO  Executor:54 - Running task 19.0 in stage 3.0 (TID 22)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 18.0 in stage 3.0 (TID 21) in 13 ms on localhost (executor driver) (19/23)
2019-01-24 14:14:19 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 19.0 in stage 3.0 (TID 22). 4658 bytes result sent to driver
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Starting task 20.0 in stage 3.0 (TID 23, localhost, executor driver, partition 20, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:14:19 INFO  Executor:54 - Running task 20.0 in stage 3.0 (TID 23)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 19.0 in stage 3.0 (TID 22) in 445 ms on localhost (executor driver) (20/23)
2019-01-24 14:14:19 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 20.0 in stage 3.0 (TID 23). 4615 bytes result sent to driver
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Starting task 21.0 in stage 3.0 (TID 24, localhost, executor driver, partition 21, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:19 INFO  Executor:54 - Running task 21.0 in stage 3.0 (TID 24)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 20.0 in stage 3.0 (TID 23) in 30 ms on localhost (executor driver) (21/23)
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 21.0 in stage 3.0 (TID 24). 4486 bytes result sent to driver
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Starting task 22.0 in stage 3.0 (TID 25, localhost, executor driver, partition 22, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:14:19 INFO  Executor:54 - Running task 22.0 in stage 3.0 (TID 25)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 21.0 in stage 3.0 (TID 24) in 13 ms on localhost (executor driver) (22/23)
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 22.0 in stage 3.0 (TID 25). 4529 bytes result sent to driver
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 22.0 in stage 3.0 (TID 25) in 14 ms on localhost (executor driver) (23/23)
2019-01-24 14:14:19 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2019-01-24 14:14:19 INFO  DAGScheduler:54 - ShuffleMapStage 3 (treeAggregate at IDF.scala:54) finished in 1.483 s
2019-01-24 14:14:19 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-01-24 14:14:19 INFO  DAGScheduler:54 - running: Set()
2019-01-24 14:14:19 INFO  DAGScheduler:54 - waiting: Set(ResultStage 4)
2019-01-24 14:14:19 INFO  DAGScheduler:54 - failed: Set()
2019-01-24 14:14:19 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-24 14:14:19 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 118.1 KB, free 1993.8 MB)
2019-01-24 14:14:19 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 31.2 KB, free 1993.8 MB)
2019-01-24 14:14:19 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on AshCloud-D1:55614 (size: 31.2 KB, free: 1996.0 MB)
2019-01-24 14:14:19 INFO  SparkContext:54 - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:14:19 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-01-24 14:14:19 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 4 tasks
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 26, localhost, executor driver, partition 0, ANY, 7649 bytes)
2019-01-24 14:14:19 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 26)
2019-01-24 14:14:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-24 14:14:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2019-01-24 14:14:19 INFO  MemoryStore:54 - Block taskresult_26 stored as bytes in memory (estimated size 2.0 MB, free 1991.8 MB)
2019-01-24 14:14:19 INFO  BlockManagerInfo:54 - Added taskresult_26 in memory on AshCloud-D1:55614 (size: 2.0 MB, free: 1993.9 MB)
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 26). 2112372 bytes result sent via BlockManager)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 27, localhost, executor driver, partition 1, ANY, 7649 bytes)
2019-01-24 14:14:19 INFO  Executor:54 - Running task 1.0 in stage 4.0 (TID 27)
2019-01-24 14:14:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-24 14:14:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 1.0 in stage 4.0 (TID 27). 4702 bytes result sent to driver
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Starting task 2.0 in stage 4.0 (TID 28, localhost, executor driver, partition 2, ANY, 7649 bytes)
2019-01-24 14:14:19 INFO  Executor:54 - Running task 2.0 in stage 4.0 (TID 28)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 27) in 10 ms on localhost (executor driver) (1/4)
2019-01-24 14:14:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-24 14:14:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-24 14:14:19 INFO  MemoryStore:54 - Block taskresult_28 stored as bytes in memory (estimated size 2.0 MB, free 1989.8 MB)
2019-01-24 14:14:19 INFO  BlockManagerInfo:54 - Added taskresult_28 in memory on AshCloud-D1:55614 (size: 2.0 MB, free: 1991.9 MB)
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 2.0 in stage 4.0 (TID 28). 2112329 bytes result sent via BlockManager)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Starting task 3.0 in stage 4.0 (TID 29, localhost, executor driver, partition 3, ANY, 7649 bytes)
2019-01-24 14:14:19 INFO  Executor:54 - Running task 3.0 in stage 4.0 (TID 29)
2019-01-24 14:14:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 5 non-empty blocks out of 23 blocks
2019-01-24 14:14:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-24 14:14:19 INFO  MemoryStore:54 - Block taskresult_29 stored as bytes in memory (estimated size 2.0 MB, free 1987.7 MB)
2019-01-24 14:14:19 INFO  BlockManagerInfo:54 - Added taskresult_29 in memory on AshCloud-D1:55614 (size: 2.0 MB, free: 1989.9 MB)
2019-01-24 14:14:19 INFO  Executor:54 - Finished task 3.0 in stage 4.0 (TID 29). 2112329 bytes result sent via BlockManager)
2019-01-24 14:14:19 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:55614 after 48 ms (0 ms spent in bootstraps)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 2.0 in stage 4.0 (TID 28) in 144 ms on localhost (executor driver) (2/4)
2019-01-24 14:14:19 INFO  BlockManagerInfo:54 - Removed taskresult_28 on AshCloud-D1:55614 in memory (size: 2.0 MB, free: 1991.9 MB)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 26) in 224 ms on localhost (executor driver) (3/4)
2019-01-24 14:14:19 INFO  BlockManagerInfo:54 - Removed taskresult_26 on AshCloud-D1:55614 in memory (size: 2.0 MB, free: 1993.9 MB)
2019-01-24 14:14:19 INFO  TaskSetManager:54 - Finished task 3.0 in stage 4.0 (TID 29) in 155 ms on localhost (executor driver) (4/4)
2019-01-24 14:14:19 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2019-01-24 14:14:19 INFO  BlockManagerInfo:54 - Removed taskresult_29 on AshCloud-D1:55614 in memory (size: 2.0 MB, free: 1996.0 MB)
2019-01-24 14:14:19 INFO  DAGScheduler:54 - ResultStage 4 (treeAggregate at IDF.scala:54) finished in 0.275 s
2019-01-24 14:14:19 INFO  DAGScheduler:54 - Job 3 finished: treeAggregate at IDF.scala:54, took 1.788411 s
2019-01-24 14:14:20 INFO  BlockManagerInfo:54 - Removed broadcast_17_piece0 on AshCloud-D1:55614 in memory (size: 31.2 KB, free: 1996.0 MB)
2019-01-24 14:14:20 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on AshCloud-D1:55614 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:14:20 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on AshCloud-D1:55614 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:14:20 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on AshCloud-D1:55614 in memory (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:14:20 INFO  BlockManagerInfo:54 - Removed broadcast_16_piece0 on AshCloud-D1:55614 in memory (size: 30.5 KB, free: 1996.1 MB)
2019-01-24 14:14:20 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on AshCloud-D1:55614 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:20 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on AshCloud-D1:55614 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:20 INFO  BlockManagerInfo:54 - Removed broadcast_15_piece0 on AshCloud-D1:55614 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:14:20 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on AshCloud-D1:55614 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:14:20 INFO  ContextCleaner:54 - Cleaned shuffle 0
2019-01-24 14:14:20 INFO  column remover:43 - removing column commit_content
2019-01-24 14:14:20 INFO  column remover:43 - removing column issue_content
2019-01-24 14:14:20 INFO  column remover:43 - removing column s_tokens
2019-01-24 14:14:20 INFO  column remover:43 - removing column t_tokens
2019-01-24 14:14:20 INFO  column remover:43 - removing column t_htf
2019-01-24 14:14:20 INFO  column remover:43 - removing column s_htf
2019-01-24 14:16:35 WARN  HeartbeatReceiver:66 - Removing executor driver with no recent heartbeats: 137205 ms exceeds timeout 120000 ms
2019-01-24 14:16:35 ERROR TaskSchedulerImpl:70 - Lost executor driver on localhost: Executor heartbeat timed out after 137205 ms
2019-01-24 14:17:29 WARN  Executor:87 - Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:785)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:814)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
2019-01-24 14:17:29 INFO  DAGScheduler:54 - Executor lost: driver (epoch 1)
2019-01-24 14:17:29 WARN  NettyRpcEnv:66 - Ignored message: HeartbeatResponse(true)
2019-01-24 14:17:29 WARN  SparkContext:66 - Killing executors is not supported by current scheduler.
2019-01-24 14:17:29 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor driver from BlockManagerMaster.
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for broadcast_0_piece0 !
2019-01-24 14:17:29 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for broadcast_2_piece0 !
2019-01-24 14:17:29 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:55614 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Removed driver successfully in removeExecutor
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  DAGScheduler:54 - Shuffle files lost for executor: driver (epoch 1)
2019-01-24 14:17:29 INFO  DAGScheduler:54 - Host added was in lost list earlier: localhost
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:55614 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  Executor:54 - Told to re-register on heartbeat
2019-01-24 14:17:29 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None) re-registering with master
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55614, None)
2019-01-24 14:17:29 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_0_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:29 INFO  BlockManagerInfo:54 - Updated broadcast_2_piece0 in memory on AshCloud-D1:55614 (current size: 20.6 KB, original size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:38 INFO  SparkContext:54 - Running Spark version 2.3.2
2019-01-24 14:17:38 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-24 14:17:38 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2468)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2468)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:934)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:925)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
	at examples.TestBase.<init>(TestBase.java:24)
	at SparkJobTest.<init>(SparkJobTest.java:25)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-01-24 14:17:38 INFO  SparkContext:54 - Submitted application: SparkTest
2019-01-24 14:17:38 INFO  SecurityManager:54 - Changing view acls to: ljfnw
2019-01-24 14:17:38 INFO  SecurityManager:54 - Changing modify acls to: ljfnw
2019-01-24 14:17:38 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-24 14:17:38 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-24 14:17:38 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljfnw); groups with view permissions: Set(); users  with modify permissions: Set(ljfnw); groups with modify permissions: Set()
2019-01-24 14:17:39 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 55676.
2019-01-24 14:17:39 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-24 14:17:39 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-24 14:17:39 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-24 14:17:39 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-24 14:17:39 INFO  DiskBlockManager:54 - Created local directory at C:\Users\ljfnw\AppData\Local\Temp\blockmgr-f7051ffc-45da-4da5-8e1a-e06d9892dffd
2019-01-24 14:17:39 INFO  MemoryStore:54 - MemoryStore started with capacity 1996.2 MB
2019-01-24 14:17:39 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-24 14:17:39 INFO  log:192 - Logging initialized @7301ms
2019-01-24 14:17:39 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-01-24 14:17:39 INFO  Server:419 - Started @7355ms
2019-01-24 14:17:39 INFO  AbstractConnector:278 - Started ServerConnector@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-24 14:17:39 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26221bad{/jobs,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cea0110{/jobs/json,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@468dda3e{/jobs/job,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78010562{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50756c76{/stages,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38aafb53{/stages/json,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1729ec00{/stages/stage,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52169758{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eda0aeb{/stages/pool,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@459b187a{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4283c4{/storage,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d0865a3{/storage/json,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@636bbbbb{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7eae3764{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10dc7d6{/environment,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f668f29{/environment/json,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@716e431d{/executors,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e744f43{/executors/json,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11a8042c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a4ccef7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69391e08{/static,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41fe8e5f{/,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3062f9f4{/api,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d2998d8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://AshCloud-D1:4040
2019-01-24 14:17:40 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-01-24 14:17:40 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55689.
2019-01-24 14:17:40 INFO  NettyBlockTransferService:54 - Server created on AshCloud-D1:55689
2019-01-24 14:17:40 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-24 14:17:40 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, AshCloud-D1, 55689, None)
2019-01-24 14:17:40 INFO  BlockManagerMasterEndpoint:54 - Registering block manager AshCloud-D1:55689 with 1996.2 MB RAM, BlockManagerId(driver, AshCloud-D1, 55689, None)
2019-01-24 14:17:40 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, AshCloud-D1, 55689, None)
2019-01-24 14:17:40 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, AshCloud-D1, 55689, None)
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12ad1b2a{/metrics/json,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/G:/Projects/SparkTrace/spark-warehouse/').
2019-01-24 14:17:40 INFO  SharedState:54 - Warehouse path is 'file:/G:/Projects/SparkTrace/spark-warehouse/'.
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68c9e023{/SQL,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1624775{/SQL/json,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17fede14{/SQL/execution,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@712ac7e6{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-01-24 14:17:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54e43bfe{/static/sql,null,AVAILABLE,@Spark}
2019-01-24 14:17:41 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-01-24 14:17:42 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:17:42 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#5, None)) > 0)
2019-01-24 14:17:42 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:17:42 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:17:43 INFO  CodeGenerator:54 - Code generated in 171.1485 ms
2019-01-24 14:17:43 INFO  CodeGenerator:54 - Code generated in 15.5049 ms
2019-01-24 14:17:43 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 220.9 KB, free 1996.0 MB)
2019-01-24 14:17:43 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1996.0 MB)
2019-01-24 14:17:43 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on AshCloud-D1:55689 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:43 INFO  SparkContext:54 - Created broadcast 0 from csv at TraceDatasetFactory.java:25
2019-01-24 14:17:43 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:17:43 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:17:43 INFO  DAGScheduler:54 - Got job 0 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:17:43 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:17:43 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:17:43 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:17:43 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:17:43 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1996.0 MB)
2019-01-24 14:17:43 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1996.0 MB)
2019-01-24 14:17:43 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on AshCloud-D1:55689 (size: 4.4 KB, free: 1996.2 MB)
2019-01-24 14:17:43 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:17:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:17:43 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-01-24 14:17:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8339 bytes)
2019-01-24 14:17:43 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-01-24 14:17:43 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-24 14:17:43 INFO  CodeGenerator:54 - Code generated in 10.7306 ms
2019-01-24 14:17:43 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2019-01-24 14:17:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 132 ms on localhost (executor driver) (1/1)
2019-01-24 14:17:44 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-24 14:17:44 INFO  DAGScheduler:54 - ResultStage 0 (csv at TraceDatasetFactory.java:25) finished in 0.210 s
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Job 0 finished: csv at TraceDatasetFactory.java:25, took 0.252734 s
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:17:44 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:17:44 INFO  CodeGenerator:54 - Code generated in 6.5465 ms
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 220.9 KB, free 1995.7 MB)
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.7 MB)
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on AshCloud-D1:55689 (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:44 INFO  SparkContext:54 - Created broadcast 2 from csv at TraceDatasetFactory.java:25
2019-01-24 14:17:44 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#36, None)) > 0)
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:17:44 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on AshCloud-D1:55689 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:17:44 INFO  SparkContext:54 - Created broadcast 3 from csv at TraceDatasetFactory.java:25
2019-01-24 14:17:44 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:17:44 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Got job 1 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 1995.5 MB)
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.5 MB)
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on AshCloud-D1:55689 (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:17:44 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:17:44 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-01-24 14:17:44 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8343 bytes)
2019-01-24 14:17:44 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-01-24 14:17:44 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:17:44 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1333 bytes result sent to driver
2019-01-24 14:17:44 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 10 ms on localhost (executor driver) (1/1)
2019-01-24 14:17:44 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-01-24 14:17:44 INFO  DAGScheduler:54 - ResultStage 1 (csv at TraceDatasetFactory.java:25) finished in 0.019 s
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Job 1 finished: csv at TraceDatasetFactory.java:25, took 0.021022 s
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:17:44 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.2 MB)
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on AshCloud-D1:55689 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:17:44 INFO  SparkContext:54 - Created broadcast 5 from csv at TraceDatasetFactory.java:25
2019-01-24 14:17:44 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#73, None)) > 0)
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:17:44 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on AshCloud-D1:55689 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:17:44 INFO  SparkContext:54 - Created broadcast 6 from csv at TraceDatasetFactory.java:25
2019-01-24 14:17:44 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:17:44 INFO  SparkContext:54 - Starting job: csv at TraceDatasetFactory.java:25
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Got job 2 (csv at TraceDatasetFactory.java:25) with 1 output partitions
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at TraceDatasetFactory.java:25)
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25), which has no missing parents
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 1995.0 MB)
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1995.0 MB)
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on AshCloud-D1:55689 (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:17:44 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[21] at csv at TraceDatasetFactory.java:25) (first 15 tasks are for partitions Vector(0))
2019-01-24 14:17:44 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-01-24 14:17:44 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2019-01-24 14:17:44 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-01-24 14:17:44 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvementCommitLinks.csv, range: 0-9592, partition values: [empty row]
2019-01-24 14:17:44 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1205 bytes result sent to driver
2019-01-24 14:17:44 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 7 ms on localhost (executor driver) (1/1)
2019-01-24 14:17:44 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-01-24 14:17:44 INFO  DAGScheduler:54 - ResultStage 2 (csv at TraceDatasetFactory.java:25) finished in 0.016 s
2019-01-24 14:17:44 INFO  DAGScheduler:54 - Job 2 finished: csv at TraceDatasetFactory.java:25, took 0.018570 s
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-01-24 14:17:44 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2019-01-24 14:17:44 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-24 14:17:44 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.7 MB)
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on AshCloud-D1:55689 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:17:44 INFO  SparkContext:54 - Created broadcast 8 from csv at TraceDatasetFactory.java:25
2019-01-24 14:17:44 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4203896 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:17:44 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_168a04410152 inputCol, its NullRemover's IO params are set to null
2019-01-24 14:17:44 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_4ef25a0795bd inputCol, its NullRemover's IO params are set to null
2019-01-24 14:17:44 WARN  NullRemoverModelSingleIO:55 - No default value for stage tok_c6ca9cc53575 inputCol, its NullRemover's IO params are set to null
2019-01-24 14:17:44 WARN  NullRemoverModelSingleIO:55 - No default value for stage hashingTF_7cb9cf23ffa3 inputCol, its NullRemover's IO params are set to null
2019-01-24 14:17:44 INFO  column remover:43 - removing column issue_content
2019-01-24 14:17:44 INFO  column remover:43 - removing column commit_content
2019-01-24 14:17:44 INFO  column remover:43 - removing column t_tokens
2019-01-24 14:17:44 INFO  column remover:43 - removing column s_tokens
2019-01-24 14:17:44 INFO  column remover:43 - removing column s_htf
2019-01-24 14:17:44 INFO  column remover:43 - removing column t_htf
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 46
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 7
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 15
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 16
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 49
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 106
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 12
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 38
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 59
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 8
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 102
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 40
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 21
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 37
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 100
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 44
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 83
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 78
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 48
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 50
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 63
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 107
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on AshCloud-D1:55689 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 82
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 36
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 52
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 85
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 14
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 28
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 54
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 11
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 88
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 42
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 80
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 55
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 24
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on AshCloud-D1:55689 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 18
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 99
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 13
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 58
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 103
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 57
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 51
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 79
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 61
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 73
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 89
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 81
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 30
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 75
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 96
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 19
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 87
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 84
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 53
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 64
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 60
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 66
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on AshCloud-D1:55689 in memory (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 6
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 105
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 68
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 91
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 45
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 56
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on AshCloud-D1:55689 in memory (size: 4.4 KB, free: 1996.1 MB)
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 72
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 26
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 98
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 69
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 86
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 41
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 39
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 17
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 62
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 70
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 67
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 10
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 97
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 9
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 25
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 29
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on AshCloud-D1:55689 in memory (size: 20.6 KB, free: 1996.2 MB)
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 93
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 23
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 22
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 76
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 92
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 77
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on AshCloud-D1:55689 in memory (size: 4.4 KB, free: 1996.2 MB)
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 95
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 90
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 94
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 27
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 104
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 71
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 43
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 47
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 74
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 101
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 65
2019-01-24 14:17:44 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on AshCloud-D1:55689 in memory (size: 4.4 KB, free: 1996.2 MB)
2019-01-24 14:17:44 INFO  ContextCleaner:54 - Cleaned accumulator 20
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_summary#54),isnotnull(issue_resolution#48),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_summary),IsNotNull(issue_resolution)
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_summary#54),isnotnull(issue_resolution#48),isnull(UDF(issue_summary#54)),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_summary),IsNotNull(issue_resolution)
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(commit_content#17),isnotnull(UDF(commit_content#17)),isnotnull(UDF(UDF(commit_content#17)))
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Output Data Schema: struct<commit_content: string>
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(commit_content)
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnull(issue_summary#54),isnotnull(issue_resolution#48),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_resolution#48)))
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Pushed Filters: IsNull(issue_summary),IsNotNull(issue_resolution)
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_summary#54),isnotnull(issue_resolution#48),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_summary),IsNotNull(issue_resolution)
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_summary#54),isnotnull(issue_resolution#48),isnotnull(UDF(issue_summary#54)),isnull(UDF(issue_resolution#48)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_summary),IsNotNull(issue_resolution)
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(issue_summary#54),isnull(issue_resolution#48),isnotnull(UDF(issue_summary#54)),isnotnull(UDF(UDF(issue_summary#54)))
2019-01-24 14:17:46 INFO  FileSourceStrategy:54 - Output Data Schema: struct<issue_resolution: string, issue_summary: string>
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(issue_summary),IsNull(issue_resolution)
2019-01-24 14:17:46 INFO  CodeGenerator:54 - Code generated in 32.9644 ms
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 220.9 KB, free 1995.5 MB)
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.5 MB)
2019-01-24 14:17:46 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on AshCloud-D1:55689 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:17:46 INFO  SparkContext:54 - Created broadcast 9 from rdd at IDF.scala:89
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:17:46 INFO  CodeGenerator:54 - Code generated in 31.6065 ms
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 220.9 KB, free 1995.3 MB)
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.3 MB)
2019-01-24 14:17:46 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on AshCloud-D1:55689 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:17:46 INFO  SparkContext:54 - Created broadcast 10 from rdd at IDF.scala:89
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:17:46 INFO  CodeGenerator:54 - Code generated in 33.5253 ms
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 220.9 KB, free 1995.0 MB)
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1995.0 MB)
2019-01-24 14:17:46 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on AshCloud-D1:55689 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:17:46 INFO  SparkContext:54 - Created broadcast 11 from rdd at IDF.scala:89
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 5696329 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:17:46 INFO  CodeGenerator:54 - Code generated in 22.9575 ms
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 220.9 KB, free 1994.8 MB)
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.8 MB)
2019-01-24 14:17:46 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on AshCloud-D1:55689 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:17:46 INFO  SparkContext:54 - Created broadcast 12 from rdd at IDF.scala:89
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:17:46 INFO  CodeGenerator:54 - Code generated in 18.349 ms
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 220.9 KB, free 1994.6 MB)
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.5 MB)
2019-01-24 14:17:46 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on AshCloud-D1:55689 (size: 20.6 KB, free: 1996.1 MB)
2019-01-24 14:17:46 INFO  SparkContext:54 - Created broadcast 13 from rdd at IDF.scala:89
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:17:46 INFO  CodeGenerator:54 - Code generated in 22.1354 ms
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 220.9 KB, free 1994.3 MB)
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.3 MB)
2019-01-24 14:17:46 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on AshCloud-D1:55689 (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:17:46 INFO  SparkContext:54 - Created broadcast 14 from rdd at IDF.scala:89
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:17:46 INFO  CodeGenerator:54 - Code generated in 17.9051 ms
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 220.9 KB, free 1994.1 MB)
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1994.1 MB)
2019-01-24 14:17:46 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on AshCloud-D1:55689 (size: 20.6 KB, free: 1996.0 MB)
2019-01-24 14:17:46 INFO  SparkContext:54 - Created broadcast 15 from rdd at IDF.scala:89
2019-01-24 14:17:46 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4353602 bytes, open cost is considered as scanning 4194304 bytes.
2019-01-24 14:17:46 INFO  SparkContext:54 - Starting job: treeAggregate at IDF.scala:54
2019-01-24 14:17:46 INFO  DAGScheduler:54 - Registering RDD 67 (treeAggregate at IDF.scala:54)
2019-01-24 14:17:46 INFO  DAGScheduler:54 - Got job 3 (treeAggregate at IDF.scala:54) with 4 output partitions
2019-01-24 14:17:46 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (treeAggregate at IDF.scala:54)
2019-01-24 14:17:46 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 3)
2019-01-24 14:17:46 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 3)
2019-01-24 14:17:46 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 117.2 KB, free 1994.0 MB)
2019-01-24 14:17:46 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.9 KB, free 1993.9 MB)
2019-01-24 14:17:46 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on AshCloud-D1:55689 (size: 29.9 KB, free: 1996.0 MB)
2019-01-24 14:17:46 INFO  SparkContext:54 - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:17:46 INFO  DAGScheduler:54 - Submitting 23 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[67] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2019-01-24 14:17:46 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 23 tasks
2019-01-24 14:17:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:46 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2019-01-24 14:17:46 INFO  CodeGenerator:54 - Code generated in 6.6548 ms
2019-01-24 14:17:46 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 4615 bytes result sent to driver
2019-01-24 14:17:46 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:46 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 4)
2019-01-24 14:17:46 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 77 ms on localhost (executor driver) (1/23)
2019-01-24 14:17:46 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 4). 4529 bytes result sent to driver
2019-01-24 14:17:46 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 5, localhost, executor driver, partition 2, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:17:46 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 5)
2019-01-24 14:17:46 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 4) in 19 ms on localhost (executor driver) (2/23)
2019-01-24 14:17:46 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:17:46 INFO  CodeGenerator:54 - Code generated in 6.9972 ms
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 5). 4615 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 3.0 in stage 3.0 (TID 6, localhost, executor driver, partition 3, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 3.0 in stage 3.0 (TID 6)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 5) in 515 ms on localhost (executor driver) (3/23)
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 3.0 in stage 3.0 (TID 6). 4529 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 4.0 in stage 3.0 (TID 7, localhost, executor driver, partition 4, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 4.0 in stage 3.0 (TID 7)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 3.0 in stage 3.0 (TID 6) in 16 ms on localhost (executor driver) (4/23)
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 4.0 in stage 3.0 (TID 7). 4529 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 5.0 in stage 3.0 (TID 8, localhost, executor driver, partition 5, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 5.0 in stage 3.0 (TID 8)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 4.0 in stage 3.0 (TID 7) in 16 ms on localhost (executor driver) (5/23)
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 5.0 in stage 3.0 (TID 8). 4529 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 6.0 in stage 3.0 (TID 9, localhost, executor driver, partition 6, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 6.0 in stage 3.0 (TID 9)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 5.0 in stage 3.0 (TID 8) in 18 ms on localhost (executor driver) (6/23)
2019-01-24 14:17:47 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 6.0 in stage 3.0 (TID 9). 4658 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 7.0 in stage 3.0 (TID 10, localhost, executor driver, partition 7, PROCESS_LOCAL, 8437 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 7.0 in stage 3.0 (TID 10)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 6.0 in stage 3.0 (TID 9) in 42 ms on localhost (executor driver) (7/23)
2019-01-24 14:17:47 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/commits.csv, range: 0-1502025, partition values: [empty row]
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 7.0 in stage 3.0 (TID 10). 4658 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 8.0 in stage 3.0 (TID 11, localhost, executor driver, partition 8, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 8.0 in stage 3.0 (TID 11)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 7.0 in stage 3.0 (TID 10) in 446 ms on localhost (executor driver) (8/23)
2019-01-24 14:17:47 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 8.0 in stage 3.0 (TID 11). 4615 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 9.0 in stage 3.0 (TID 12, localhost, executor driver, partition 9, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 9.0 in stage 3.0 (TID 12)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 8.0 in stage 3.0 (TID 11) in 30 ms on localhost (executor driver) (9/23)
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 9.0 in stage 3.0 (TID 12). 4529 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 10.0 in stage 3.0 (TID 13, localhost, executor driver, partition 10, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 10.0 in stage 3.0 (TID 13)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 9.0 in stage 3.0 (TID 12) in 14 ms on localhost (executor driver) (10/23)
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 10.0 in stage 3.0 (TID 13). 4529 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 11.0 in stage 3.0 (TID 14, localhost, executor driver, partition 11, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 11.0 in stage 3.0 (TID 14)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 10.0 in stage 3.0 (TID 13) in 14 ms on localhost (executor driver) (11/23)
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 11.0 in stage 3.0 (TID 14). 4529 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 12.0 in stage 3.0 (TID 15, localhost, executor driver, partition 12, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 12.0 in stage 3.0 (TID 15)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 11.0 in stage 3.0 (TID 14) in 18 ms on localhost (executor driver) (12/23)
2019-01-24 14:17:47 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 12.0 in stage 3.0 (TID 15). 4615 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 13.0 in stage 3.0 (TID 16, localhost, executor driver, partition 13, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 13.0 in stage 3.0 (TID 16)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 12.0 in stage 3.0 (TID 15) in 71 ms on localhost (executor driver) (13/23)
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 13.0 in stage 3.0 (TID 16). 4529 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 14.0 in stage 3.0 (TID 17, localhost, executor driver, partition 14, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 14.0 in stage 3.0 (TID 17)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 13.0 in stage 3.0 (TID 16) in 15 ms on localhost (executor driver) (14/23)
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 14.0 in stage 3.0 (TID 17). 4529 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 15.0 in stage 3.0 (TID 18, localhost, executor driver, partition 15, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 15.0 in stage 3.0 (TID 18)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 14.0 in stage 3.0 (TID 17) in 14 ms on localhost (executor driver) (15/23)
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 15.0 in stage 3.0 (TID 18). 4529 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 16.0 in stage 3.0 (TID 19, localhost, executor driver, partition 16, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 16.0 in stage 3.0 (TID 19)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 15.0 in stage 3.0 (TID 18) in 16 ms on localhost (executor driver) (16/23)
2019-01-24 14:17:47 INFO  Executor:54 - Finished task 16.0 in stage 3.0 (TID 19). 4529 bytes result sent to driver
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Starting task 17.0 in stage 3.0 (TID 20, localhost, executor driver, partition 17, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:17:47 INFO  Executor:54 - Running task 17.0 in stage 3.0 (TID 20)
2019-01-24 14:17:47 INFO  TaskSetManager:54 - Finished task 16.0 in stage 3.0 (TID 19) in 14 ms on localhost (executor driver) (17/23)
2019-01-24 14:17:47 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:17:48 INFO  Executor:54 - Finished task 17.0 in stage 3.0 (TID 20). 4615 bytes result sent to driver
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Starting task 18.0 in stage 3.0 (TID 21, localhost, executor driver, partition 18, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:48 INFO  Executor:54 - Running task 18.0 in stage 3.0 (TID 21)
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Finished task 17.0 in stage 3.0 (TID 20) in 30 ms on localhost (executor driver) (18/23)
2019-01-24 14:17:48 INFO  Executor:54 - Finished task 18.0 in stage 3.0 (TID 21). 4529 bytes result sent to driver
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Starting task 19.0 in stage 3.0 (TID 22, localhost, executor driver, partition 19, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:48 INFO  Executor:54 - Running task 19.0 in stage 3.0 (TID 22)
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Finished task 18.0 in stage 3.0 (TID 21) in 15 ms on localhost (executor driver) (19/23)
2019-01-24 14:17:48 INFO  Executor:54 - Finished task 19.0 in stage 3.0 (TID 22). 4529 bytes result sent to driver
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Starting task 20.0 in stage 3.0 (TID 23, localhost, executor driver, partition 20, PROCESS_LOCAL, 8441 bytes)
2019-01-24 14:17:48 INFO  Executor:54 - Running task 20.0 in stage 3.0 (TID 23)
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Finished task 19.0 in stage 3.0 (TID 22) in 15 ms on localhost (executor driver) (20/23)
2019-01-24 14:17:48 INFO  FileScanRDD:54 - Reading File path: file:///G:/Projects/SparkTrace/src/main/resources/maven_sample/improvement.csv, range: 0-159298, partition values: [empty row]
2019-01-24 14:17:48 INFO  Executor:54 - Finished task 20.0 in stage 3.0 (TID 23). 4615 bytes result sent to driver
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Starting task 21.0 in stage 3.0 (TID 24, localhost, executor driver, partition 21, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:48 INFO  Executor:54 - Running task 21.0 in stage 3.0 (TID 24)
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Finished task 20.0 in stage 3.0 (TID 23) in 27 ms on localhost (executor driver) (21/23)
2019-01-24 14:17:48 INFO  Executor:54 - Finished task 21.0 in stage 3.0 (TID 24). 4486 bytes result sent to driver
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Starting task 22.0 in stage 3.0 (TID 25, localhost, executor driver, partition 22, PROCESS_LOCAL, 7978 bytes)
2019-01-24 14:17:48 INFO  Executor:54 - Running task 22.0 in stage 3.0 (TID 25)
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Finished task 21.0 in stage 3.0 (TID 24) in 14 ms on localhost (executor driver) (22/23)
2019-01-24 14:17:48 INFO  Executor:54 - Finished task 22.0 in stage 3.0 (TID 25). 4572 bytes result sent to driver
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Finished task 22.0 in stage 3.0 (TID 25) in 20 ms on localhost (executor driver) (23/23)
2019-01-24 14:17:48 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2019-01-24 14:17:48 INFO  DAGScheduler:54 - ShuffleMapStage 3 (treeAggregate at IDF.scala:54) finished in 1.480 s
2019-01-24 14:17:48 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-01-24 14:17:48 INFO  DAGScheduler:54 - running: Set()
2019-01-24 14:17:48 INFO  DAGScheduler:54 - waiting: Set(ResultStage 4)
2019-01-24 14:17:48 INFO  DAGScheduler:54 - failed: Set()
2019-01-24 14:17:48 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54), which has no missing parents
2019-01-24 14:17:48 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 118.2 KB, free 1993.8 MB)
2019-01-24 14:17:48 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 30.6 KB, free 1993.8 MB)
2019-01-24 14:17:48 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on AshCloud-D1:55689 (size: 30.6 KB, free: 1996.0 MB)
2019-01-24 14:17:48 INFO  SparkContext:54 - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2019-01-24 14:17:48 INFO  DAGScheduler:54 - Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[69] at treeAggregate at IDF.scala:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-01-24 14:17:48 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 4 tasks
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 26, localhost, executor driver, partition 0, ANY, 7649 bytes)
2019-01-24 14:17:48 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 26)
2019-01-24 14:17:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-24 14:17:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2019-01-24 14:17:48 INFO  MemoryStore:54 - Block taskresult_26 stored as bytes in memory (estimated size 2.0 MB, free 1991.8 MB)
2019-01-24 14:17:48 INFO  BlockManagerInfo:54 - Added taskresult_26 in memory on AshCloud-D1:55689 (size: 2.0 MB, free: 1993.9 MB)
2019-01-24 14:17:48 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 26). 2112329 bytes result sent via BlockManager)
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 27, localhost, executor driver, partition 1, ANY, 7649 bytes)
2019-01-24 14:17:48 INFO  Executor:54 - Running task 1.0 in stage 4.0 (TID 27)
2019-01-24 14:17:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-24 14:17:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2019-01-24 14:17:48 INFO  Executor:54 - Finished task 1.0 in stage 4.0 (TID 27). 4745 bytes result sent to driver
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Starting task 2.0 in stage 4.0 (TID 28, localhost, executor driver, partition 2, ANY, 7649 bytes)
2019-01-24 14:17:48 INFO  Executor:54 - Running task 2.0 in stage 4.0 (TID 28)
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 27) in 12 ms on localhost (executor driver) (1/4)
2019-01-24 14:17:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks out of 23 blocks
2019-01-24 14:17:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-24 14:17:48 INFO  MemoryStore:54 - Block taskresult_28 stored as bytes in memory (estimated size 2.0 MB, free 1989.8 MB)
2019-01-24 14:17:48 INFO  BlockManagerInfo:54 - Added taskresult_28 in memory on AshCloud-D1:55689 (size: 2.0 MB, free: 1991.9 MB)
2019-01-24 14:17:48 INFO  Executor:54 - Finished task 2.0 in stage 4.0 (TID 28). 2112329 bytes result sent via BlockManager)
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Starting task 3.0 in stage 4.0 (TID 29, localhost, executor driver, partition 3, ANY, 7649 bytes)
2019-01-24 14:17:48 INFO  Executor:54 - Running task 3.0 in stage 4.0 (TID 29)
2019-01-24 14:17:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 5 non-empty blocks out of 23 blocks
2019-01-24 14:17:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-01-24 14:17:48 INFO  MemoryStore:54 - Block taskresult_29 stored as bytes in memory (estimated size 2.0 MB, free 1987.7 MB)
2019-01-24 14:17:48 INFO  BlockManagerInfo:54 - Added taskresult_29 in memory on AshCloud-D1:55689 (size: 2.0 MB, free: 1989.9 MB)
2019-01-24 14:17:48 INFO  Executor:54 - Finished task 3.0 in stage 4.0 (TID 29). 2112329 bytes result sent via BlockManager)
2019-01-24 14:17:48 INFO  TransportClientFactory:267 - Successfully created connection to AshCloud-D1/192.168.56.1:55689 after 49 ms (0 ms spent in bootstraps)
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Finished task 3.0 in stage 4.0 (TID 29) in 120 ms on localhost (executor driver) (2/4)
2019-01-24 14:17:48 INFO  BlockManagerInfo:54 - Removed taskresult_29 on AshCloud-D1:55689 in memory (size: 2.0 MB, free: 1991.9 MB)
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Finished task 2.0 in stage 4.0 (TID 28) in 156 ms on localhost (executor driver) (3/4)
2019-01-24 14:17:48 INFO  BlockManagerInfo:54 - Removed taskresult_28 on AshCloud-D1:55689 in memory (size: 2.0 MB, free: 1993.9 MB)
2019-01-24 14:17:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 26) in 244 ms on localhost (executor driver) (4/4)
2019-01-24 14:17:48 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2019-01-24 14:17:48 INFO  BlockManagerInfo:54 - Removed taskresult_26 on AshCloud-D1:55689 in memory (size: 2.0 MB, free: 1996.0 MB)
2019-01-24 14:17:48 INFO  DAGScheduler:54 - ResultStage 4 (treeAggregate at IDF.scala:54) finished in 0.286 s
2019-01-24 14:17:48 INFO  DAGScheduler:54 - Job 3 finished: treeAggregate at IDF.scala:54, took 1.795876 s
2019-01-24 14:17:49 INFO  column remover:43 - removing column issue_content
2019-01-24 14:17:49 INFO  column remover:43 - removing column commit_content
2019-01-24 14:17:49 INFO  column remover:43 - removing column t_tokens
2019-01-24 14:17:49 INFO  column remover:43 - removing column s_tokens
2019-01-24 14:17:49 INFO  column remover:43 - removing column s_htf
2019-01-24 14:17:49 INFO  column remover:43 - removing column t_htf
2019-01-24 14:18:20 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-01-24 14:18:20 INFO  AbstractConnector:318 - Stopped Spark@2e51d054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-01-24 14:18:20 INFO  SparkUI:54 - Stopped Spark web UI at http://AshCloud-D1:4040
2019-01-24 14:18:20 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-24 14:18:20 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-24 14:18:20 INFO  BlockManager:54 - BlockManager stopped
2019-01-24 14:18:20 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-24 14:18:20 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-24 14:18:20 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-24 14:18:20 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-24 14:18:20 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\ljfnw\AppData\Local\Temp\spark-0fac4689-350f-4263-914c-e171cc3b5524
